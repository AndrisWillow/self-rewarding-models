{
  "best_metric": 1.2541581392288208,
  "best_model_checkpoint": "outputs/checkpoint-615",
  "epoch": 0.9991876523151909,
  "eval_steps": 500,
  "global_step": 615,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.6619882583618164,
      "learning_rate": 9.983739837398374e-05,
      "loss": 2.0594,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4180248975753784,
      "learning_rate": 9.967479674796748e-05,
      "loss": 1.6998,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.6101924180984497,
      "learning_rate": 9.951219512195122e-05,
      "loss": 1.9389,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1824049949645996,
      "learning_rate": 9.934959349593496e-05,
      "loss": 1.6928,
      "step": 4
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0487148761749268,
      "learning_rate": 9.91869918699187e-05,
      "loss": 1.626,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0813438892364502,
      "learning_rate": 9.902439024390244e-05,
      "loss": 1.5443,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1494327783584595,
      "learning_rate": 9.886178861788619e-05,
      "loss": 1.749,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.796608030796051,
      "learning_rate": 9.869918699186992e-05,
      "loss": 1.4189,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7082507610321045,
      "learning_rate": 9.853658536585366e-05,
      "loss": 1.4822,
      "step": 9
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6610210537910461,
      "learning_rate": 9.837398373983741e-05,
      "loss": 1.4091,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7291989326477051,
      "learning_rate": 9.821138211382113e-05,
      "loss": 1.425,
      "step": 11
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8241230845451355,
      "learning_rate": 9.804878048780489e-05,
      "loss": 1.6065,
      "step": 12
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7277543544769287,
      "learning_rate": 9.788617886178862e-05,
      "loss": 1.5293,
      "step": 13
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6385793685913086,
      "learning_rate": 9.772357723577236e-05,
      "loss": 1.2467,
      "step": 14
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.738784670829773,
      "learning_rate": 9.75609756097561e-05,
      "loss": 1.2666,
      "step": 15
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6526834964752197,
      "learning_rate": 9.739837398373984e-05,
      "loss": 1.3673,
      "step": 16
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6895115375518799,
      "learning_rate": 9.723577235772358e-05,
      "loss": 1.457,
      "step": 17
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6643384099006653,
      "learning_rate": 9.707317073170732e-05,
      "loss": 1.2423,
      "step": 18
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.650823175907135,
      "learning_rate": 9.691056910569106e-05,
      "loss": 1.4472,
      "step": 19
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5646463632583618,
      "learning_rate": 9.674796747967481e-05,
      "loss": 1.3397,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6632969379425049,
      "learning_rate": 9.658536585365854e-05,
      "loss": 1.5438,
      "step": 21
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5917642116546631,
      "learning_rate": 9.642276422764228e-05,
      "loss": 1.3458,
      "step": 22
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6882281303405762,
      "learning_rate": 9.626016260162603e-05,
      "loss": 1.2378,
      "step": 23
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6643629670143127,
      "learning_rate": 9.609756097560975e-05,
      "loss": 1.4592,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6394911408424377,
      "learning_rate": 9.59349593495935e-05,
      "loss": 1.2439,
      "step": 25
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6219387650489807,
      "learning_rate": 9.577235772357725e-05,
      "loss": 1.4826,
      "step": 26
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6518576741218567,
      "learning_rate": 9.560975609756097e-05,
      "loss": 1.4645,
      "step": 27
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6392241716384888,
      "learning_rate": 9.544715447154472e-05,
      "loss": 1.4271,
      "step": 28
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6501966714859009,
      "learning_rate": 9.528455284552846e-05,
      "loss": 1.3055,
      "step": 29
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5562293529510498,
      "learning_rate": 9.51219512195122e-05,
      "loss": 1.3151,
      "step": 30
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6508284211158752,
      "learning_rate": 9.495934959349594e-05,
      "loss": 1.5794,
      "step": 31
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5743926167488098,
      "learning_rate": 9.479674796747968e-05,
      "loss": 1.3256,
      "step": 32
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5422836542129517,
      "learning_rate": 9.463414634146342e-05,
      "loss": 1.2551,
      "step": 33
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6135895848274231,
      "learning_rate": 9.447154471544716e-05,
      "loss": 1.1229,
      "step": 34
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.584614098072052,
      "learning_rate": 9.43089430894309e-05,
      "loss": 1.3705,
      "step": 35
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.548236072063446,
      "learning_rate": 9.414634146341463e-05,
      "loss": 1.2084,
      "step": 36
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5403878688812256,
      "learning_rate": 9.398373983739837e-05,
      "loss": 1.2593,
      "step": 37
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8253616094589233,
      "learning_rate": 9.382113821138213e-05,
      "loss": 1.3616,
      "step": 38
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9050314426422119,
      "learning_rate": 9.365853658536587e-05,
      "loss": 1.2861,
      "step": 39
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5609120726585388,
      "learning_rate": 9.349593495934959e-05,
      "loss": 1.3973,
      "step": 40
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5464379787445068,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.2137,
      "step": 41
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6507397890090942,
      "learning_rate": 9.317073170731708e-05,
      "loss": 1.4261,
      "step": 42
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5542796850204468,
      "learning_rate": 9.300813008130082e-05,
      "loss": 1.1578,
      "step": 43
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5620958209037781,
      "learning_rate": 9.284552845528456e-05,
      "loss": 1.3533,
      "step": 44
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5988433957099915,
      "learning_rate": 9.26829268292683e-05,
      "loss": 1.3104,
      "step": 45
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6156195998191833,
      "learning_rate": 9.252032520325204e-05,
      "loss": 1.2617,
      "step": 46
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.719072699546814,
      "learning_rate": 9.235772357723578e-05,
      "loss": 1.3694,
      "step": 47
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5386471152305603,
      "learning_rate": 9.219512195121952e-05,
      "loss": 1.2871,
      "step": 48
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5087131261825562,
      "learning_rate": 9.203252032520325e-05,
      "loss": 1.3197,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6908032894134521,
      "learning_rate": 9.1869918699187e-05,
      "loss": 1.2806,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6564034223556519,
      "learning_rate": 9.170731707317075e-05,
      "loss": 1.3061,
      "step": 51
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6286119222640991,
      "learning_rate": 9.154471544715447e-05,
      "loss": 1.2627,
      "step": 52
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6581635475158691,
      "learning_rate": 9.138211382113821e-05,
      "loss": 1.3966,
      "step": 53
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5669249296188354,
      "learning_rate": 9.121951219512196e-05,
      "loss": 1.3214,
      "step": 54
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6881750822067261,
      "learning_rate": 9.105691056910569e-05,
      "loss": 1.2898,
      "step": 55
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5473026633262634,
      "learning_rate": 9.089430894308944e-05,
      "loss": 1.3795,
      "step": 56
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5297854542732239,
      "learning_rate": 9.073170731707318e-05,
      "loss": 1.2805,
      "step": 57
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.49123212695121765,
      "learning_rate": 9.05691056910569e-05,
      "loss": 1.16,
      "step": 58
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5563681721687317,
      "learning_rate": 9.040650406504066e-05,
      "loss": 1.3468,
      "step": 59
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7523199915885925,
      "learning_rate": 9.02439024390244e-05,
      "loss": 1.2977,
      "step": 60
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5152796506881714,
      "learning_rate": 9.008130081300812e-05,
      "loss": 1.1318,
      "step": 61
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.544002890586853,
      "learning_rate": 8.991869918699188e-05,
      "loss": 1.226,
      "step": 62
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6231495141983032,
      "learning_rate": 8.975609756097561e-05,
      "loss": 1.3425,
      "step": 63
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6768231391906738,
      "learning_rate": 8.959349593495935e-05,
      "loss": 1.2115,
      "step": 64
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5748189687728882,
      "learning_rate": 8.943089430894309e-05,
      "loss": 1.3995,
      "step": 65
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.597105860710144,
      "learning_rate": 8.926829268292683e-05,
      "loss": 1.399,
      "step": 66
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5448141098022461,
      "learning_rate": 8.910569105691058e-05,
      "loss": 1.1371,
      "step": 67
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6085965037345886,
      "learning_rate": 8.894308943089431e-05,
      "loss": 1.3198,
      "step": 68
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6282637715339661,
      "learning_rate": 8.878048780487805e-05,
      "loss": 1.209,
      "step": 69
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5990417003631592,
      "learning_rate": 8.86178861788618e-05,
      "loss": 1.2926,
      "step": 70
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5542348027229309,
      "learning_rate": 8.845528455284553e-05,
      "loss": 1.1062,
      "step": 71
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5459975004196167,
      "learning_rate": 8.829268292682928e-05,
      "loss": 1.4557,
      "step": 72
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5370736122131348,
      "learning_rate": 8.813008130081302e-05,
      "loss": 1.3962,
      "step": 73
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.612689197063446,
      "learning_rate": 8.796747967479674e-05,
      "loss": 1.3224,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6951398849487305,
      "learning_rate": 8.78048780487805e-05,
      "loss": 1.4873,
      "step": 75
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5295649766921997,
      "learning_rate": 8.764227642276423e-05,
      "loss": 1.3708,
      "step": 76
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.639380156993866,
      "learning_rate": 8.747967479674797e-05,
      "loss": 1.3842,
      "step": 77
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6651098132133484,
      "learning_rate": 8.731707317073171e-05,
      "loss": 1.3494,
      "step": 78
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.48855507373809814,
      "learning_rate": 8.715447154471545e-05,
      "loss": 1.2612,
      "step": 79
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5891953110694885,
      "learning_rate": 8.699186991869919e-05,
      "loss": 1.4276,
      "step": 80
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5714675784111023,
      "learning_rate": 8.682926829268293e-05,
      "loss": 1.2279,
      "step": 81
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.584551215171814,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.3015,
      "step": 82
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5524696707725525,
      "learning_rate": 8.650406504065041e-05,
      "loss": 1.2612,
      "step": 83
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5450222492218018,
      "learning_rate": 8.634146341463415e-05,
      "loss": 1.2143,
      "step": 84
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6503773331642151,
      "learning_rate": 8.61788617886179e-05,
      "loss": 1.4929,
      "step": 85
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5270754098892212,
      "learning_rate": 8.601626016260162e-05,
      "loss": 1.17,
      "step": 86
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.596122682094574,
      "learning_rate": 8.585365853658536e-05,
      "loss": 1.2629,
      "step": 87
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6987171173095703,
      "learning_rate": 8.569105691056912e-05,
      "loss": 1.393,
      "step": 88
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5593202114105225,
      "learning_rate": 8.552845528455284e-05,
      "loss": 1.1873,
      "step": 89
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5915197134017944,
      "learning_rate": 8.53658536585366e-05,
      "loss": 1.418,
      "step": 90
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.577746570110321,
      "learning_rate": 8.520325203252033e-05,
      "loss": 1.1529,
      "step": 91
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5915642976760864,
      "learning_rate": 8.504065040650407e-05,
      "loss": 1.3216,
      "step": 92
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6324462890625,
      "learning_rate": 8.487804878048781e-05,
      "loss": 1.2,
      "step": 93
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5466193556785583,
      "learning_rate": 8.471544715447155e-05,
      "loss": 1.3205,
      "step": 94
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6219903230667114,
      "learning_rate": 8.455284552845529e-05,
      "loss": 1.1126,
      "step": 95
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6140713095664978,
      "learning_rate": 8.439024390243903e-05,
      "loss": 1.4174,
      "step": 96
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5694624781608582,
      "learning_rate": 8.422764227642277e-05,
      "loss": 1.2155,
      "step": 97
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5953131318092346,
      "learning_rate": 8.406504065040652e-05,
      "loss": 1.2321,
      "step": 98
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.592572033405304,
      "learning_rate": 8.390243902439024e-05,
      "loss": 1.4686,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5274655222892761,
      "learning_rate": 8.373983739837398e-05,
      "loss": 1.2452,
      "step": 100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5314759016036987,
      "learning_rate": 8.357723577235774e-05,
      "loss": 1.1937,
      "step": 101
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.570746898651123,
      "learning_rate": 8.341463414634146e-05,
      "loss": 1.2808,
      "step": 102
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8377143144607544,
      "learning_rate": 8.325203252032521e-05,
      "loss": 1.2508,
      "step": 103
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4679543077945709,
      "learning_rate": 8.308943089430895e-05,
      "loss": 1.0657,
      "step": 104
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6343200206756592,
      "learning_rate": 8.292682926829268e-05,
      "loss": 1.4053,
      "step": 105
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6451442241668701,
      "learning_rate": 8.276422764227643e-05,
      "loss": 1.4354,
      "step": 106
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6408475041389465,
      "learning_rate": 8.260162601626017e-05,
      "loss": 1.4265,
      "step": 107
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5527917146682739,
      "learning_rate": 8.243902439024391e-05,
      "loss": 1.2082,
      "step": 108
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.530204176902771,
      "learning_rate": 8.227642276422765e-05,
      "loss": 1.2338,
      "step": 109
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5953561067581177,
      "learning_rate": 8.211382113821139e-05,
      "loss": 1.5119,
      "step": 110
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6458445191383362,
      "learning_rate": 8.195121951219513e-05,
      "loss": 1.1803,
      "step": 111
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5106032490730286,
      "learning_rate": 8.178861788617886e-05,
      "loss": 1.1229,
      "step": 112
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6302518844604492,
      "learning_rate": 8.16260162601626e-05,
      "loss": 1.1865,
      "step": 113
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5690764784812927,
      "learning_rate": 8.146341463414634e-05,
      "loss": 1.2039,
      "step": 114
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5876096487045288,
      "learning_rate": 8.130081300813008e-05,
      "loss": 1.4479,
      "step": 115
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6127801537513733,
      "learning_rate": 8.113821138211382e-05,
      "loss": 1.3122,
      "step": 116
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5718587636947632,
      "learning_rate": 8.097560975609757e-05,
      "loss": 1.2828,
      "step": 117
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6121511459350586,
      "learning_rate": 8.08130081300813e-05,
      "loss": 1.2765,
      "step": 118
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7616240978240967,
      "learning_rate": 8.065040650406505e-05,
      "loss": 1.2686,
      "step": 119
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6663839221000671,
      "learning_rate": 8.048780487804879e-05,
      "loss": 1.2667,
      "step": 120
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5809702277183533,
      "learning_rate": 8.032520325203252e-05,
      "loss": 1.2149,
      "step": 121
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6582948565483093,
      "learning_rate": 8.016260162601627e-05,
      "loss": 1.3174,
      "step": 122
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5829148292541504,
      "learning_rate": 8e-05,
      "loss": 1.1512,
      "step": 123
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6512185335159302,
      "learning_rate": 7.983739837398375e-05,
      "loss": 1.2871,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6522266864776611,
      "learning_rate": 7.967479674796748e-05,
      "loss": 1.1823,
      "step": 125
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6056987643241882,
      "learning_rate": 7.951219512195122e-05,
      "loss": 1.2538,
      "step": 126
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5542613863945007,
      "learning_rate": 7.934959349593496e-05,
      "loss": 1.2726,
      "step": 127
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6742851138114929,
      "learning_rate": 7.91869918699187e-05,
      "loss": 1.3155,
      "step": 128
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7141271233558655,
      "learning_rate": 7.902439024390244e-05,
      "loss": 1.2172,
      "step": 129
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7262750864028931,
      "learning_rate": 7.886178861788618e-05,
      "loss": 1.3074,
      "step": 130
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5914454460144043,
      "learning_rate": 7.869918699186992e-05,
      "loss": 1.2844,
      "step": 131
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6421563029289246,
      "learning_rate": 7.853658536585367e-05,
      "loss": 1.2114,
      "step": 132
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5500821471214294,
      "learning_rate": 7.83739837398374e-05,
      "loss": 1.1316,
      "step": 133
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.609657883644104,
      "learning_rate": 7.821138211382114e-05,
      "loss": 1.2113,
      "step": 134
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6188536286354065,
      "learning_rate": 7.804878048780489e-05,
      "loss": 1.1125,
      "step": 135
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6686450839042664,
      "learning_rate": 7.788617886178861e-05,
      "loss": 1.3174,
      "step": 136
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5800057053565979,
      "learning_rate": 7.772357723577237e-05,
      "loss": 1.3016,
      "step": 137
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5756174325942993,
      "learning_rate": 7.75609756097561e-05,
      "loss": 1.3335,
      "step": 138
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5452691316604614,
      "learning_rate": 7.739837398373983e-05,
      "loss": 1.3368,
      "step": 139
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6890747547149658,
      "learning_rate": 7.723577235772358e-05,
      "loss": 1.3184,
      "step": 140
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.57225501537323,
      "learning_rate": 7.707317073170732e-05,
      "loss": 1.1993,
      "step": 141
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6803627014160156,
      "learning_rate": 7.691056910569106e-05,
      "loss": 1.3245,
      "step": 142
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5659903287887573,
      "learning_rate": 7.67479674796748e-05,
      "loss": 1.1342,
      "step": 143
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5949404239654541,
      "learning_rate": 7.658536585365854e-05,
      "loss": 1.204,
      "step": 144
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6512598991394043,
      "learning_rate": 7.642276422764229e-05,
      "loss": 1.5274,
      "step": 145
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7384660840034485,
      "learning_rate": 7.626016260162602e-05,
      "loss": 1.2281,
      "step": 146
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6564880609512329,
      "learning_rate": 7.609756097560976e-05,
      "loss": 1.181,
      "step": 147
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7359193563461304,
      "learning_rate": 7.593495934959351e-05,
      "loss": 1.3005,
      "step": 148
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6252042651176453,
      "learning_rate": 7.577235772357723e-05,
      "loss": 1.4634,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7631053328514099,
      "learning_rate": 7.560975609756099e-05,
      "loss": 1.3994,
      "step": 150
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6986962556838989,
      "learning_rate": 7.544715447154472e-05,
      "loss": 1.2537,
      "step": 151
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6075642108917236,
      "learning_rate": 7.528455284552845e-05,
      "loss": 1.3714,
      "step": 152
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6266046166419983,
      "learning_rate": 7.51219512195122e-05,
      "loss": 1.2739,
      "step": 153
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5648692846298218,
      "learning_rate": 7.495934959349594e-05,
      "loss": 1.1532,
      "step": 154
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5742453336715698,
      "learning_rate": 7.479674796747968e-05,
      "loss": 1.339,
      "step": 155
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6407999396324158,
      "learning_rate": 7.463414634146342e-05,
      "loss": 1.2164,
      "step": 156
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6072515249252319,
      "learning_rate": 7.447154471544716e-05,
      "loss": 1.2415,
      "step": 157
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.61440110206604,
      "learning_rate": 7.43089430894309e-05,
      "loss": 1.3001,
      "step": 158
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7390683889389038,
      "learning_rate": 7.414634146341464e-05,
      "loss": 1.3259,
      "step": 159
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6517521142959595,
      "learning_rate": 7.398373983739838e-05,
      "loss": 1.3192,
      "step": 160
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6988760828971863,
      "learning_rate": 7.382113821138211e-05,
      "loss": 1.4404,
      "step": 161
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6632258892059326,
      "learning_rate": 7.365853658536585e-05,
      "loss": 1.2399,
      "step": 162
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6257189512252808,
      "learning_rate": 7.34959349593496e-05,
      "loss": 1.2032,
      "step": 163
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7276090383529663,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.3383,
      "step": 164
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.658758819103241,
      "learning_rate": 7.317073170731707e-05,
      "loss": 1.3104,
      "step": 165
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6173214316368103,
      "learning_rate": 7.300813008130082e-05,
      "loss": 1.0573,
      "step": 166
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5503921508789062,
      "learning_rate": 7.284552845528456e-05,
      "loss": 1.1775,
      "step": 167
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7709712982177734,
      "learning_rate": 7.26829268292683e-05,
      "loss": 1.3565,
      "step": 168
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5861253142356873,
      "learning_rate": 7.252032520325204e-05,
      "loss": 1.1906,
      "step": 169
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5870308876037598,
      "learning_rate": 7.235772357723578e-05,
      "loss": 1.2169,
      "step": 170
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7330202460289001,
      "learning_rate": 7.219512195121952e-05,
      "loss": 1.3022,
      "step": 171
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7294589877128601,
      "learning_rate": 7.203252032520326e-05,
      "loss": 1.4051,
      "step": 172
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5549353361129761,
      "learning_rate": 7.1869918699187e-05,
      "loss": 1.1262,
      "step": 173
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6872254014015198,
      "learning_rate": 7.170731707317073e-05,
      "loss": 1.276,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5867165923118591,
      "learning_rate": 7.154471544715447e-05,
      "loss": 1.0714,
      "step": 175
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6014262437820435,
      "learning_rate": 7.138211382113821e-05,
      "loss": 1.4271,
      "step": 176
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6867149472236633,
      "learning_rate": 7.121951219512195e-05,
      "loss": 1.4392,
      "step": 177
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5338932871818542,
      "learning_rate": 7.105691056910569e-05,
      "loss": 1.169,
      "step": 178
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6093665361404419,
      "learning_rate": 7.089430894308944e-05,
      "loss": 1.2758,
      "step": 179
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5186262130737305,
      "learning_rate": 7.073170731707317e-05,
      "loss": 1.1784,
      "step": 180
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5884575843811035,
      "learning_rate": 7.056910569105691e-05,
      "loss": 1.4024,
      "step": 181
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6177799701690674,
      "learning_rate": 7.040650406504066e-05,
      "loss": 1.2727,
      "step": 182
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6310541033744812,
      "learning_rate": 7.024390243902439e-05,
      "loss": 1.3503,
      "step": 183
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5758781433105469,
      "learning_rate": 7.008130081300814e-05,
      "loss": 1.4238,
      "step": 184
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7419762015342712,
      "learning_rate": 6.991869918699188e-05,
      "loss": 1.407,
      "step": 185
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6069523096084595,
      "learning_rate": 6.97560975609756e-05,
      "loss": 1.1352,
      "step": 186
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8692017793655396,
      "learning_rate": 6.959349593495935e-05,
      "loss": 1.3163,
      "step": 187
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.602403998374939,
      "learning_rate": 6.94308943089431e-05,
      "loss": 1.0393,
      "step": 188
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5346267819404602,
      "learning_rate": 6.926829268292683e-05,
      "loss": 1.043,
      "step": 189
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5802115201950073,
      "learning_rate": 6.910569105691057e-05,
      "loss": 1.2396,
      "step": 190
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6421557664871216,
      "learning_rate": 6.894308943089431e-05,
      "loss": 1.1747,
      "step": 191
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6143375635147095,
      "learning_rate": 6.878048780487805e-05,
      "loss": 1.2481,
      "step": 192
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5890875458717346,
      "learning_rate": 6.861788617886179e-05,
      "loss": 1.2289,
      "step": 193
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7373915910720825,
      "learning_rate": 6.845528455284553e-05,
      "loss": 1.4938,
      "step": 194
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5974326729774475,
      "learning_rate": 6.829268292682928e-05,
      "loss": 1.2671,
      "step": 195
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5680444240570068,
      "learning_rate": 6.8130081300813e-05,
      "loss": 1.0563,
      "step": 196
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6289734244346619,
      "learning_rate": 6.796747967479676e-05,
      "loss": 1.1559,
      "step": 197
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6801060438156128,
      "learning_rate": 6.78048780487805e-05,
      "loss": 1.249,
      "step": 198
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5553024411201477,
      "learning_rate": 6.764227642276422e-05,
      "loss": 1.0967,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7075248956680298,
      "learning_rate": 6.747967479674798e-05,
      "loss": 1.2681,
      "step": 200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5687246918678284,
      "learning_rate": 6.731707317073171e-05,
      "loss": 1.1759,
      "step": 201
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5929650664329529,
      "learning_rate": 6.715447154471545e-05,
      "loss": 1.1103,
      "step": 202
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5183151364326477,
      "learning_rate": 6.699186991869919e-05,
      "loss": 1.1543,
      "step": 203
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6365258693695068,
      "learning_rate": 6.682926829268293e-05,
      "loss": 1.1986,
      "step": 204
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5888717174530029,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.1159,
      "step": 205
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6091896891593933,
      "learning_rate": 6.650406504065041e-05,
      "loss": 1.2659,
      "step": 206
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6064072251319885,
      "learning_rate": 6.634146341463415e-05,
      "loss": 1.3949,
      "step": 207
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5553269982337952,
      "learning_rate": 6.617886178861789e-05,
      "loss": 1.0395,
      "step": 208
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6357668042182922,
      "learning_rate": 6.601626016260163e-05,
      "loss": 1.2671,
      "step": 209
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5017789006233215,
      "learning_rate": 6.585365853658538e-05,
      "loss": 1.0161,
      "step": 210
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6161097288131714,
      "learning_rate": 6.56910569105691e-05,
      "loss": 1.2717,
      "step": 211
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5246614813804626,
      "learning_rate": 6.552845528455284e-05,
      "loss": 1.2852,
      "step": 212
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5811266303062439,
      "learning_rate": 6.53658536585366e-05,
      "loss": 1.1817,
      "step": 213
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6266393661499023,
      "learning_rate": 6.520325203252032e-05,
      "loss": 1.1315,
      "step": 214
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6001920700073242,
      "learning_rate": 6.504065040650407e-05,
      "loss": 1.2943,
      "step": 215
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6727237105369568,
      "learning_rate": 6.487804878048781e-05,
      "loss": 1.2618,
      "step": 216
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5512345433235168,
      "learning_rate": 6.471544715447154e-05,
      "loss": 1.1518,
      "step": 217
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5624498128890991,
      "learning_rate": 6.455284552845529e-05,
      "loss": 1.3025,
      "step": 218
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5259178876876831,
      "learning_rate": 6.439024390243903e-05,
      "loss": 1.0034,
      "step": 219
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6117075085639954,
      "learning_rate": 6.422764227642277e-05,
      "loss": 1.3159,
      "step": 220
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7121913433074951,
      "learning_rate": 6.406504065040651e-05,
      "loss": 1.474,
      "step": 221
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6187475323677063,
      "learning_rate": 6.390243902439025e-05,
      "loss": 1.0588,
      "step": 222
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5895246267318726,
      "learning_rate": 6.373983739837398e-05,
      "loss": 1.2557,
      "step": 223
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6115685701370239,
      "learning_rate": 6.357723577235772e-05,
      "loss": 1.2058,
      "step": 224
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6017666459083557,
      "learning_rate": 6.341463414634146e-05,
      "loss": 1.3414,
      "step": 225
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6520211100578308,
      "learning_rate": 6.325203252032522e-05,
      "loss": 1.4838,
      "step": 226
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5408685207366943,
      "learning_rate": 6.308943089430894e-05,
      "loss": 1.1864,
      "step": 227
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6175771355628967,
      "learning_rate": 6.292682926829268e-05,
      "loss": 1.2622,
      "step": 228
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.639784574508667,
      "learning_rate": 6.276422764227643e-05,
      "loss": 1.2164,
      "step": 229
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5511655807495117,
      "learning_rate": 6.260162601626016e-05,
      "loss": 1.2325,
      "step": 230
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6149067282676697,
      "learning_rate": 6.243902439024391e-05,
      "loss": 1.3486,
      "step": 231
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.572593092918396,
      "learning_rate": 6.227642276422765e-05,
      "loss": 1.208,
      "step": 232
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6460756063461304,
      "learning_rate": 6.211382113821137e-05,
      "loss": 1.2512,
      "step": 233
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6060636639595032,
      "learning_rate": 6.195121951219513e-05,
      "loss": 1.1585,
      "step": 234
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5944042205810547,
      "learning_rate": 6.178861788617887e-05,
      "loss": 1.236,
      "step": 235
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6936793327331543,
      "learning_rate": 6.16260162601626e-05,
      "loss": 1.3698,
      "step": 236
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6487632393836975,
      "learning_rate": 6.146341463414634e-05,
      "loss": 1.2188,
      "step": 237
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5294262766838074,
      "learning_rate": 6.130081300813008e-05,
      "loss": 1.0413,
      "step": 238
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5472660660743713,
      "learning_rate": 6.113821138211382e-05,
      "loss": 1.005,
      "step": 239
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6575759053230286,
      "learning_rate": 6.097560975609756e-05,
      "loss": 1.2429,
      "step": 240
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5867732167243958,
      "learning_rate": 6.081300813008131e-05,
      "loss": 1.2596,
      "step": 241
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5875574350357056,
      "learning_rate": 6.065040650406504e-05,
      "loss": 1.0854,
      "step": 242
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.676263689994812,
      "learning_rate": 6.0487804878048785e-05,
      "loss": 1.3205,
      "step": 243
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5848759412765503,
      "learning_rate": 6.0325203252032524e-05,
      "loss": 1.0078,
      "step": 244
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6677606105804443,
      "learning_rate": 6.016260162601627e-05,
      "loss": 1.388,
      "step": 245
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7104223966598511,
      "learning_rate": 6e-05,
      "loss": 1.2982,
      "step": 246
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6098873615264893,
      "learning_rate": 5.983739837398375e-05,
      "loss": 1.3112,
      "step": 247
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5788127183914185,
      "learning_rate": 5.9674796747967486e-05,
      "loss": 1.3462,
      "step": 248
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5756991505622864,
      "learning_rate": 5.951219512195122e-05,
      "loss": 1.1654,
      "step": 249
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6393716931343079,
      "learning_rate": 5.9349593495934964e-05,
      "loss": 1.339,
      "step": 250
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5919890403747559,
      "learning_rate": 5.91869918699187e-05,
      "loss": 1.3697,
      "step": 251
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6335658431053162,
      "learning_rate": 5.902439024390244e-05,
      "loss": 1.0332,
      "step": 252
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5848334431648254,
      "learning_rate": 5.886178861788618e-05,
      "loss": 1.3411,
      "step": 253
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5658566355705261,
      "learning_rate": 5.869918699186993e-05,
      "loss": 1.239,
      "step": 254
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5670969486236572,
      "learning_rate": 5.853658536585366e-05,
      "loss": 1.1283,
      "step": 255
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5434495806694031,
      "learning_rate": 5.83739837398374e-05,
      "loss": 1.2206,
      "step": 256
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6106528043746948,
      "learning_rate": 5.8211382113821144e-05,
      "loss": 1.1983,
      "step": 257
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6360364556312561,
      "learning_rate": 5.8048780487804876e-05,
      "loss": 1.3374,
      "step": 258
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5377088785171509,
      "learning_rate": 5.788617886178862e-05,
      "loss": 1.2251,
      "step": 259
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.551970362663269,
      "learning_rate": 5.772357723577236e-05,
      "loss": 1.1504,
      "step": 260
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6987795233726501,
      "learning_rate": 5.756097560975609e-05,
      "loss": 1.2099,
      "step": 261
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5603809952735901,
      "learning_rate": 5.739837398373984e-05,
      "loss": 1.2482,
      "step": 262
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5703409910202026,
      "learning_rate": 5.7235772357723584e-05,
      "loss": 1.0964,
      "step": 263
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6553710103034973,
      "learning_rate": 5.7073170731707317e-05,
      "loss": 1.1452,
      "step": 264
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5934346318244934,
      "learning_rate": 5.6910569105691056e-05,
      "loss": 1.157,
      "step": 265
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.623037576675415,
      "learning_rate": 5.67479674796748e-05,
      "loss": 1.256,
      "step": 266
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6053218841552734,
      "learning_rate": 5.6585365853658533e-05,
      "loss": 1.2787,
      "step": 267
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5706206560134888,
      "learning_rate": 5.642276422764228e-05,
      "loss": 1.3064,
      "step": 268
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.609350860118866,
      "learning_rate": 5.626016260162602e-05,
      "loss": 1.4272,
      "step": 269
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6242534518241882,
      "learning_rate": 5.6097560975609764e-05,
      "loss": 1.1609,
      "step": 270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5588169693946838,
      "learning_rate": 5.5934959349593496e-05,
      "loss": 1.0623,
      "step": 271
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5875682830810547,
      "learning_rate": 5.577235772357724e-05,
      "loss": 1.1328,
      "step": 272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5508478283882141,
      "learning_rate": 5.560975609756098e-05,
      "loss": 1.17,
      "step": 273
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5653434991836548,
      "learning_rate": 5.544715447154471e-05,
      "loss": 1.2307,
      "step": 274
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5598006248474121,
      "learning_rate": 5.528455284552846e-05,
      "loss": 1.3079,
      "step": 275
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5367336869239807,
      "learning_rate": 5.5121951219512205e-05,
      "loss": 1.1393,
      "step": 276
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5393407344818115,
      "learning_rate": 5.495934959349594e-05,
      "loss": 1.2599,
      "step": 277
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5671065449714661,
      "learning_rate": 5.4796747967479676e-05,
      "loss": 1.2057,
      "step": 278
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7143087983131409,
      "learning_rate": 5.463414634146342e-05,
      "loss": 1.2122,
      "step": 279
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5496362447738647,
      "learning_rate": 5.4471544715447154e-05,
      "loss": 1.0523,
      "step": 280
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5251711010932922,
      "learning_rate": 5.43089430894309e-05,
      "loss": 1.2111,
      "step": 281
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5740899443626404,
      "learning_rate": 5.414634146341464e-05,
      "loss": 1.087,
      "step": 282
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6250092387199402,
      "learning_rate": 5.398373983739837e-05,
      "loss": 1.2772,
      "step": 283
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5189806222915649,
      "learning_rate": 5.3821138211382116e-05,
      "loss": 0.9974,
      "step": 284
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5587503910064697,
      "learning_rate": 5.365853658536586e-05,
      "loss": 1.1008,
      "step": 285
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6446901559829712,
      "learning_rate": 5.3495934959349594e-05,
      "loss": 1.1717,
      "step": 286
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5910882353782654,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.359,
      "step": 287
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5249620676040649,
      "learning_rate": 5.317073170731708e-05,
      "loss": 1.0573,
      "step": 288
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6405501365661621,
      "learning_rate": 5.300813008130081e-05,
      "loss": 1.2277,
      "step": 289
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5738648176193237,
      "learning_rate": 5.284552845528456e-05,
      "loss": 1.2282,
      "step": 290
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6335141658782959,
      "learning_rate": 5.2682926829268296e-05,
      "loss": 1.2264,
      "step": 291
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6149213910102844,
      "learning_rate": 5.252032520325203e-05,
      "loss": 1.37,
      "step": 292
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6203625202178955,
      "learning_rate": 5.2357723577235774e-05,
      "loss": 1.1942,
      "step": 293
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.57346111536026,
      "learning_rate": 5.219512195121952e-05,
      "loss": 1.4205,
      "step": 294
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.590073823928833,
      "learning_rate": 5.203252032520326e-05,
      "loss": 1.1708,
      "step": 295
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6527993679046631,
      "learning_rate": 5.186991869918699e-05,
      "loss": 1.2853,
      "step": 296
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5916646122932434,
      "learning_rate": 5.1707317073170736e-05,
      "loss": 1.2077,
      "step": 297
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5275101661682129,
      "learning_rate": 5.154471544715448e-05,
      "loss": 1.0367,
      "step": 298
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0104056596755981,
      "learning_rate": 5.1382113821138214e-05,
      "loss": 1.3434,
      "step": 299
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6295941472053528,
      "learning_rate": 5.121951219512195e-05,
      "loss": 1.1393,
      "step": 300
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6079818606376648,
      "learning_rate": 5.10569105691057e-05,
      "loss": 1.1624,
      "step": 301
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5940336585044861,
      "learning_rate": 5.089430894308943e-05,
      "loss": 1.2023,
      "step": 302
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5591450333595276,
      "learning_rate": 5.073170731707318e-05,
      "loss": 0.9951,
      "step": 303
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6434249877929688,
      "learning_rate": 5.0569105691056916e-05,
      "loss": 1.1714,
      "step": 304
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.563266932964325,
      "learning_rate": 5.040650406504065e-05,
      "loss": 1.065,
      "step": 305
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5658858418464661,
      "learning_rate": 5.0243902439024394e-05,
      "loss": 1.3254,
      "step": 306
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6201404929161072,
      "learning_rate": 5.008130081300813e-05,
      "loss": 1.1863,
      "step": 307
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5981325507164001,
      "learning_rate": 4.991869918699187e-05,
      "loss": 1.1767,
      "step": 308
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7141116857528687,
      "learning_rate": 4.975609756097561e-05,
      "loss": 1.3639,
      "step": 309
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6775573492050171,
      "learning_rate": 4.959349593495935e-05,
      "loss": 1.1434,
      "step": 310
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5852282047271729,
      "learning_rate": 4.9430894308943096e-05,
      "loss": 1.1112,
      "step": 311
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5951559543609619,
      "learning_rate": 4.926829268292683e-05,
      "loss": 1.0427,
      "step": 312
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5275505781173706,
      "learning_rate": 4.910569105691057e-05,
      "loss": 1.2065,
      "step": 313
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6332387924194336,
      "learning_rate": 4.894308943089431e-05,
      "loss": 1.1904,
      "step": 314
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5775592923164368,
      "learning_rate": 4.878048780487805e-05,
      "loss": 1.2195,
      "step": 315
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5335661172866821,
      "learning_rate": 4.861788617886179e-05,
      "loss": 1.2547,
      "step": 316
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7407934665679932,
      "learning_rate": 4.845528455284553e-05,
      "loss": 1.2645,
      "step": 317
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5755009055137634,
      "learning_rate": 4.829268292682927e-05,
      "loss": 1.0483,
      "step": 318
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6151820421218872,
      "learning_rate": 4.8130081300813014e-05,
      "loss": 1.3269,
      "step": 319
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6094321608543396,
      "learning_rate": 4.796747967479675e-05,
      "loss": 1.3278,
      "step": 320
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6792434453964233,
      "learning_rate": 4.7804878048780485e-05,
      "loss": 1.3116,
      "step": 321
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6384254097938538,
      "learning_rate": 4.764227642276423e-05,
      "loss": 1.3698,
      "step": 322
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6277899146080017,
      "learning_rate": 4.747967479674797e-05,
      "loss": 1.4095,
      "step": 323
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6357695460319519,
      "learning_rate": 4.731707317073171e-05,
      "loss": 1.1906,
      "step": 324
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5955873727798462,
      "learning_rate": 4.715447154471545e-05,
      "loss": 1.213,
      "step": 325
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6685850024223328,
      "learning_rate": 4.699186991869919e-05,
      "loss": 1.4138,
      "step": 326
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6232776045799255,
      "learning_rate": 4.682926829268293e-05,
      "loss": 1.2347,
      "step": 327
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5274770855903625,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.2354,
      "step": 328
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6573265790939331,
      "learning_rate": 4.650406504065041e-05,
      "loss": 1.2307,
      "step": 329
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6100287437438965,
      "learning_rate": 4.634146341463415e-05,
      "loss": 1.1336,
      "step": 330
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5450040698051453,
      "learning_rate": 4.617886178861789e-05,
      "loss": 1.1239,
      "step": 331
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.574665904045105,
      "learning_rate": 4.601626016260163e-05,
      "loss": 1.3981,
      "step": 332
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5267447233200073,
      "learning_rate": 4.585365853658537e-05,
      "loss": 1.1355,
      "step": 333
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5912678241729736,
      "learning_rate": 4.5691056910569105e-05,
      "loss": 1.2012,
      "step": 334
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5953156352043152,
      "learning_rate": 4.5528455284552844e-05,
      "loss": 1.1085,
      "step": 335
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5205215811729431,
      "learning_rate": 4.536585365853659e-05,
      "loss": 1.0978,
      "step": 336
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.570984959602356,
      "learning_rate": 4.520325203252033e-05,
      "loss": 1.0831,
      "step": 337
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7039902210235596,
      "learning_rate": 4.504065040650406e-05,
      "loss": 1.3632,
      "step": 338
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5946062803268433,
      "learning_rate": 4.487804878048781e-05,
      "loss": 1.2883,
      "step": 339
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5400751233100891,
      "learning_rate": 4.4715447154471546e-05,
      "loss": 1.1256,
      "step": 340
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5688837766647339,
      "learning_rate": 4.455284552845529e-05,
      "loss": 0.9212,
      "step": 341
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5751178860664368,
      "learning_rate": 4.4390243902439024e-05,
      "loss": 1.2268,
      "step": 342
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5511839985847473,
      "learning_rate": 4.422764227642276e-05,
      "loss": 1.1729,
      "step": 343
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.629936695098877,
      "learning_rate": 4.406504065040651e-05,
      "loss": 1.2306,
      "step": 344
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5898679494857788,
      "learning_rate": 4.390243902439025e-05,
      "loss": 1.3316,
      "step": 345
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5847095847129822,
      "learning_rate": 4.373983739837399e-05,
      "loss": 1.2169,
      "step": 346
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6047746539115906,
      "learning_rate": 4.3577235772357726e-05,
      "loss": 1.2059,
      "step": 347
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6273103952407837,
      "learning_rate": 4.3414634146341465e-05,
      "loss": 1.2413,
      "step": 348
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6296385526657104,
      "learning_rate": 4.3252032520325204e-05,
      "loss": 1.2447,
      "step": 349
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.64070063829422,
      "learning_rate": 4.308943089430895e-05,
      "loss": 1.2819,
      "step": 350
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5843188762664795,
      "learning_rate": 4.292682926829268e-05,
      "loss": 1.067,
      "step": 351
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5703254342079163,
      "learning_rate": 4.276422764227642e-05,
      "loss": 1.3029,
      "step": 352
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5968242883682251,
      "learning_rate": 4.2601626016260166e-05,
      "loss": 1.0391,
      "step": 353
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6252856254577637,
      "learning_rate": 4.2439024390243905e-05,
      "loss": 1.1284,
      "step": 354
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5996291041374207,
      "learning_rate": 4.2276422764227644e-05,
      "loss": 1.4647,
      "step": 355
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5687545537948608,
      "learning_rate": 4.211382113821138e-05,
      "loss": 1.2907,
      "step": 356
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5543563961982727,
      "learning_rate": 4.195121951219512e-05,
      "loss": 1.2777,
      "step": 357
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5838420987129211,
      "learning_rate": 4.178861788617887e-05,
      "loss": 1.1648,
      "step": 358
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5892930030822754,
      "learning_rate": 4.162601626016261e-05,
      "loss": 1.0655,
      "step": 359
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5569360256195068,
      "learning_rate": 4.146341463414634e-05,
      "loss": 1.0898,
      "step": 360
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5730072855949402,
      "learning_rate": 4.1300813008130085e-05,
      "loss": 1.415,
      "step": 361
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6080520153045654,
      "learning_rate": 4.1138211382113824e-05,
      "loss": 1.0377,
      "step": 362
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7698791027069092,
      "learning_rate": 4.097560975609756e-05,
      "loss": 1.4893,
      "step": 363
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6368225812911987,
      "learning_rate": 4.08130081300813e-05,
      "loss": 1.23,
      "step": 364
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5506315231323242,
      "learning_rate": 4.065040650406504e-05,
      "loss": 1.1966,
      "step": 365
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5113133192062378,
      "learning_rate": 4.0487804878048786e-05,
      "loss": 1.0332,
      "step": 366
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5762972831726074,
      "learning_rate": 4.0325203252032525e-05,
      "loss": 1.0264,
      "step": 367
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6999551057815552,
      "learning_rate": 4.016260162601626e-05,
      "loss": 1.1949,
      "step": 368
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6079989075660706,
      "learning_rate": 4e-05,
      "loss": 1.1831,
      "step": 369
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6212978363037109,
      "learning_rate": 3.983739837398374e-05,
      "loss": 1.2168,
      "step": 370
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5500436425209045,
      "learning_rate": 3.967479674796748e-05,
      "loss": 1.2403,
      "step": 371
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5649189352989197,
      "learning_rate": 3.951219512195122e-05,
      "loss": 1.2772,
      "step": 372
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5377671718597412,
      "learning_rate": 3.934959349593496e-05,
      "loss": 1.2629,
      "step": 373
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5045995116233826,
      "learning_rate": 3.91869918699187e-05,
      "loss": 1.1753,
      "step": 374
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6102975010871887,
      "learning_rate": 3.9024390243902444e-05,
      "loss": 1.0947,
      "step": 375
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5847062468528748,
      "learning_rate": 3.886178861788618e-05,
      "loss": 1.1313,
      "step": 376
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5716582536697388,
      "learning_rate": 3.8699186991869915e-05,
      "loss": 1.1326,
      "step": 377
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6156095266342163,
      "learning_rate": 3.853658536585366e-05,
      "loss": 1.2887,
      "step": 378
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5589428544044495,
      "learning_rate": 3.83739837398374e-05,
      "loss": 1.2202,
      "step": 379
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5391108393669128,
      "learning_rate": 3.8211382113821145e-05,
      "loss": 1.2592,
      "step": 380
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5955345034599304,
      "learning_rate": 3.804878048780488e-05,
      "loss": 1.2073,
      "step": 381
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6365709900856018,
      "learning_rate": 3.788617886178862e-05,
      "loss": 1.4708,
      "step": 382
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5494793653488159,
      "learning_rate": 3.772357723577236e-05,
      "loss": 1.3313,
      "step": 383
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5509845614433289,
      "learning_rate": 3.75609756097561e-05,
      "loss": 1.3773,
      "step": 384
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6802929639816284,
      "learning_rate": 3.739837398373984e-05,
      "loss": 1.3941,
      "step": 385
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5969604253768921,
      "learning_rate": 3.723577235772358e-05,
      "loss": 1.0744,
      "step": 386
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5551146268844604,
      "learning_rate": 3.707317073170732e-05,
      "loss": 1.1055,
      "step": 387
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4873504936695099,
      "learning_rate": 3.691056910569106e-05,
      "loss": 1.0115,
      "step": 388
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5367836356163025,
      "learning_rate": 3.67479674796748e-05,
      "loss": 1.1972,
      "step": 389
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5798401236534119,
      "learning_rate": 3.6585365853658535e-05,
      "loss": 1.0448,
      "step": 390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5646956562995911,
      "learning_rate": 3.642276422764228e-05,
      "loss": 1.278,
      "step": 391
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6591240167617798,
      "learning_rate": 3.626016260162602e-05,
      "loss": 1.381,
      "step": 392
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6057823896408081,
      "learning_rate": 3.609756097560976e-05,
      "loss": 1.1091,
      "step": 393
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5173417925834656,
      "learning_rate": 3.59349593495935e-05,
      "loss": 1.0608,
      "step": 394
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5778465270996094,
      "learning_rate": 3.577235772357724e-05,
      "loss": 1.3809,
      "step": 395
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.591874897480011,
      "learning_rate": 3.5609756097560976e-05,
      "loss": 1.0554,
      "step": 396
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5983489751815796,
      "learning_rate": 3.544715447154472e-05,
      "loss": 1.2953,
      "step": 397
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6200058460235596,
      "learning_rate": 3.5284552845528454e-05,
      "loss": 1.3381,
      "step": 398
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6416685581207275,
      "learning_rate": 3.512195121951219e-05,
      "loss": 1.2902,
      "step": 399
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.551964521408081,
      "learning_rate": 3.495934959349594e-05,
      "loss": 1.1623,
      "step": 400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5433493256568909,
      "learning_rate": 3.479674796747968e-05,
      "loss": 1.1798,
      "step": 401
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6368557214736938,
      "learning_rate": 3.4634146341463416e-05,
      "loss": 1.2985,
      "step": 402
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5949450135231018,
      "learning_rate": 3.4471544715447155e-05,
      "loss": 1.0199,
      "step": 403
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5193494558334351,
      "learning_rate": 3.4308943089430894e-05,
      "loss": 1.1352,
      "step": 404
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5551422834396362,
      "learning_rate": 3.414634146341464e-05,
      "loss": 1.3253,
      "step": 405
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5929396748542786,
      "learning_rate": 3.398373983739838e-05,
      "loss": 1.1345,
      "step": 406
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5794588923454285,
      "learning_rate": 3.382113821138211e-05,
      "loss": 1.2315,
      "step": 407
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5553157925605774,
      "learning_rate": 3.365853658536586e-05,
      "loss": 1.1553,
      "step": 408
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6275562644004822,
      "learning_rate": 3.3495934959349596e-05,
      "loss": 1.2523,
      "step": 409
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6451495885848999,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.1546,
      "step": 410
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6557435393333435,
      "learning_rate": 3.3170731707317074e-05,
      "loss": 1.2194,
      "step": 411
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6255144476890564,
      "learning_rate": 3.300813008130081e-05,
      "loss": 1.5045,
      "step": 412
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5750375986099243,
      "learning_rate": 3.284552845528455e-05,
      "loss": 1.1356,
      "step": 413
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.659187912940979,
      "learning_rate": 3.26829268292683e-05,
      "loss": 1.3908,
      "step": 414
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5419296026229858,
      "learning_rate": 3.2520325203252037e-05,
      "loss": 1.0973,
      "step": 415
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6904046535491943,
      "learning_rate": 3.235772357723577e-05,
      "loss": 1.4903,
      "step": 416
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7058510184288025,
      "learning_rate": 3.2195121951219514e-05,
      "loss": 1.2199,
      "step": 417
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6852660179138184,
      "learning_rate": 3.2032520325203253e-05,
      "loss": 1.3541,
      "step": 418
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.49797096848487854,
      "learning_rate": 3.186991869918699e-05,
      "loss": 1.149,
      "step": 419
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.635815441608429,
      "learning_rate": 3.170731707317073e-05,
      "loss": 1.1086,
      "step": 420
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5697216987609863,
      "learning_rate": 3.154471544715447e-05,
      "loss": 1.26,
      "step": 421
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.649803876876831,
      "learning_rate": 3.1382113821138216e-05,
      "loss": 1.1005,
      "step": 422
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5413908362388611,
      "learning_rate": 3.1219512195121955e-05,
      "loss": 1.0701,
      "step": 423
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6329879760742188,
      "learning_rate": 3.105691056910569e-05,
      "loss": 1.1816,
      "step": 424
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5695899128913879,
      "learning_rate": 3.089430894308943e-05,
      "loss": 1.174,
      "step": 425
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5745494961738586,
      "learning_rate": 3.073170731707317e-05,
      "loss": 1.4215,
      "step": 426
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.519962728023529,
      "learning_rate": 3.056910569105691e-05,
      "loss": 1.0675,
      "step": 427
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5622302889823914,
      "learning_rate": 3.0406504065040653e-05,
      "loss": 1.062,
      "step": 428
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5587425827980042,
      "learning_rate": 3.0243902439024392e-05,
      "loss": 1.3578,
      "step": 429
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5603405833244324,
      "learning_rate": 3.0081300813008135e-05,
      "loss": 1.2675,
      "step": 430
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5927146077156067,
      "learning_rate": 2.9918699186991874e-05,
      "loss": 1.1786,
      "step": 431
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6706606149673462,
      "learning_rate": 2.975609756097561e-05,
      "loss": 1.4659,
      "step": 432
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6352270245552063,
      "learning_rate": 2.959349593495935e-05,
      "loss": 1.2413,
      "step": 433
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6240341067314148,
      "learning_rate": 2.943089430894309e-05,
      "loss": 1.1908,
      "step": 434
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.609263002872467,
      "learning_rate": 2.926829268292683e-05,
      "loss": 1.2007,
      "step": 435
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6368755102157593,
      "learning_rate": 2.9105691056910572e-05,
      "loss": 1.364,
      "step": 436
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6076527237892151,
      "learning_rate": 2.894308943089431e-05,
      "loss": 1.3328,
      "step": 437
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6506764888763428,
      "learning_rate": 2.8780487804878046e-05,
      "loss": 1.0908,
      "step": 438
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.684511125087738,
      "learning_rate": 2.8617886178861792e-05,
      "loss": 1.2587,
      "step": 439
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7841042876243591,
      "learning_rate": 2.8455284552845528e-05,
      "loss": 1.6078,
      "step": 440
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.676543653011322,
      "learning_rate": 2.8292682926829267e-05,
      "loss": 1.042,
      "step": 441
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5731042623519897,
      "learning_rate": 2.813008130081301e-05,
      "loss": 1.1154,
      "step": 442
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6072109937667847,
      "learning_rate": 2.7967479674796748e-05,
      "loss": 1.0506,
      "step": 443
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5841884016990662,
      "learning_rate": 2.780487804878049e-05,
      "loss": 1.3147,
      "step": 444
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6464782953262329,
      "learning_rate": 2.764227642276423e-05,
      "loss": 1.2904,
      "step": 445
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5209493637084961,
      "learning_rate": 2.747967479674797e-05,
      "loss": 1.0114,
      "step": 446
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5915167927742004,
      "learning_rate": 2.731707317073171e-05,
      "loss": 1.3247,
      "step": 447
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5479035377502441,
      "learning_rate": 2.715447154471545e-05,
      "loss": 1.224,
      "step": 448
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7527971267700195,
      "learning_rate": 2.6991869918699185e-05,
      "loss": 1.3387,
      "step": 449
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6330116391181946,
      "learning_rate": 2.682926829268293e-05,
      "loss": 1.3187,
      "step": 450
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.617461621761322,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.2354,
      "step": 451
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6665680408477783,
      "learning_rate": 2.6504065040650406e-05,
      "loss": 1.2616,
      "step": 452
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7406666278839111,
      "learning_rate": 2.6341463414634148e-05,
      "loss": 1.2032,
      "step": 453
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6815105080604553,
      "learning_rate": 2.6178861788617887e-05,
      "loss": 1.148,
      "step": 454
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5012332797050476,
      "learning_rate": 2.601626016260163e-05,
      "loss": 1.2498,
      "step": 455
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.631519079208374,
      "learning_rate": 2.5853658536585368e-05,
      "loss": 1.2034,
      "step": 456
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5638870000839233,
      "learning_rate": 2.5691056910569107e-05,
      "loss": 1.2534,
      "step": 457
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5773815512657166,
      "learning_rate": 2.552845528455285e-05,
      "loss": 1.2136,
      "step": 458
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6065455675125122,
      "learning_rate": 2.536585365853659e-05,
      "loss": 1.4471,
      "step": 459
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5597954988479614,
      "learning_rate": 2.5203252032520324e-05,
      "loss": 1.1385,
      "step": 460
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6076185703277588,
      "learning_rate": 2.5040650406504066e-05,
      "loss": 1.0692,
      "step": 461
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5982486009597778,
      "learning_rate": 2.4878048780487805e-05,
      "loss": 1.1315,
      "step": 462
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6467679738998413,
      "learning_rate": 2.4715447154471548e-05,
      "loss": 1.59,
      "step": 463
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7274214029312134,
      "learning_rate": 2.4552845528455283e-05,
      "loss": 1.3918,
      "step": 464
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.623665988445282,
      "learning_rate": 2.4390243902439026e-05,
      "loss": 1.2054,
      "step": 465
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6219509840011597,
      "learning_rate": 2.4227642276422765e-05,
      "loss": 1.2599,
      "step": 466
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6561957001686096,
      "learning_rate": 2.4065040650406507e-05,
      "loss": 1.2255,
      "step": 467
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5756489634513855,
      "learning_rate": 2.3902439024390243e-05,
      "loss": 1.1864,
      "step": 468
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5768493413925171,
      "learning_rate": 2.3739837398373985e-05,
      "loss": 1.2294,
      "step": 469
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5679581761360168,
      "learning_rate": 2.3577235772357724e-05,
      "loss": 1.1502,
      "step": 470
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5461903810501099,
      "learning_rate": 2.3414634146341466e-05,
      "loss": 1.1678,
      "step": 471
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6201043725013733,
      "learning_rate": 2.3252032520325205e-05,
      "loss": 1.108,
      "step": 472
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5330760478973389,
      "learning_rate": 2.3089430894308944e-05,
      "loss": 1.2704,
      "step": 473
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7033615112304688,
      "learning_rate": 2.2926829268292687e-05,
      "loss": 1.2578,
      "step": 474
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6821314692497253,
      "learning_rate": 2.2764227642276422e-05,
      "loss": 1.5061,
      "step": 475
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6884558200836182,
      "learning_rate": 2.2601626016260165e-05,
      "loss": 1.162,
      "step": 476
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6041995882987976,
      "learning_rate": 2.2439024390243904e-05,
      "loss": 1.2946,
      "step": 477
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6138174533843994,
      "learning_rate": 2.2276422764227646e-05,
      "loss": 1.3407,
      "step": 478
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6538270115852356,
      "learning_rate": 2.211382113821138e-05,
      "loss": 1.4126,
      "step": 479
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5147035121917725,
      "learning_rate": 2.1951219512195124e-05,
      "loss": 1.2663,
      "step": 480
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6673200130462646,
      "learning_rate": 2.1788617886178863e-05,
      "loss": 1.2262,
      "step": 481
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5296094417572021,
      "learning_rate": 2.1626016260162602e-05,
      "loss": 1.2074,
      "step": 482
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6079146862030029,
      "learning_rate": 2.146341463414634e-05,
      "loss": 1.0541,
      "step": 483
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.551802933216095,
      "learning_rate": 2.1300813008130083e-05,
      "loss": 1.4021,
      "step": 484
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.585853099822998,
      "learning_rate": 2.1138211382113822e-05,
      "loss": 1.0755,
      "step": 485
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6092184782028198,
      "learning_rate": 2.097560975609756e-05,
      "loss": 1.0969,
      "step": 486
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5295586585998535,
      "learning_rate": 2.0813008130081303e-05,
      "loss": 1.103,
      "step": 487
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7935827374458313,
      "learning_rate": 2.0650406504065042e-05,
      "loss": 1.1543,
      "step": 488
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6095513701438904,
      "learning_rate": 2.048780487804878e-05,
      "loss": 1.2199,
      "step": 489
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.651914119720459,
      "learning_rate": 2.032520325203252e-05,
      "loss": 1.2327,
      "step": 490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6184487342834473,
      "learning_rate": 2.0162601626016263e-05,
      "loss": 1.1073,
      "step": 491
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6615145206451416,
      "learning_rate": 2e-05,
      "loss": 1.2592,
      "step": 492
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5036728382110596,
      "learning_rate": 1.983739837398374e-05,
      "loss": 1.1509,
      "step": 493
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5562529563903809,
      "learning_rate": 1.967479674796748e-05,
      "loss": 1.2939,
      "step": 494
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7089607119560242,
      "learning_rate": 1.9512195121951222e-05,
      "loss": 1.1882,
      "step": 495
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.568822979927063,
      "learning_rate": 1.9349593495934958e-05,
      "loss": 1.2159,
      "step": 496
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5847984552383423,
      "learning_rate": 1.91869918699187e-05,
      "loss": 1.2666,
      "step": 497
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.615049421787262,
      "learning_rate": 1.902439024390244e-05,
      "loss": 1.206,
      "step": 498
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7347215414047241,
      "learning_rate": 1.886178861788618e-05,
      "loss": 1.309,
      "step": 499
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6233913898468018,
      "learning_rate": 1.869918699186992e-05,
      "loss": 1.22,
      "step": 500
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5635728240013123,
      "learning_rate": 1.853658536585366e-05,
      "loss": 1.2439,
      "step": 501
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.7399195432662964,
      "learning_rate": 1.83739837398374e-05,
      "loss": 1.3139,
      "step": 502
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6528146862983704,
      "learning_rate": 1.821138211382114e-05,
      "loss": 1.1394,
      "step": 503
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6272217035293579,
      "learning_rate": 1.804878048780488e-05,
      "loss": 1.1584,
      "step": 504
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6616477370262146,
      "learning_rate": 1.788617886178862e-05,
      "loss": 1.2188,
      "step": 505
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6278210878372192,
      "learning_rate": 1.772357723577236e-05,
      "loss": 1.0062,
      "step": 506
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6322477459907532,
      "learning_rate": 1.7560975609756096e-05,
      "loss": 1.2374,
      "step": 507
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.734391987323761,
      "learning_rate": 1.739837398373984e-05,
      "loss": 1.5292,
      "step": 508
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6056950092315674,
      "learning_rate": 1.7235772357723578e-05,
      "loss": 1.1615,
      "step": 509
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5762361288070679,
      "learning_rate": 1.707317073170732e-05,
      "loss": 1.1037,
      "step": 510
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6219015121459961,
      "learning_rate": 1.6910569105691056e-05,
      "loss": 0.9982,
      "step": 511
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5152187943458557,
      "learning_rate": 1.6747967479674798e-05,
      "loss": 1.0395,
      "step": 512
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5913021564483643,
      "learning_rate": 1.6585365853658537e-05,
      "loss": 1.1396,
      "step": 513
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6387860774993896,
      "learning_rate": 1.6422764227642276e-05,
      "loss": 1.1517,
      "step": 514
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.66391921043396,
      "learning_rate": 1.6260162601626018e-05,
      "loss": 1.2894,
      "step": 515
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5906839966773987,
      "learning_rate": 1.6097560975609757e-05,
      "loss": 1.2237,
      "step": 516
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6661176681518555,
      "learning_rate": 1.5934959349593496e-05,
      "loss": 1.1032,
      "step": 517
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5848115682601929,
      "learning_rate": 1.5772357723577235e-05,
      "loss": 1.2432,
      "step": 518
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5665104985237122,
      "learning_rate": 1.5609756097560978e-05,
      "loss": 1.0056,
      "step": 519
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6808274984359741,
      "learning_rate": 1.5447154471544717e-05,
      "loss": 1.1793,
      "step": 520
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6078669428825378,
      "learning_rate": 1.5284552845528455e-05,
      "loss": 1.2357,
      "step": 521
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5641710162162781,
      "learning_rate": 1.5121951219512196e-05,
      "loss": 1.1396,
      "step": 522
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6799913644790649,
      "learning_rate": 1.4959349593495937e-05,
      "loss": 1.3471,
      "step": 523
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6461642980575562,
      "learning_rate": 1.4796747967479676e-05,
      "loss": 1.2458,
      "step": 524
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6256033778190613,
      "learning_rate": 1.4634146341463415e-05,
      "loss": 1.3327,
      "step": 525
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6022074818611145,
      "learning_rate": 1.4471544715447155e-05,
      "loss": 1.0283,
      "step": 526
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6688457131385803,
      "learning_rate": 1.4308943089430896e-05,
      "loss": 1.1865,
      "step": 527
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5505173206329346,
      "learning_rate": 1.4146341463414633e-05,
      "loss": 1.2462,
      "step": 528
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5834978222846985,
      "learning_rate": 1.3983739837398374e-05,
      "loss": 1.1417,
      "step": 529
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6514319777488708,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 1.1065,
      "step": 530
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5753183960914612,
      "learning_rate": 1.3658536585365855e-05,
      "loss": 1.0414,
      "step": 531
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5459241271018982,
      "learning_rate": 1.3495934959349593e-05,
      "loss": 1.1904,
      "step": 532
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6059259176254272,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.1871,
      "step": 533
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5979688167572021,
      "learning_rate": 1.3170731707317074e-05,
      "loss": 1.4459,
      "step": 534
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5902886986732483,
      "learning_rate": 1.3008130081300815e-05,
      "loss": 1.2841,
      "step": 535
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5885306000709534,
      "learning_rate": 1.2845528455284554e-05,
      "loss": 1.1849,
      "step": 536
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5702282190322876,
      "learning_rate": 1.2682926829268294e-05,
      "loss": 1.0398,
      "step": 537
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6157494783401489,
      "learning_rate": 1.2520325203252033e-05,
      "loss": 1.1827,
      "step": 538
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6133560538291931,
      "learning_rate": 1.2357723577235774e-05,
      "loss": 1.2582,
      "step": 539
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5923981070518494,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 1.0443,
      "step": 540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.566020667552948,
      "learning_rate": 1.2032520325203254e-05,
      "loss": 1.1974,
      "step": 541
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6214295029640198,
      "learning_rate": 1.1869918699186992e-05,
      "loss": 1.2157,
      "step": 542
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5594684481620789,
      "learning_rate": 1.1707317073170733e-05,
      "loss": 1.309,
      "step": 543
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5765097737312317,
      "learning_rate": 1.1544715447154472e-05,
      "loss": 1.3939,
      "step": 544
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5538408160209656,
      "learning_rate": 1.1382113821138211e-05,
      "loss": 1.0295,
      "step": 545
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6209011673927307,
      "learning_rate": 1.1219512195121952e-05,
      "loss": 1.2117,
      "step": 546
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7655690908432007,
      "learning_rate": 1.105691056910569e-05,
      "loss": 1.2998,
      "step": 547
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5802749395370483,
      "learning_rate": 1.0894308943089431e-05,
      "loss": 1.2495,
      "step": 548
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6126115322113037,
      "learning_rate": 1.073170731707317e-05,
      "loss": 1.3127,
      "step": 549
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6555020809173584,
      "learning_rate": 1.0569105691056911e-05,
      "loss": 1.3068,
      "step": 550
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6141782402992249,
      "learning_rate": 1.0406504065040652e-05,
      "loss": 1.0843,
      "step": 551
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6077665090560913,
      "learning_rate": 1.024390243902439e-05,
      "loss": 1.0928,
      "step": 552
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7192431092262268,
      "learning_rate": 1.0081300813008131e-05,
      "loss": 1.2511,
      "step": 553
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5512276291847229,
      "learning_rate": 9.91869918699187e-06,
      "loss": 1.0273,
      "step": 554
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5976685285568237,
      "learning_rate": 9.756097560975611e-06,
      "loss": 1.0757,
      "step": 555
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5692313313484192,
      "learning_rate": 9.59349593495935e-06,
      "loss": 1.3248,
      "step": 556
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.624089777469635,
      "learning_rate": 9.43089430894309e-06,
      "loss": 1.3148,
      "step": 557
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6139058470726013,
      "learning_rate": 9.26829268292683e-06,
      "loss": 1.2222,
      "step": 558
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5464222431182861,
      "learning_rate": 9.10569105691057e-06,
      "loss": 1.2106,
      "step": 559
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7536869645118713,
      "learning_rate": 8.94308943089431e-06,
      "loss": 1.243,
      "step": 560
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5915424227714539,
      "learning_rate": 8.780487804878048e-06,
      "loss": 1.1469,
      "step": 561
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6128919124603271,
      "learning_rate": 8.617886178861789e-06,
      "loss": 1.226,
      "step": 562
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5765390396118164,
      "learning_rate": 8.455284552845528e-06,
      "loss": 1.1282,
      "step": 563
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8483685255050659,
      "learning_rate": 8.292682926829268e-06,
      "loss": 1.3169,
      "step": 564
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5521007776260376,
      "learning_rate": 8.130081300813009e-06,
      "loss": 1.0342,
      "step": 565
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6133531928062439,
      "learning_rate": 7.967479674796748e-06,
      "loss": 1.1192,
      "step": 566
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5069576501846313,
      "learning_rate": 7.804878048780489e-06,
      "loss": 1.0674,
      "step": 567
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6670443415641785,
      "learning_rate": 7.642276422764228e-06,
      "loss": 1.0266,
      "step": 568
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5490599870681763,
      "learning_rate": 7.479674796747968e-06,
      "loss": 1.1987,
      "step": 569
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7114666104316711,
      "learning_rate": 7.317073170731707e-06,
      "loss": 1.1389,
      "step": 570
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5915193557739258,
      "learning_rate": 7.154471544715448e-06,
      "loss": 1.3249,
      "step": 571
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5571520328521729,
      "learning_rate": 6.991869918699187e-06,
      "loss": 0.9243,
      "step": 572
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4982016086578369,
      "learning_rate": 6.829268292682928e-06,
      "loss": 1.1625,
      "step": 573
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5658428072929382,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.3275,
      "step": 574
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5510423183441162,
      "learning_rate": 6.504065040650407e-06,
      "loss": 1.1219,
      "step": 575
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5396825075149536,
      "learning_rate": 6.341463414634147e-06,
      "loss": 1.0442,
      "step": 576
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5658376812934875,
      "learning_rate": 6.178861788617887e-06,
      "loss": 1.1787,
      "step": 577
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6281037926673889,
      "learning_rate": 6.016260162601627e-06,
      "loss": 1.4951,
      "step": 578
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.717558741569519,
      "learning_rate": 5.853658536585367e-06,
      "loss": 1.3421,
      "step": 579
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5493326783180237,
      "learning_rate": 5.6910569105691056e-06,
      "loss": 0.9907,
      "step": 580
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5810380578041077,
      "learning_rate": 5.528455284552845e-06,
      "loss": 1.4415,
      "step": 581
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5449215769767761,
      "learning_rate": 5.365853658536585e-06,
      "loss": 1.2817,
      "step": 582
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6764107942581177,
      "learning_rate": 5.203252032520326e-06,
      "loss": 1.4277,
      "step": 583
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6480046510696411,
      "learning_rate": 5.040650406504066e-06,
      "loss": 1.0979,
      "step": 584
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5687589049339294,
      "learning_rate": 4.8780487804878055e-06,
      "loss": 1.0829,
      "step": 585
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5640531778335571,
      "learning_rate": 4.715447154471545e-06,
      "loss": 1.1832,
      "step": 586
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5553130507469177,
      "learning_rate": 4.552845528455285e-06,
      "loss": 1.1955,
      "step": 587
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.644838809967041,
      "learning_rate": 4.390243902439024e-06,
      "loss": 1.3625,
      "step": 588
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6489309668540955,
      "learning_rate": 4.227642276422764e-06,
      "loss": 1.4003,
      "step": 589
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6127081513404846,
      "learning_rate": 4.0650406504065046e-06,
      "loss": 1.2944,
      "step": 590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7064576148986816,
      "learning_rate": 3.902439024390244e-06,
      "loss": 1.2562,
      "step": 591
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.591510534286499,
      "learning_rate": 3.739837398373984e-06,
      "loss": 1.2203,
      "step": 592
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6008673906326294,
      "learning_rate": 3.577235772357724e-06,
      "loss": 1.2166,
      "step": 593
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6218029856681824,
      "learning_rate": 3.414634146341464e-06,
      "loss": 1.1062,
      "step": 594
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6293817758560181,
      "learning_rate": 3.2520325203252037e-06,
      "loss": 1.3224,
      "step": 595
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5373908877372742,
      "learning_rate": 3.0894308943089435e-06,
      "loss": 1.0054,
      "step": 596
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5833137035369873,
      "learning_rate": 2.9268292682926833e-06,
      "loss": 1.1424,
      "step": 597
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6306708455085754,
      "learning_rate": 2.7642276422764227e-06,
      "loss": 1.5455,
      "step": 598
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.598529577255249,
      "learning_rate": 2.601626016260163e-06,
      "loss": 1.1924,
      "step": 599
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7502354979515076,
      "learning_rate": 2.4390243902439027e-06,
      "loss": 1.2883,
      "step": 600
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5586222410202026,
      "learning_rate": 2.2764227642276426e-06,
      "loss": 1.0596,
      "step": 601
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5384691953659058,
      "learning_rate": 2.113821138211382e-06,
      "loss": 1.0263,
      "step": 602
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6116771101951599,
      "learning_rate": 1.951219512195122e-06,
      "loss": 1.1553,
      "step": 603
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5474973917007446,
      "learning_rate": 1.788617886178862e-06,
      "loss": 1.189,
      "step": 604
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9431177973747253,
      "learning_rate": 1.6260162601626018e-06,
      "loss": 1.3169,
      "step": 605
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5889328718185425,
      "learning_rate": 1.4634146341463416e-06,
      "loss": 1.1048,
      "step": 606
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5249641537666321,
      "learning_rate": 1.3008130081300815e-06,
      "loss": 1.0887,
      "step": 607
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5675404071807861,
      "learning_rate": 1.1382113821138213e-06,
      "loss": 1.1328,
      "step": 608
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6923323273658752,
      "learning_rate": 9.75609756097561e-07,
      "loss": 1.2411,
      "step": 609
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6647180914878845,
      "learning_rate": 8.130081300813009e-07,
      "loss": 1.3848,
      "step": 610
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.586513340473175,
      "learning_rate": 6.504065040650407e-07,
      "loss": 1.2417,
      "step": 611
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5629855394363403,
      "learning_rate": 4.878048780487805e-07,
      "loss": 1.0053,
      "step": 612
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5869565606117249,
      "learning_rate": 3.2520325203252037e-07,
      "loss": 1.2839,
      "step": 613
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6274411678314209,
      "learning_rate": 1.6260162601626018e-07,
      "loss": 1.123,
      "step": 614
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5628176331520081,
      "learning_rate": 0.0,
      "loss": 1.1691,
      "step": 615
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2541581392288208,
      "eval_runtime": 143.1579,
      "eval_samples_per_second": 3.618,
      "eval_steps_per_second": 0.908,
      "step": 615
    }
  ],
  "logging_steps": 1,
  "max_steps": 615,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.0782088869445632e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
