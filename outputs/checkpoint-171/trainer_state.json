{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9956331877729258,
  "eval_steps": 500,
  "global_step": 171,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.5079707503318787,
      "learning_rate": 9.941520467836257e-05,
      "loss": 1.7512,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.47717615962028503,
      "learning_rate": 9.883040935672515e-05,
      "loss": 1.5415,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.447896271944046,
      "learning_rate": 9.824561403508771e-05,
      "loss": 1.5219,
      "step": 3
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3937566876411438,
      "learning_rate": 9.76608187134503e-05,
      "loss": 1.2967,
      "step": 4
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5241495370864868,
      "learning_rate": 9.707602339181286e-05,
      "loss": 1.3156,
      "step": 5
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5523796677589417,
      "learning_rate": 9.649122807017544e-05,
      "loss": 1.224,
      "step": 6
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0777430534362793,
      "learning_rate": 9.590643274853801e-05,
      "loss": 1.2128,
      "step": 7
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.773317813873291,
      "learning_rate": 9.532163742690059e-05,
      "loss": 1.02,
      "step": 8
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.094699740409851,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.9677,
      "step": 9
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3442504405975342,
      "learning_rate": 9.415204678362574e-05,
      "loss": 0.9413,
      "step": 10
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2552473545074463,
      "learning_rate": 9.35672514619883e-05,
      "loss": 0.9154,
      "step": 11
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.678652286529541,
      "learning_rate": 9.298245614035089e-05,
      "loss": 0.9047,
      "step": 12
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.820421576499939,
      "learning_rate": 9.239766081871345e-05,
      "loss": 0.7807,
      "step": 13
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0140758752822876,
      "learning_rate": 9.181286549707603e-05,
      "loss": 0.8534,
      "step": 14
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3888595998287201,
      "learning_rate": 9.12280701754386e-05,
      "loss": 0.8783,
      "step": 15
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4389491379261017,
      "learning_rate": 9.064327485380117e-05,
      "loss": 0.7361,
      "step": 16
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.38374873995780945,
      "learning_rate": 9.005847953216374e-05,
      "loss": 0.9291,
      "step": 17
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.35796183347702026,
      "learning_rate": 8.947368421052632e-05,
      "loss": 0.7711,
      "step": 18
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3714817762374878,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.7642,
      "step": 19
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3001875579357147,
      "learning_rate": 8.830409356725147e-05,
      "loss": 0.9553,
      "step": 20
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3049091398715973,
      "learning_rate": 8.771929824561403e-05,
      "loss": 0.8553,
      "step": 21
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.33749300241470337,
      "learning_rate": 8.713450292397662e-05,
      "loss": 0.7437,
      "step": 22
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30262887477874756,
      "learning_rate": 8.654970760233918e-05,
      "loss": 0.664,
      "step": 23
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2789560556411743,
      "learning_rate": 8.596491228070177e-05,
      "loss": 0.749,
      "step": 24
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.26675376296043396,
      "learning_rate": 8.538011695906433e-05,
      "loss": 0.6463,
      "step": 25
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.28164440393447876,
      "learning_rate": 8.47953216374269e-05,
      "loss": 0.6854,
      "step": 26
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31815993785858154,
      "learning_rate": 8.421052631578948e-05,
      "loss": 0.7834,
      "step": 27
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2649915814399719,
      "learning_rate": 8.362573099415205e-05,
      "loss": 0.6626,
      "step": 28
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2429223358631134,
      "learning_rate": 8.304093567251462e-05,
      "loss": 0.7204,
      "step": 29
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.24875637888908386,
      "learning_rate": 8.24561403508772e-05,
      "loss": 0.697,
      "step": 30
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.23844870924949646,
      "learning_rate": 8.187134502923976e-05,
      "loss": 0.7752,
      "step": 31
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2588953673839569,
      "learning_rate": 8.128654970760235e-05,
      "loss": 0.7105,
      "step": 32
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2086048573255539,
      "learning_rate": 8.070175438596491e-05,
      "loss": 0.6471,
      "step": 33
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.26345425844192505,
      "learning_rate": 8.01169590643275e-05,
      "loss": 0.6646,
      "step": 34
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.23597341775894165,
      "learning_rate": 7.953216374269006e-05,
      "loss": 0.8466,
      "step": 35
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.22851356863975525,
      "learning_rate": 7.894736842105263e-05,
      "loss": 0.6699,
      "step": 36
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.23911544680595398,
      "learning_rate": 7.836257309941521e-05,
      "loss": 0.8987,
      "step": 37
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.22794190049171448,
      "learning_rate": 7.777777777777778e-05,
      "loss": 0.6964,
      "step": 38
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.19631730020046234,
      "learning_rate": 7.719298245614036e-05,
      "loss": 0.5652,
      "step": 39
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.24796119332313538,
      "learning_rate": 7.660818713450293e-05,
      "loss": 0.763,
      "step": 40
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.21319743990898132,
      "learning_rate": 7.602339181286549e-05,
      "loss": 0.611,
      "step": 41
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2395896017551422,
      "learning_rate": 7.543859649122808e-05,
      "loss": 0.7296,
      "step": 42
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2201964110136032,
      "learning_rate": 7.485380116959064e-05,
      "loss": 0.6377,
      "step": 43
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21766842901706696,
      "learning_rate": 7.426900584795321e-05,
      "loss": 0.6125,
      "step": 44
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2592512369155884,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.7703,
      "step": 45
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.2314213067293167,
      "learning_rate": 7.309941520467836e-05,
      "loss": 0.5978,
      "step": 46
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.22837281227111816,
      "learning_rate": 7.251461988304094e-05,
      "loss": 0.7557,
      "step": 47
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.27675485610961914,
      "learning_rate": 7.192982456140351e-05,
      "loss": 0.649,
      "step": 48
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.21626032888889313,
      "learning_rate": 7.134502923976609e-05,
      "loss": 0.6478,
      "step": 49
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2388623058795929,
      "learning_rate": 7.076023391812866e-05,
      "loss": 0.7797,
      "step": 50
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2286951243877411,
      "learning_rate": 7.017543859649122e-05,
      "loss": 0.7019,
      "step": 51
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.23132836818695068,
      "learning_rate": 6.959064327485381e-05,
      "loss": 0.7228,
      "step": 52
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.22687596082687378,
      "learning_rate": 6.900584795321637e-05,
      "loss": 0.73,
      "step": 53
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.23204563558101654,
      "learning_rate": 6.842105263157895e-05,
      "loss": 0.6831,
      "step": 54
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.21667227149009705,
      "learning_rate": 6.783625730994152e-05,
      "loss": 0.7499,
      "step": 55
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2795565128326416,
      "learning_rate": 6.72514619883041e-05,
      "loss": 0.6822,
      "step": 56
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.22644612193107605,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.5898,
      "step": 57
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.21100248396396637,
      "learning_rate": 6.608187134502924e-05,
      "loss": 0.7936,
      "step": 58
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.21977001428604126,
      "learning_rate": 6.549707602339182e-05,
      "loss": 0.7465,
      "step": 59
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.2637122571468353,
      "learning_rate": 6.49122807017544e-05,
      "loss": 0.9666,
      "step": 60
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.21302179992198944,
      "learning_rate": 6.432748538011695e-05,
      "loss": 0.6417,
      "step": 61
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20771828293800354,
      "learning_rate": 6.374269005847954e-05,
      "loss": 0.6999,
      "step": 62
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.25213390588760376,
      "learning_rate": 6.31578947368421e-05,
      "loss": 0.9086,
      "step": 63
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.22744451463222504,
      "learning_rate": 6.257309941520468e-05,
      "loss": 0.7071,
      "step": 64
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.25481918454170227,
      "learning_rate": 6.198830409356725e-05,
      "loss": 0.6931,
      "step": 65
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.252323716878891,
      "learning_rate": 6.140350877192983e-05,
      "loss": 0.8272,
      "step": 66
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.27616482973098755,
      "learning_rate": 6.0818713450292395e-05,
      "loss": 0.7295,
      "step": 67
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.23655326664447784,
      "learning_rate": 6.0233918128654976e-05,
      "loss": 0.9691,
      "step": 68
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.22495710849761963,
      "learning_rate": 5.9649122807017544e-05,
      "loss": 0.6812,
      "step": 69
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.23999591171741486,
      "learning_rate": 5.9064327485380125e-05,
      "loss": 0.6684,
      "step": 70
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.24061056971549988,
      "learning_rate": 5.847953216374269e-05,
      "loss": 0.6636,
      "step": 71
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.22183002531528473,
      "learning_rate": 5.789473684210527e-05,
      "loss": 0.7298,
      "step": 72
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.22921103239059448,
      "learning_rate": 5.7309941520467835e-05,
      "loss": 0.7006,
      "step": 73
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.21120592951774597,
      "learning_rate": 5.6725146198830416e-05,
      "loss": 0.6659,
      "step": 74
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.22219139337539673,
      "learning_rate": 5.6140350877192984e-05,
      "loss": 0.6133,
      "step": 75
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2301660031080246,
      "learning_rate": 5.555555555555556e-05,
      "loss": 0.8583,
      "step": 76
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.21489545702934265,
      "learning_rate": 5.4970760233918126e-05,
      "loss": 0.7115,
      "step": 77
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.2266853153705597,
      "learning_rate": 5.438596491228071e-05,
      "loss": 0.7151,
      "step": 78
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.20585425198078156,
      "learning_rate": 5.3801169590643275e-05,
      "loss": 0.7263,
      "step": 79
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.211324542760849,
      "learning_rate": 5.3216374269005856e-05,
      "loss": 0.7348,
      "step": 80
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2166685163974762,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 0.6128,
      "step": 81
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.21514636278152466,
      "learning_rate": 5.2046783625731e-05,
      "loss": 0.7286,
      "step": 82
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.213045135140419,
      "learning_rate": 5.1461988304093566e-05,
      "loss": 0.6275,
      "step": 83
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.28087517619132996,
      "learning_rate": 5.087719298245615e-05,
      "loss": 0.6819,
      "step": 84
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.21679602563381195,
      "learning_rate": 5.0292397660818715e-05,
      "loss": 0.6191,
      "step": 85
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2241823822259903,
      "learning_rate": 4.970760233918128e-05,
      "loss": 0.6535,
      "step": 86
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.22347375750541687,
      "learning_rate": 4.912280701754386e-05,
      "loss": 0.6912,
      "step": 87
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.2656656801700592,
      "learning_rate": 4.853801169590643e-05,
      "loss": 0.8487,
      "step": 88
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.25451284646987915,
      "learning_rate": 4.7953216374269006e-05,
      "loss": 0.7514,
      "step": 89
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.23387295007705688,
      "learning_rate": 4.736842105263158e-05,
      "loss": 0.6681,
      "step": 90
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.2123001664876938,
      "learning_rate": 4.678362573099415e-05,
      "loss": 0.6953,
      "step": 91
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.2181600034236908,
      "learning_rate": 4.619883040935672e-05,
      "loss": 0.726,
      "step": 92
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.21566253900527954,
      "learning_rate": 4.56140350877193e-05,
      "loss": 0.5844,
      "step": 93
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.23085778951644897,
      "learning_rate": 4.502923976608187e-05,
      "loss": 0.7358,
      "step": 94
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.22272683680057526,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.6844,
      "step": 95
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.20189125835895538,
      "learning_rate": 4.3859649122807014e-05,
      "loss": 0.7274,
      "step": 96
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.25160324573516846,
      "learning_rate": 4.327485380116959e-05,
      "loss": 0.6982,
      "step": 97
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.23704494535923004,
      "learning_rate": 4.269005847953216e-05,
      "loss": 0.8036,
      "step": 98
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.23310022056102753,
      "learning_rate": 4.210526315789474e-05,
      "loss": 0.7271,
      "step": 99
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.21082371473312378,
      "learning_rate": 4.152046783625731e-05,
      "loss": 0.8226,
      "step": 100
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.23931339383125305,
      "learning_rate": 4.093567251461988e-05,
      "loss": 0.6718,
      "step": 101
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.24356496334075928,
      "learning_rate": 4.0350877192982455e-05,
      "loss": 0.6669,
      "step": 102
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2400166094303131,
      "learning_rate": 3.976608187134503e-05,
      "loss": 0.8443,
      "step": 103
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.2646399140357971,
      "learning_rate": 3.9181286549707604e-05,
      "loss": 0.8053,
      "step": 104
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.214915469288826,
      "learning_rate": 3.859649122807018e-05,
      "loss": 0.715,
      "step": 105
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1970195472240448,
      "learning_rate": 3.8011695906432746e-05,
      "loss": 0.6565,
      "step": 106
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.22237519919872284,
      "learning_rate": 3.742690058479532e-05,
      "loss": 0.7021,
      "step": 107
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.20642811059951782,
      "learning_rate": 3.6842105263157895e-05,
      "loss": 0.6153,
      "step": 108
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.22573687136173248,
      "learning_rate": 3.625730994152047e-05,
      "loss": 0.7282,
      "step": 109
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2173849195241928,
      "learning_rate": 3.5672514619883044e-05,
      "loss": 0.7521,
      "step": 110
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.2285294383764267,
      "learning_rate": 3.508771929824561e-05,
      "loss": 0.6223,
      "step": 111
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.26065072417259216,
      "learning_rate": 3.4502923976608186e-05,
      "loss": 0.6651,
      "step": 112
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.2239789366722107,
      "learning_rate": 3.391812865497076e-05,
      "loss": 0.6487,
      "step": 113
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.23464550077915192,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.5913,
      "step": 114
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2017011046409607,
      "learning_rate": 3.274853801169591e-05,
      "loss": 0.7089,
      "step": 115
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.23116903007030487,
      "learning_rate": 3.216374269005848e-05,
      "loss": 0.7013,
      "step": 116
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.21319203078746796,
      "learning_rate": 3.157894736842105e-05,
      "loss": 0.776,
      "step": 117
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.27289271354675293,
      "learning_rate": 3.0994152046783626e-05,
      "loss": 0.8934,
      "step": 118
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.20521993935108185,
      "learning_rate": 3.0409356725146197e-05,
      "loss": 0.669,
      "step": 119
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.24131035804748535,
      "learning_rate": 2.9824561403508772e-05,
      "loss": 0.7993,
      "step": 120
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.2180141657590866,
      "learning_rate": 2.9239766081871346e-05,
      "loss": 0.6801,
      "step": 121
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.25675174593925476,
      "learning_rate": 2.8654970760233917e-05,
      "loss": 0.774,
      "step": 122
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.21738213300704956,
      "learning_rate": 2.8070175438596492e-05,
      "loss": 0.7451,
      "step": 123
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.26868098974227905,
      "learning_rate": 2.7485380116959063e-05,
      "loss": 0.7118,
      "step": 124
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.2665553689002991,
      "learning_rate": 2.6900584795321637e-05,
      "loss": 0.7579,
      "step": 125
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.22297339141368866,
      "learning_rate": 2.6315789473684212e-05,
      "loss": 0.685,
      "step": 126
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.21167656779289246,
      "learning_rate": 2.5730994152046783e-05,
      "loss": 0.7537,
      "step": 127
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.24959582090377808,
      "learning_rate": 2.5146198830409358e-05,
      "loss": 0.7082,
      "step": 128
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.23908688127994537,
      "learning_rate": 2.456140350877193e-05,
      "loss": 0.6828,
      "step": 129
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.21949416399002075,
      "learning_rate": 2.3976608187134503e-05,
      "loss": 0.7603,
      "step": 130
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2360575944185257,
      "learning_rate": 2.3391812865497074e-05,
      "loss": 0.6818,
      "step": 131
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.20841437578201294,
      "learning_rate": 2.280701754385965e-05,
      "loss": 0.6683,
      "step": 132
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.23409686982631683,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.7009,
      "step": 133
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.21358506381511688,
      "learning_rate": 2.1637426900584794e-05,
      "loss": 0.689,
      "step": 134
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.21957162022590637,
      "learning_rate": 2.105263157894737e-05,
      "loss": 0.6447,
      "step": 135
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2155575007200241,
      "learning_rate": 2.046783625730994e-05,
      "loss": 0.5582,
      "step": 136
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1974402666091919,
      "learning_rate": 1.9883040935672515e-05,
      "loss": 0.6881,
      "step": 137
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.21292586624622345,
      "learning_rate": 1.929824561403509e-05,
      "loss": 0.6173,
      "step": 138
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.21581678092479706,
      "learning_rate": 1.871345029239766e-05,
      "loss": 0.6661,
      "step": 139
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.24485108256340027,
      "learning_rate": 1.8128654970760235e-05,
      "loss": 0.7424,
      "step": 140
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.230226069688797,
      "learning_rate": 1.7543859649122806e-05,
      "loss": 0.6816,
      "step": 141
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2252146601676941,
      "learning_rate": 1.695906432748538e-05,
      "loss": 0.796,
      "step": 142
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2226230502128601,
      "learning_rate": 1.6374269005847955e-05,
      "loss": 0.7135,
      "step": 143
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.23225343227386475,
      "learning_rate": 1.5789473684210526e-05,
      "loss": 0.7287,
      "step": 144
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.25074052810668945,
      "learning_rate": 1.5204678362573099e-05,
      "loss": 0.7948,
      "step": 145
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.19966654479503632,
      "learning_rate": 1.4619883040935673e-05,
      "loss": 0.7026,
      "step": 146
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.2111911028623581,
      "learning_rate": 1.4035087719298246e-05,
      "loss": 0.6619,
      "step": 147
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.2703656554222107,
      "learning_rate": 1.3450292397660819e-05,
      "loss": 0.859,
      "step": 148
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.20034350454807281,
      "learning_rate": 1.2865497076023392e-05,
      "loss": 0.6822,
      "step": 149
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.2546096742153168,
      "learning_rate": 1.2280701754385964e-05,
      "loss": 0.6838,
      "step": 150
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.22302524745464325,
      "learning_rate": 1.1695906432748537e-05,
      "loss": 0.6803,
      "step": 151
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.21371202170848846,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.6528,
      "step": 152
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.2823996841907501,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.7207,
      "step": 153
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2119722217321396,
      "learning_rate": 9.941520467836257e-06,
      "loss": 0.5844,
      "step": 154
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2140345275402069,
      "learning_rate": 9.35672514619883e-06,
      "loss": 0.6438,
      "step": 155
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.22299349308013916,
      "learning_rate": 8.771929824561403e-06,
      "loss": 0.6285,
      "step": 156
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.22018541395664215,
      "learning_rate": 8.187134502923977e-06,
      "loss": 0.8146,
      "step": 157
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.2676851749420166,
      "learning_rate": 7.602339181286549e-06,
      "loss": 0.7551,
      "step": 158
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.19644752144813538,
      "learning_rate": 7.017543859649123e-06,
      "loss": 0.6865,
      "step": 159
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.25468114018440247,
      "learning_rate": 6.432748538011696e-06,
      "loss": 0.6739,
      "step": 160
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.24298781156539917,
      "learning_rate": 5.8479532163742686e-06,
      "loss": 0.663,
      "step": 161
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.25749126076698303,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.7449,
      "step": 162
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.20812560617923737,
      "learning_rate": 4.678362573099415e-06,
      "loss": 0.7817,
      "step": 163
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.22626443207263947,
      "learning_rate": 4.093567251461989e-06,
      "loss": 0.6475,
      "step": 164
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2318228930234909,
      "learning_rate": 3.5087719298245615e-06,
      "loss": 0.8557,
      "step": 165
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.22729453444480896,
      "learning_rate": 2.9239766081871343e-06,
      "loss": 0.657,
      "step": 166
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.24178995192050934,
      "learning_rate": 2.3391812865497075e-06,
      "loss": 0.7493,
      "step": 167
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.24412408471107483,
      "learning_rate": 1.7543859649122807e-06,
      "loss": 0.8019,
      "step": 168
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.21037892997264862,
      "learning_rate": 1.1695906432748538e-06,
      "loss": 0.7202,
      "step": 169
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.22254633903503418,
      "learning_rate": 5.847953216374269e-07,
      "loss": 0.6165,
      "step": 170
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2618260383605957,
      "learning_rate": 0.0,
      "loss": 0.7469,
      "step": 171
    }
  ],
  "logging_steps": 1,
  "max_steps": 171,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2.3983573290083942e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
