{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9988465974625144,
  "eval_steps": 500,
  "global_step": 433,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.540300726890564,
      "learning_rate": 9.976905311778292e-05,
      "loss": 1.4442,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3330491781234741,
      "learning_rate": 9.953810623556582e-05,
      "loss": 1.1748,
      "step": 2
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5270003080368042,
      "learning_rate": 9.930715935334873e-05,
      "loss": 1.6035,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8793728351593018,
      "learning_rate": 9.907621247113164e-05,
      "loss": 1.5518,
      "step": 4
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0267550945281982,
      "learning_rate": 9.884526558891456e-05,
      "loss": 1.4557,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0052447319030762,
      "learning_rate": 9.861431870669747e-05,
      "loss": 1.3218,
      "step": 6
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8264322876930237,
      "learning_rate": 9.838337182448038e-05,
      "loss": 1.6262,
      "step": 7
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9543130397796631,
      "learning_rate": 9.81524249422633e-05,
      "loss": 1.094,
      "step": 8
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9285637140274048,
      "learning_rate": 9.79214780600462e-05,
      "loss": 1.4251,
      "step": 9
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7475267648696899,
      "learning_rate": 9.76905311778291e-05,
      "loss": 1.0696,
      "step": 10
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8054271340370178,
      "learning_rate": 9.745958429561202e-05,
      "loss": 1.4862,
      "step": 11
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6913732886314392,
      "learning_rate": 9.722863741339492e-05,
      "loss": 1.2282,
      "step": 12
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7641425132751465,
      "learning_rate": 9.699769053117783e-05,
      "loss": 1.167,
      "step": 13
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9681414365768433,
      "learning_rate": 9.676674364896074e-05,
      "loss": 1.7335,
      "step": 14
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5192265510559082,
      "learning_rate": 9.653579676674366e-05,
      "loss": 1.029,
      "step": 15
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6921968460083008,
      "learning_rate": 9.630484988452656e-05,
      "loss": 1.4416,
      "step": 16
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8217036724090576,
      "learning_rate": 9.607390300230947e-05,
      "loss": 1.4562,
      "step": 17
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6116511225700378,
      "learning_rate": 9.584295612009238e-05,
      "loss": 1.1495,
      "step": 18
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6196756362915039,
      "learning_rate": 9.56120092378753e-05,
      "loss": 1.3876,
      "step": 19
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7575554251670837,
      "learning_rate": 9.538106235565821e-05,
      "loss": 1.2743,
      "step": 20
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7523427605628967,
      "learning_rate": 9.515011547344112e-05,
      "loss": 1.4921,
      "step": 21
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8128708600997925,
      "learning_rate": 9.491916859122403e-05,
      "loss": 1.342,
      "step": 22
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8715088963508606,
      "learning_rate": 9.468822170900693e-05,
      "loss": 1.2454,
      "step": 23
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.205068588256836,
      "learning_rate": 9.445727482678985e-05,
      "loss": 1.9316,
      "step": 24
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6587191820144653,
      "learning_rate": 9.422632794457276e-05,
      "loss": 1.0687,
      "step": 25
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.551268458366394,
      "learning_rate": 9.399538106235566e-05,
      "loss": 0.945,
      "step": 26
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.552905261516571,
      "learning_rate": 9.376443418013857e-05,
      "loss": 1.0165,
      "step": 27
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6475135087966919,
      "learning_rate": 9.353348729792148e-05,
      "loss": 0.8521,
      "step": 28
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.49177926778793335,
      "learning_rate": 9.330254041570438e-05,
      "loss": 1.1671,
      "step": 29
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6570556163787842,
      "learning_rate": 9.30715935334873e-05,
      "loss": 0.8867,
      "step": 30
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6123206615447998,
      "learning_rate": 9.284064665127021e-05,
      "loss": 0.8658,
      "step": 31
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7208852767944336,
      "learning_rate": 9.260969976905312e-05,
      "loss": 1.0621,
      "step": 32
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5100782513618469,
      "learning_rate": 9.237875288683603e-05,
      "loss": 1.2436,
      "step": 33
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6818571090698242,
      "learning_rate": 9.214780600461895e-05,
      "loss": 1.5052,
      "step": 34
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5807391405105591,
      "learning_rate": 9.191685912240186e-05,
      "loss": 1.1032,
      "step": 35
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1523158550262451,
      "learning_rate": 9.168591224018476e-05,
      "loss": 1.6509,
      "step": 36
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8436355590820312,
      "learning_rate": 9.145496535796767e-05,
      "loss": 1.1338,
      "step": 37
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5897828340530396,
      "learning_rate": 9.122401847575059e-05,
      "loss": 1.0281,
      "step": 38
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5301767587661743,
      "learning_rate": 9.09930715935335e-05,
      "loss": 1.1078,
      "step": 39
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7043818831443787,
      "learning_rate": 9.07621247113164e-05,
      "loss": 1.371,
      "step": 40
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5622115731239319,
      "learning_rate": 9.053117782909931e-05,
      "loss": 1.1973,
      "step": 41
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6247332096099854,
      "learning_rate": 9.030023094688222e-05,
      "loss": 1.269,
      "step": 42
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8398478031158447,
      "learning_rate": 9.006928406466512e-05,
      "loss": 1.3551,
      "step": 43
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7809211611747742,
      "learning_rate": 8.983833718244804e-05,
      "loss": 1.5535,
      "step": 44
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8414689302444458,
      "learning_rate": 8.960739030023095e-05,
      "loss": 1.1547,
      "step": 45
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5275339484214783,
      "learning_rate": 8.937644341801386e-05,
      "loss": 1.2276,
      "step": 46
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6457666754722595,
      "learning_rate": 8.914549653579677e-05,
      "loss": 1.2008,
      "step": 47
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6633278131484985,
      "learning_rate": 8.891454965357969e-05,
      "loss": 1.202,
      "step": 48
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5776439905166626,
      "learning_rate": 8.86836027713626e-05,
      "loss": 0.9728,
      "step": 49
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6010388731956482,
      "learning_rate": 8.84526558891455e-05,
      "loss": 1.1161,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.909532904624939,
      "learning_rate": 8.822170900692841e-05,
      "loss": 1.2523,
      "step": 51
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5296417474746704,
      "learning_rate": 8.799076212471132e-05,
      "loss": 1.3305,
      "step": 52
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6706807613372803,
      "learning_rate": 8.775981524249422e-05,
      "loss": 1.2193,
      "step": 53
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6673189997673035,
      "learning_rate": 8.752886836027714e-05,
      "loss": 1.2104,
      "step": 54
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5883070826530457,
      "learning_rate": 8.729792147806005e-05,
      "loss": 1.3025,
      "step": 55
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7696932554244995,
      "learning_rate": 8.706697459584296e-05,
      "loss": 1.3427,
      "step": 56
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5432226061820984,
      "learning_rate": 8.683602771362586e-05,
      "loss": 0.9257,
      "step": 57
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5916113257408142,
      "learning_rate": 8.660508083140877e-05,
      "loss": 1.16,
      "step": 58
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5943997502326965,
      "learning_rate": 8.637413394919169e-05,
      "loss": 1.1372,
      "step": 59
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6410192847251892,
      "learning_rate": 8.61431870669746e-05,
      "loss": 1.0832,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6020844578742981,
      "learning_rate": 8.591224018475751e-05,
      "loss": 1.2896,
      "step": 61
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5752028226852417,
      "learning_rate": 8.568129330254043e-05,
      "loss": 1.1263,
      "step": 62
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6023229956626892,
      "learning_rate": 8.545034642032334e-05,
      "loss": 0.9937,
      "step": 63
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6330811381340027,
      "learning_rate": 8.521939953810624e-05,
      "loss": 0.9545,
      "step": 64
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8242529034614563,
      "learning_rate": 8.498845265588915e-05,
      "loss": 1.3703,
      "step": 65
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7298058867454529,
      "learning_rate": 8.475750577367206e-05,
      "loss": 1.1591,
      "step": 66
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5944536328315735,
      "learning_rate": 8.452655889145496e-05,
      "loss": 1.1077,
      "step": 67
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6842570304870605,
      "learning_rate": 8.429561200923788e-05,
      "loss": 1.1439,
      "step": 68
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9696840643882751,
      "learning_rate": 8.406466512702079e-05,
      "loss": 1.1906,
      "step": 69
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8492388725280762,
      "learning_rate": 8.383371824480369e-05,
      "loss": 1.5368,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5529193878173828,
      "learning_rate": 8.36027713625866e-05,
      "loss": 0.9783,
      "step": 71
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6014724373817444,
      "learning_rate": 8.337182448036951e-05,
      "loss": 0.9433,
      "step": 72
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9924451112747192,
      "learning_rate": 8.314087759815243e-05,
      "loss": 1.5687,
      "step": 73
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5551179051399231,
      "learning_rate": 8.290993071593534e-05,
      "loss": 1.1211,
      "step": 74
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8127499222755432,
      "learning_rate": 8.267898383371825e-05,
      "loss": 1.3814,
      "step": 75
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6266010403633118,
      "learning_rate": 8.244803695150117e-05,
      "loss": 1.4488,
      "step": 76
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7005047798156738,
      "learning_rate": 8.221709006928406e-05,
      "loss": 1.2282,
      "step": 77
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6370469331741333,
      "learning_rate": 8.198614318706698e-05,
      "loss": 0.9865,
      "step": 78
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5986791253089905,
      "learning_rate": 8.175519630484989e-05,
      "loss": 0.762,
      "step": 79
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.590674638748169,
      "learning_rate": 8.15242494226328e-05,
      "loss": 0.9754,
      "step": 80
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7716051936149597,
      "learning_rate": 8.12933025404157e-05,
      "loss": 1.2357,
      "step": 81
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6141093373298645,
      "learning_rate": 8.106235565819862e-05,
      "loss": 1.2884,
      "step": 82
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9501966834068298,
      "learning_rate": 8.083140877598153e-05,
      "loss": 1.4857,
      "step": 83
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5012556910514832,
      "learning_rate": 8.060046189376443e-05,
      "loss": 1.0324,
      "step": 84
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5673837661743164,
      "learning_rate": 8.036951501154734e-05,
      "loss": 1.0732,
      "step": 85
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9634870886802673,
      "learning_rate": 8.013856812933027e-05,
      "loss": 1.2834,
      "step": 86
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6324511170387268,
      "learning_rate": 7.990762124711317e-05,
      "loss": 1.4388,
      "step": 87
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7055947780609131,
      "learning_rate": 7.967667436489608e-05,
      "loss": 0.9513,
      "step": 88
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.050689935684204,
      "learning_rate": 7.944572748267899e-05,
      "loss": 1.4021,
      "step": 89
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6323882937431335,
      "learning_rate": 7.92147806004619e-05,
      "loss": 0.9408,
      "step": 90
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7087694406509399,
      "learning_rate": 7.89838337182448e-05,
      "loss": 1.0525,
      "step": 91
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7272806167602539,
      "learning_rate": 7.875288683602772e-05,
      "loss": 1.0403,
      "step": 92
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1518563032150269,
      "learning_rate": 7.852193995381063e-05,
      "loss": 1.1422,
      "step": 93
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8026465773582458,
      "learning_rate": 7.829099307159353e-05,
      "loss": 1.3559,
      "step": 94
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9015594124794006,
      "learning_rate": 7.806004618937644e-05,
      "loss": 1.4429,
      "step": 95
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6377812027931213,
      "learning_rate": 7.782909930715935e-05,
      "loss": 1.5083,
      "step": 96
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7874252200126648,
      "learning_rate": 7.759815242494227e-05,
      "loss": 1.5141,
      "step": 97
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6445866823196411,
      "learning_rate": 7.736720554272518e-05,
      "loss": 0.98,
      "step": 98
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6904916167259216,
      "learning_rate": 7.71362586605081e-05,
      "loss": 1.4408,
      "step": 99
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7521154284477234,
      "learning_rate": 7.6905311778291e-05,
      "loss": 1.1332,
      "step": 100
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6416658163070679,
      "learning_rate": 7.66743648960739e-05,
      "loss": 0.9846,
      "step": 101
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6785231232643127,
      "learning_rate": 7.644341801385682e-05,
      "loss": 0.8069,
      "step": 102
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6956231594085693,
      "learning_rate": 7.621247113163973e-05,
      "loss": 1.3364,
      "step": 103
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6046852469444275,
      "learning_rate": 7.598152424942263e-05,
      "loss": 0.9554,
      "step": 104
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5413433909416199,
      "learning_rate": 7.575057736720554e-05,
      "loss": 1.0883,
      "step": 105
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5651752352714539,
      "learning_rate": 7.551963048498846e-05,
      "loss": 0.9541,
      "step": 106
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.49770066142082214,
      "learning_rate": 7.528868360277137e-05,
      "loss": 0.9866,
      "step": 107
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6177400350570679,
      "learning_rate": 7.505773672055427e-05,
      "loss": 1.0988,
      "step": 108
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5367798805236816,
      "learning_rate": 7.482678983833718e-05,
      "loss": 0.9886,
      "step": 109
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7266485691070557,
      "learning_rate": 7.45958429561201e-05,
      "loss": 1.2932,
      "step": 110
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.636247456073761,
      "learning_rate": 7.436489607390301e-05,
      "loss": 0.892,
      "step": 111
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5911558866500854,
      "learning_rate": 7.413394919168592e-05,
      "loss": 1.1905,
      "step": 112
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.558164656162262,
      "learning_rate": 7.390300230946883e-05,
      "loss": 1.0273,
      "step": 113
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7261124849319458,
      "learning_rate": 7.367205542725175e-05,
      "loss": 1.6304,
      "step": 114
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6452188491821289,
      "learning_rate": 7.344110854503465e-05,
      "loss": 1.0962,
      "step": 115
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7096442580223083,
      "learning_rate": 7.321016166281756e-05,
      "loss": 1.2266,
      "step": 116
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5936583876609802,
      "learning_rate": 7.297921478060047e-05,
      "loss": 1.0241,
      "step": 117
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7904931306838989,
      "learning_rate": 7.274826789838337e-05,
      "loss": 0.9577,
      "step": 118
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.89790940284729,
      "learning_rate": 7.251732101616628e-05,
      "loss": 1.2961,
      "step": 119
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5825165510177612,
      "learning_rate": 7.22863741339492e-05,
      "loss": 0.9123,
      "step": 120
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8491649627685547,
      "learning_rate": 7.205542725173211e-05,
      "loss": 1.5342,
      "step": 121
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7955842018127441,
      "learning_rate": 7.182448036951501e-05,
      "loss": 1.3265,
      "step": 122
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5736297369003296,
      "learning_rate": 7.159353348729792e-05,
      "loss": 1.0086,
      "step": 123
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6100782752037048,
      "learning_rate": 7.136258660508083e-05,
      "loss": 0.9109,
      "step": 124
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7423821687698364,
      "learning_rate": 7.113163972286375e-05,
      "loss": 1.0931,
      "step": 125
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8508225679397583,
      "learning_rate": 7.090069284064666e-05,
      "loss": 1.3869,
      "step": 126
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5468029975891113,
      "learning_rate": 7.066974595842957e-05,
      "loss": 1.1876,
      "step": 127
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5892660617828369,
      "learning_rate": 7.043879907621247e-05,
      "loss": 1.1662,
      "step": 128
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8112539649009705,
      "learning_rate": 7.020785219399538e-05,
      "loss": 1.4764,
      "step": 129
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5635946989059448,
      "learning_rate": 6.99769053117783e-05,
      "loss": 1.1802,
      "step": 130
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.605717122554779,
      "learning_rate": 6.974595842956121e-05,
      "loss": 1.1614,
      "step": 131
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6112560033798218,
      "learning_rate": 6.951501154734411e-05,
      "loss": 0.9914,
      "step": 132
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7439377307891846,
      "learning_rate": 6.928406466512702e-05,
      "loss": 1.2256,
      "step": 133
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6924118399620056,
      "learning_rate": 6.905311778290994e-05,
      "loss": 1.2749,
      "step": 134
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8105635643005371,
      "learning_rate": 6.882217090069283e-05,
      "loss": 1.0811,
      "step": 135
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6196795701980591,
      "learning_rate": 6.859122401847575e-05,
      "loss": 1.2659,
      "step": 136
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5173664689064026,
      "learning_rate": 6.836027713625866e-05,
      "loss": 1.0372,
      "step": 137
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6062767505645752,
      "learning_rate": 6.812933025404157e-05,
      "loss": 1.1535,
      "step": 138
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5338917970657349,
      "learning_rate": 6.789838337182449e-05,
      "loss": 1.0189,
      "step": 139
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6469847559928894,
      "learning_rate": 6.76674364896074e-05,
      "loss": 1.2202,
      "step": 140
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6842794418334961,
      "learning_rate": 6.743648960739031e-05,
      "loss": 1.4166,
      "step": 141
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6501606702804565,
      "learning_rate": 6.720554272517321e-05,
      "loss": 1.0588,
      "step": 142
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8217818140983582,
      "learning_rate": 6.697459584295612e-05,
      "loss": 1.1435,
      "step": 143
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5860817432403564,
      "learning_rate": 6.674364896073904e-05,
      "loss": 1.2044,
      "step": 144
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5959539413452148,
      "learning_rate": 6.651270207852194e-05,
      "loss": 1.3863,
      "step": 145
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4581656754016876,
      "learning_rate": 6.628175519630485e-05,
      "loss": 1.1459,
      "step": 146
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6370532512664795,
      "learning_rate": 6.605080831408776e-05,
      "loss": 0.8815,
      "step": 147
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5955986380577087,
      "learning_rate": 6.581986143187067e-05,
      "loss": 1.1854,
      "step": 148
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6983250975608826,
      "learning_rate": 6.558891454965357e-05,
      "loss": 1.2067,
      "step": 149
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5966513156890869,
      "learning_rate": 6.535796766743649e-05,
      "loss": 0.8643,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.746486246585846,
      "learning_rate": 6.51270207852194e-05,
      "loss": 1.2969,
      "step": 151
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.709350049495697,
      "learning_rate": 6.489607390300231e-05,
      "loss": 1.4685,
      "step": 152
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8365532159805298,
      "learning_rate": 6.466512702078523e-05,
      "loss": 1.6093,
      "step": 153
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8681790232658386,
      "learning_rate": 6.443418013856814e-05,
      "loss": 0.9668,
      "step": 154
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6299667954444885,
      "learning_rate": 6.420323325635105e-05,
      "loss": 1.3,
      "step": 155
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4736969470977783,
      "learning_rate": 6.397228637413395e-05,
      "loss": 0.8245,
      "step": 156
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5642755627632141,
      "learning_rate": 6.374133949191686e-05,
      "loss": 0.9824,
      "step": 157
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6178954243659973,
      "learning_rate": 6.351039260969978e-05,
      "loss": 1.3946,
      "step": 158
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7917515635490417,
      "learning_rate": 6.327944572748268e-05,
      "loss": 1.0831,
      "step": 159
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6946099400520325,
      "learning_rate": 6.304849884526559e-05,
      "loss": 1.2872,
      "step": 160
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9384307861328125,
      "learning_rate": 6.28175519630485e-05,
      "loss": 1.6378,
      "step": 161
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.640295147895813,
      "learning_rate": 6.25866050808314e-05,
      "loss": 0.9096,
      "step": 162
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5898810625076294,
      "learning_rate": 6.235565819861431e-05,
      "loss": 1.0708,
      "step": 163
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8007053732872009,
      "learning_rate": 6.212471131639723e-05,
      "loss": 1.4934,
      "step": 164
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8391989469528198,
      "learning_rate": 6.189376443418015e-05,
      "loss": 1.3296,
      "step": 165
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9027516841888428,
      "learning_rate": 6.166281755196305e-05,
      "loss": 1.1213,
      "step": 166
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5259537696838379,
      "learning_rate": 6.143187066974596e-05,
      "loss": 0.9641,
      "step": 167
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6903867721557617,
      "learning_rate": 6.120092378752888e-05,
      "loss": 1.2214,
      "step": 168
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7312260866165161,
      "learning_rate": 6.096997690531178e-05,
      "loss": 1.258,
      "step": 169
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7016615867614746,
      "learning_rate": 6.073903002309469e-05,
      "loss": 1.7146,
      "step": 170
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5524300336837769,
      "learning_rate": 6.05080831408776e-05,
      "loss": 1.0477,
      "step": 171
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6852999925613403,
      "learning_rate": 6.0277136258660516e-05,
      "loss": 1.1019,
      "step": 172
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6557573676109314,
      "learning_rate": 6.0046189376443415e-05,
      "loss": 1.0028,
      "step": 173
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7546808123588562,
      "learning_rate": 5.9815242494226335e-05,
      "loss": 1.1849,
      "step": 174
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.831322193145752,
      "learning_rate": 5.958429561200925e-05,
      "loss": 1.1529,
      "step": 175
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9614126086235046,
      "learning_rate": 5.935334872979215e-05,
      "loss": 1.1692,
      "step": 176
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.695743978023529,
      "learning_rate": 5.912240184757506e-05,
      "loss": 1.1016,
      "step": 177
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6409220695495605,
      "learning_rate": 5.889145496535797e-05,
      "loss": 1.2959,
      "step": 178
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6547515392303467,
      "learning_rate": 5.866050808314087e-05,
      "loss": 1.0092,
      "step": 179
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6340076327323914,
      "learning_rate": 5.842956120092379e-05,
      "loss": 1.0929,
      "step": 180
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7406728267669678,
      "learning_rate": 5.8198614318706704e-05,
      "loss": 1.0391,
      "step": 181
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8029519319534302,
      "learning_rate": 5.796766743648962e-05,
      "loss": 1.1482,
      "step": 182
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.807340681552887,
      "learning_rate": 5.7736720554272516e-05,
      "loss": 1.4575,
      "step": 183
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7535825967788696,
      "learning_rate": 5.750577367205543e-05,
      "loss": 1.1332,
      "step": 184
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7517385482788086,
      "learning_rate": 5.727482678983834e-05,
      "loss": 1.1865,
      "step": 185
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6104194521903992,
      "learning_rate": 5.704387990762125e-05,
      "loss": 0.9372,
      "step": 186
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7413724660873413,
      "learning_rate": 5.681293302540416e-05,
      "loss": 1.2259,
      "step": 187
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5767136216163635,
      "learning_rate": 5.6581986143187074e-05,
      "loss": 0.9219,
      "step": 188
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5508605241775513,
      "learning_rate": 5.635103926096999e-05,
      "loss": 0.8628,
      "step": 189
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7309855222702026,
      "learning_rate": 5.6120092378752886e-05,
      "loss": 1.1234,
      "step": 190
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5676395893096924,
      "learning_rate": 5.58891454965358e-05,
      "loss": 1.0802,
      "step": 191
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5213097929954529,
      "learning_rate": 5.565819861431871e-05,
      "loss": 1.1485,
      "step": 192
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.573695182800293,
      "learning_rate": 5.542725173210162e-05,
      "loss": 0.9254,
      "step": 193
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5547528266906738,
      "learning_rate": 5.519630484988453e-05,
      "loss": 1.6491,
      "step": 194
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.583267331123352,
      "learning_rate": 5.4965357967667444e-05,
      "loss": 1.0435,
      "step": 195
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7090733647346497,
      "learning_rate": 5.4734411085450356e-05,
      "loss": 1.2433,
      "step": 196
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6370952129364014,
      "learning_rate": 5.4503464203233256e-05,
      "loss": 0.7876,
      "step": 197
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5483533143997192,
      "learning_rate": 5.427251732101617e-05,
      "loss": 1.3853,
      "step": 198
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6083074808120728,
      "learning_rate": 5.404157043879908e-05,
      "loss": 1.1047,
      "step": 199
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4430088698863983,
      "learning_rate": 5.381062355658199e-05,
      "loss": 0.7726,
      "step": 200
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7283863425254822,
      "learning_rate": 5.35796766743649e-05,
      "loss": 1.4765,
      "step": 201
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5858674049377441,
      "learning_rate": 5.334872979214781e-05,
      "loss": 0.9913,
      "step": 202
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5524507761001587,
      "learning_rate": 5.311778290993071e-05,
      "loss": 1.0321,
      "step": 203
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8980139493942261,
      "learning_rate": 5.2886836027713626e-05,
      "loss": 1.3865,
      "step": 204
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6956557035446167,
      "learning_rate": 5.265588914549654e-05,
      "loss": 1.1624,
      "step": 205
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4873349666595459,
      "learning_rate": 5.242494226327945e-05,
      "loss": 0.992,
      "step": 206
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6562525033950806,
      "learning_rate": 5.219399538106236e-05,
      "loss": 1.3269,
      "step": 207
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6661133766174316,
      "learning_rate": 5.196304849884527e-05,
      "loss": 1.0417,
      "step": 208
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6441981792449951,
      "learning_rate": 5.173210161662818e-05,
      "loss": 1.3095,
      "step": 209
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8442685604095459,
      "learning_rate": 5.150115473441108e-05,
      "loss": 1.5501,
      "step": 210
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6082341074943542,
      "learning_rate": 5.1270207852193995e-05,
      "loss": 1.1976,
      "step": 211
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.615328848361969,
      "learning_rate": 5.103926096997691e-05,
      "loss": 1.1273,
      "step": 212
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5838889479637146,
      "learning_rate": 5.080831408775982e-05,
      "loss": 0.8007,
      "step": 213
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6234093308448792,
      "learning_rate": 5.057736720554273e-05,
      "loss": 1.0443,
      "step": 214
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6111536026000977,
      "learning_rate": 5.034642032332564e-05,
      "loss": 0.9304,
      "step": 215
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6399489045143127,
      "learning_rate": 5.011547344110855e-05,
      "loss": 1.0729,
      "step": 216
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.615061342716217,
      "learning_rate": 4.988452655889146e-05,
      "loss": 0.9302,
      "step": 217
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6260786056518555,
      "learning_rate": 4.9653579676674365e-05,
      "loss": 1.0653,
      "step": 218
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7086613774299622,
      "learning_rate": 4.942263279445728e-05,
      "loss": 1.4331,
      "step": 219
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5983715057373047,
      "learning_rate": 4.919168591224019e-05,
      "loss": 1.0718,
      "step": 220
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6849055290222168,
      "learning_rate": 4.89607390300231e-05,
      "loss": 0.8045,
      "step": 221
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6293378472328186,
      "learning_rate": 4.872979214780601e-05,
      "loss": 1.1954,
      "step": 222
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6034068465232849,
      "learning_rate": 4.8498845265588916e-05,
      "loss": 1.2495,
      "step": 223
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7014632225036621,
      "learning_rate": 4.826789838337183e-05,
      "loss": 1.0104,
      "step": 224
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7799348831176758,
      "learning_rate": 4.8036951501154735e-05,
      "loss": 1.2115,
      "step": 225
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6364681720733643,
      "learning_rate": 4.780600461893765e-05,
      "loss": 1.4495,
      "step": 226
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.629269540309906,
      "learning_rate": 4.757505773672056e-05,
      "loss": 0.8965,
      "step": 227
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6115840077400208,
      "learning_rate": 4.7344110854503466e-05,
      "loss": 0.9827,
      "step": 228
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7040014266967773,
      "learning_rate": 4.711316397228638e-05,
      "loss": 0.9222,
      "step": 229
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9098108410835266,
      "learning_rate": 4.6882217090069285e-05,
      "loss": 1.2453,
      "step": 230
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6183587908744812,
      "learning_rate": 4.665127020785219e-05,
      "loss": 1.2244,
      "step": 231
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6828473806381226,
      "learning_rate": 4.6420323325635104e-05,
      "loss": 1.2252,
      "step": 232
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.578758180141449,
      "learning_rate": 4.618937644341802e-05,
      "loss": 1.1052,
      "step": 233
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5727221965789795,
      "learning_rate": 4.595842956120093e-05,
      "loss": 1.0207,
      "step": 234
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5295357704162598,
      "learning_rate": 4.5727482678983836e-05,
      "loss": 0.8895,
      "step": 235
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5041090846061707,
      "learning_rate": 4.549653579676675e-05,
      "loss": 1.245,
      "step": 236
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7279676795005798,
      "learning_rate": 4.5265588914549655e-05,
      "loss": 1.4903,
      "step": 237
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7031594514846802,
      "learning_rate": 4.503464203233256e-05,
      "loss": 1.1091,
      "step": 238
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5715548396110535,
      "learning_rate": 4.4803695150115474e-05,
      "loss": 0.9799,
      "step": 239
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6250030398368835,
      "learning_rate": 4.457274826789839e-05,
      "loss": 1.3314,
      "step": 240
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.748870849609375,
      "learning_rate": 4.43418013856813e-05,
      "loss": 1.2741,
      "step": 241
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5800572633743286,
      "learning_rate": 4.4110854503464206e-05,
      "loss": 0.8995,
      "step": 242
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5962545275688171,
      "learning_rate": 4.387990762124711e-05,
      "loss": 0.9514,
      "step": 243
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7039762735366821,
      "learning_rate": 4.3648960739030025e-05,
      "loss": 1.6262,
      "step": 244
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6786389350891113,
      "learning_rate": 4.341801385681293e-05,
      "loss": 1.4078,
      "step": 245
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9517892599105835,
      "learning_rate": 4.3187066974595844e-05,
      "loss": 1.3154,
      "step": 246
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6077975630760193,
      "learning_rate": 4.2956120092378757e-05,
      "loss": 0.9482,
      "step": 247
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6827284097671509,
      "learning_rate": 4.272517321016167e-05,
      "loss": 1.3555,
      "step": 248
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.063452124595642,
      "learning_rate": 4.2494226327944576e-05,
      "loss": 1.5395,
      "step": 249
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.937432587146759,
      "learning_rate": 4.226327944572748e-05,
      "loss": 2.0295,
      "step": 250
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.49732404947280884,
      "learning_rate": 4.2032332563510394e-05,
      "loss": 0.8851,
      "step": 251
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6485344171524048,
      "learning_rate": 4.18013856812933e-05,
      "loss": 1.0992,
      "step": 252
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7452957034111023,
      "learning_rate": 4.1570438799076213e-05,
      "loss": 1.2005,
      "step": 253
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.686880350112915,
      "learning_rate": 4.1339491916859126e-05,
      "loss": 1.3275,
      "step": 254
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6837098002433777,
      "learning_rate": 4.110854503464203e-05,
      "loss": 0.8495,
      "step": 255
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6329058408737183,
      "learning_rate": 4.0877598152424945e-05,
      "loss": 0.9077,
      "step": 256
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6141243577003479,
      "learning_rate": 4.064665127020785e-05,
      "loss": 1.2517,
      "step": 257
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5839391350746155,
      "learning_rate": 4.0415704387990764e-05,
      "loss": 1.4203,
      "step": 258
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7274187207221985,
      "learning_rate": 4.018475750577367e-05,
      "loss": 1.1525,
      "step": 259
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6803593635559082,
      "learning_rate": 3.995381062355658e-05,
      "loss": 0.8402,
      "step": 260
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6995021104812622,
      "learning_rate": 3.9722863741339496e-05,
      "loss": 1.2957,
      "step": 261
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5450542569160461,
      "learning_rate": 3.94919168591224e-05,
      "loss": 1.2997,
      "step": 262
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5956547856330872,
      "learning_rate": 3.9260969976905315e-05,
      "loss": 1.0699,
      "step": 263
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6582439541816711,
      "learning_rate": 3.903002309468822e-05,
      "loss": 1.1495,
      "step": 264
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7589648365974426,
      "learning_rate": 3.8799076212471134e-05,
      "loss": 1.1648,
      "step": 265
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7827998995780945,
      "learning_rate": 3.856812933025405e-05,
      "loss": 1.3487,
      "step": 266
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5429435968399048,
      "learning_rate": 3.833718244803695e-05,
      "loss": 1.0493,
      "step": 267
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6658375263214111,
      "learning_rate": 3.8106235565819866e-05,
      "loss": 1.2497,
      "step": 268
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7300008535385132,
      "learning_rate": 3.787528868360277e-05,
      "loss": 1.2649,
      "step": 269
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5298250317573547,
      "learning_rate": 3.7644341801385685e-05,
      "loss": 0.7807,
      "step": 270
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5955215096473694,
      "learning_rate": 3.741339491916859e-05,
      "loss": 1.2658,
      "step": 271
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6581772565841675,
      "learning_rate": 3.7182448036951504e-05,
      "loss": 1.2258,
      "step": 272
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7958313226699829,
      "learning_rate": 3.6951501154734416e-05,
      "loss": 0.9897,
      "step": 273
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1623414754867554,
      "learning_rate": 3.672055427251732e-05,
      "loss": 1.54,
      "step": 274
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6696137189865112,
      "learning_rate": 3.6489607390300235e-05,
      "loss": 0.9636,
      "step": 275
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6067636013031006,
      "learning_rate": 3.625866050808314e-05,
      "loss": 1.2652,
      "step": 276
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6971254944801331,
      "learning_rate": 3.6027713625866054e-05,
      "loss": 1.0877,
      "step": 277
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9581014513969421,
      "learning_rate": 3.579676674364896e-05,
      "loss": 1.1773,
      "step": 278
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.684958815574646,
      "learning_rate": 3.556581986143187e-05,
      "loss": 1.4173,
      "step": 279
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6617326736450195,
      "learning_rate": 3.5334872979214786e-05,
      "loss": 1.0314,
      "step": 280
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6674864888191223,
      "learning_rate": 3.510392609699769e-05,
      "loss": 1.0331,
      "step": 281
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7181568145751953,
      "learning_rate": 3.4872979214780605e-05,
      "loss": 1.1123,
      "step": 282
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6205177307128906,
      "learning_rate": 3.464203233256351e-05,
      "loss": 0.9554,
      "step": 283
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7795842885971069,
      "learning_rate": 3.441108545034642e-05,
      "loss": 1.2317,
      "step": 284
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4916892349720001,
      "learning_rate": 3.418013856812933e-05,
      "loss": 1.1503,
      "step": 285
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5900442600250244,
      "learning_rate": 3.394919168591224e-05,
      "loss": 0.8501,
      "step": 286
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7036773562431335,
      "learning_rate": 3.3718244803695156e-05,
      "loss": 1.0886,
      "step": 287
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7106011509895325,
      "learning_rate": 3.348729792147806e-05,
      "loss": 1.109,
      "step": 288
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5604704022407532,
      "learning_rate": 3.325635103926097e-05,
      "loss": 1.3281,
      "step": 289
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8849707841873169,
      "learning_rate": 3.302540415704388e-05,
      "loss": 1.2857,
      "step": 290
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.994551420211792,
      "learning_rate": 3.279445727482679e-05,
      "loss": 1.0253,
      "step": 291
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7556214332580566,
      "learning_rate": 3.25635103926097e-05,
      "loss": 1.2211,
      "step": 292
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5440333485603333,
      "learning_rate": 3.233256351039261e-05,
      "loss": 0.9234,
      "step": 293
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6727986335754395,
      "learning_rate": 3.2101616628175526e-05,
      "loss": 1.63,
      "step": 294
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6568259000778198,
      "learning_rate": 3.187066974595843e-05,
      "loss": 1.2872,
      "step": 295
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6315668821334839,
      "learning_rate": 3.163972286374134e-05,
      "loss": 0.9251,
      "step": 296
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6996174454689026,
      "learning_rate": 3.140877598152425e-05,
      "loss": 0.981,
      "step": 297
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5558082461357117,
      "learning_rate": 3.117782909930716e-05,
      "loss": 0.9107,
      "step": 298
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6836870312690735,
      "learning_rate": 3.0946882217090076e-05,
      "loss": 1.3667,
      "step": 299
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6944900155067444,
      "learning_rate": 3.071593533487298e-05,
      "loss": 1.2893,
      "step": 300
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5826818346977234,
      "learning_rate": 3.048498845265589e-05,
      "loss": 1.1005,
      "step": 301
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6149059534072876,
      "learning_rate": 3.02540415704388e-05,
      "loss": 1.0797,
      "step": 302
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6584354043006897,
      "learning_rate": 3.0023094688221707e-05,
      "loss": 1.1321,
      "step": 303
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7319487929344177,
      "learning_rate": 2.9792147806004624e-05,
      "loss": 1.5425,
      "step": 304
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6964814066886902,
      "learning_rate": 2.956120092378753e-05,
      "loss": 1.2244,
      "step": 305
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6413137912750244,
      "learning_rate": 2.9330254041570436e-05,
      "loss": 1.144,
      "step": 306
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8962225914001465,
      "learning_rate": 2.9099307159353352e-05,
      "loss": 1.2485,
      "step": 307
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6088312268257141,
      "learning_rate": 2.8868360277136258e-05,
      "loss": 1.1202,
      "step": 308
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.571694016456604,
      "learning_rate": 2.863741339491917e-05,
      "loss": 1.1174,
      "step": 309
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6141538619995117,
      "learning_rate": 2.840646651270208e-05,
      "loss": 1.1493,
      "step": 310
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.808792233467102,
      "learning_rate": 2.8175519630484993e-05,
      "loss": 1.259,
      "step": 311
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.47373443841934204,
      "learning_rate": 2.79445727482679e-05,
      "loss": 0.9899,
      "step": 312
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6130377054214478,
      "learning_rate": 2.771362586605081e-05,
      "loss": 1.4181,
      "step": 313
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8211190104484558,
      "learning_rate": 2.7482678983833722e-05,
      "loss": 1.6237,
      "step": 314
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5214871168136597,
      "learning_rate": 2.7251732101616628e-05,
      "loss": 0.8193,
      "step": 315
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4748308062553406,
      "learning_rate": 2.702078521939954e-05,
      "loss": 0.8413,
      "step": 316
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6986903548240662,
      "learning_rate": 2.678983833718245e-05,
      "loss": 1.1393,
      "step": 317
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6819972395896912,
      "learning_rate": 2.6558891454965356e-05,
      "loss": 1.1177,
      "step": 318
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5828747749328613,
      "learning_rate": 2.632794457274827e-05,
      "loss": 1.2746,
      "step": 319
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6186408996582031,
      "learning_rate": 2.609699769053118e-05,
      "loss": 1.1114,
      "step": 320
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6909712553024292,
      "learning_rate": 2.586605080831409e-05,
      "loss": 1.0633,
      "step": 321
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6006143689155579,
      "learning_rate": 2.5635103926096998e-05,
      "loss": 0.9671,
      "step": 322
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7531188130378723,
      "learning_rate": 2.540415704387991e-05,
      "loss": 1.1837,
      "step": 323
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9135515689849854,
      "learning_rate": 2.517321016166282e-05,
      "loss": 1.3913,
      "step": 324
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6830499768257141,
      "learning_rate": 2.494226327944573e-05,
      "loss": 1.069,
      "step": 325
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7192435264587402,
      "learning_rate": 2.471131639722864e-05,
      "loss": 1.0868,
      "step": 326
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6242456436157227,
      "learning_rate": 2.448036951501155e-05,
      "loss": 0.974,
      "step": 327
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5996115207672119,
      "learning_rate": 2.4249422632794458e-05,
      "loss": 1.2022,
      "step": 328
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6854118704795837,
      "learning_rate": 2.4018475750577367e-05,
      "loss": 1.2834,
      "step": 329
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7951475977897644,
      "learning_rate": 2.378752886836028e-05,
      "loss": 1.5543,
      "step": 330
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7480990290641785,
      "learning_rate": 2.355658198614319e-05,
      "loss": 1.3514,
      "step": 331
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5712164044380188,
      "learning_rate": 2.3325635103926096e-05,
      "loss": 1.0465,
      "step": 332
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5975993275642395,
      "learning_rate": 2.309468822170901e-05,
      "loss": 1.0303,
      "step": 333
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9328867793083191,
      "learning_rate": 2.2863741339491918e-05,
      "loss": 1.1816,
      "step": 334
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5094149112701416,
      "learning_rate": 2.2632794457274828e-05,
      "loss": 0.8974,
      "step": 335
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6454190611839294,
      "learning_rate": 2.2401847575057737e-05,
      "loss": 0.9949,
      "step": 336
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5644716620445251,
      "learning_rate": 2.217090069284065e-05,
      "loss": 0.9442,
      "step": 337
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6831125617027283,
      "learning_rate": 2.1939953810623556e-05,
      "loss": 1.2315,
      "step": 338
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.639931321144104,
      "learning_rate": 2.1709006928406465e-05,
      "loss": 1.1977,
      "step": 339
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7066858410835266,
      "learning_rate": 2.1478060046189378e-05,
      "loss": 1.0419,
      "step": 340
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6378226280212402,
      "learning_rate": 2.1247113163972288e-05,
      "loss": 1.7477,
      "step": 341
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6431068181991577,
      "learning_rate": 2.1016166281755197e-05,
      "loss": 1.2252,
      "step": 342
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5516421794891357,
      "learning_rate": 2.0785219399538107e-05,
      "loss": 1.2249,
      "step": 343
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5857992768287659,
      "learning_rate": 2.0554272517321016e-05,
      "loss": 1.6025,
      "step": 344
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0386868715286255,
      "learning_rate": 2.0323325635103926e-05,
      "loss": 1.5743,
      "step": 345
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8322114944458008,
      "learning_rate": 2.0092378752886835e-05,
      "loss": 1.433,
      "step": 346
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6743536591529846,
      "learning_rate": 1.9861431870669748e-05,
      "loss": 1.1659,
      "step": 347
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6952770948410034,
      "learning_rate": 1.9630484988452657e-05,
      "loss": 1.3052,
      "step": 348
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6402193903923035,
      "learning_rate": 1.9399538106235567e-05,
      "loss": 1.2096,
      "step": 349
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0055774450302124,
      "learning_rate": 1.9168591224018476e-05,
      "loss": 1.1081,
      "step": 350
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.864611804485321,
      "learning_rate": 1.8937644341801386e-05,
      "loss": 1.2137,
      "step": 351
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7737880349159241,
      "learning_rate": 1.8706697459584295e-05,
      "loss": 1.5423,
      "step": 352
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8066962361335754,
      "learning_rate": 1.8475750577367208e-05,
      "loss": 1.5897,
      "step": 353
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6740752458572388,
      "learning_rate": 1.8244803695150118e-05,
      "loss": 0.9792,
      "step": 354
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5285582542419434,
      "learning_rate": 1.8013856812933027e-05,
      "loss": 1.0213,
      "step": 355
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5914124846458435,
      "learning_rate": 1.7782909930715937e-05,
      "loss": 1.021,
      "step": 356
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6450713276863098,
      "learning_rate": 1.7551963048498846e-05,
      "loss": 1.2571,
      "step": 357
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.094211220741272,
      "learning_rate": 1.7321016166281756e-05,
      "loss": 1.2569,
      "step": 358
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6568135619163513,
      "learning_rate": 1.7090069284064665e-05,
      "loss": 1.1187,
      "step": 359
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5724815726280212,
      "learning_rate": 1.6859122401847578e-05,
      "loss": 0.9694,
      "step": 360
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8528203368186951,
      "learning_rate": 1.6628175519630484e-05,
      "loss": 1.6255,
      "step": 361
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7205151319503784,
      "learning_rate": 1.6397228637413393e-05,
      "loss": 1.1337,
      "step": 362
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5519550442695618,
      "learning_rate": 1.6166281755196306e-05,
      "loss": 0.7697,
      "step": 363
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0401818752288818,
      "learning_rate": 1.5935334872979216e-05,
      "loss": 1.339,
      "step": 364
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4379380941390991,
      "learning_rate": 1.5704387990762125e-05,
      "loss": 1.5439,
      "step": 365
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6235213279724121,
      "learning_rate": 1.5473441108545038e-05,
      "loss": 1.084,
      "step": 366
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.672027051448822,
      "learning_rate": 1.5242494226327944e-05,
      "loss": 1.3229,
      "step": 367
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5569518804550171,
      "learning_rate": 1.5011547344110854e-05,
      "loss": 0.8697,
      "step": 368
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5976542830467224,
      "learning_rate": 1.4780600461893765e-05,
      "loss": 0.9417,
      "step": 369
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6742978096008301,
      "learning_rate": 1.4549653579676676e-05,
      "loss": 0.9619,
      "step": 370
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8110527396202087,
      "learning_rate": 1.4318706697459586e-05,
      "loss": 1.1081,
      "step": 371
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7877007722854614,
      "learning_rate": 1.4087759815242497e-05,
      "loss": 1.3592,
      "step": 372
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7997602224349976,
      "learning_rate": 1.3856812933025404e-05,
      "loss": 1.2977,
      "step": 373
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6455217003822327,
      "learning_rate": 1.3625866050808314e-05,
      "loss": 1.2178,
      "step": 374
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6878575086593628,
      "learning_rate": 1.3394919168591225e-05,
      "loss": 1.1687,
      "step": 375
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7163199186325073,
      "learning_rate": 1.3163972286374135e-05,
      "loss": 1.1795,
      "step": 376
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6507314443588257,
      "learning_rate": 1.2933025404157046e-05,
      "loss": 1.184,
      "step": 377
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.47500699758529663,
      "learning_rate": 1.2702078521939955e-05,
      "loss": 0.7738,
      "step": 378
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6501362323760986,
      "learning_rate": 1.2471131639722865e-05,
      "loss": 0.948,
      "step": 379
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2649705410003662,
      "learning_rate": 1.2240184757505774e-05,
      "loss": 1.594,
      "step": 380
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6714444160461426,
      "learning_rate": 1.2009237875288684e-05,
      "loss": 1.1925,
      "step": 381
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7186347246170044,
      "learning_rate": 1.1778290993071595e-05,
      "loss": 1.0153,
      "step": 382
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.838364839553833,
      "learning_rate": 1.1547344110854504e-05,
      "loss": 1.2616,
      "step": 383
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6191871166229248,
      "learning_rate": 1.1316397228637414e-05,
      "loss": 1.1428,
      "step": 384
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5674224495887756,
      "learning_rate": 1.1085450346420325e-05,
      "loss": 0.9166,
      "step": 385
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6889145970344543,
      "learning_rate": 1.0854503464203233e-05,
      "loss": 1.2877,
      "step": 386
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6644319891929626,
      "learning_rate": 1.0623556581986144e-05,
      "loss": 1.3043,
      "step": 387
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.968376636505127,
      "learning_rate": 1.0392609699769053e-05,
      "loss": 1.3192,
      "step": 388
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8687054514884949,
      "learning_rate": 1.0161662817551963e-05,
      "loss": 1.4184,
      "step": 389
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8458670973777771,
      "learning_rate": 9.930715935334874e-06,
      "loss": 1.2396,
      "step": 390
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5742601156234741,
      "learning_rate": 9.699769053117783e-06,
      "loss": 1.3257,
      "step": 391
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7386878728866577,
      "learning_rate": 9.468822170900693e-06,
      "loss": 1.2816,
      "step": 392
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6845839619636536,
      "learning_rate": 9.237875288683604e-06,
      "loss": 1.4591,
      "step": 393
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6172453761100769,
      "learning_rate": 9.006928406466514e-06,
      "loss": 1.3919,
      "step": 394
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8049135208129883,
      "learning_rate": 8.775981524249423e-06,
      "loss": 1.1972,
      "step": 395
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5362932682037354,
      "learning_rate": 8.545034642032333e-06,
      "loss": 1.0299,
      "step": 396
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5450180768966675,
      "learning_rate": 8.314087759815242e-06,
      "loss": 1.114,
      "step": 397
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8306377530097961,
      "learning_rate": 8.083140877598153e-06,
      "loss": 1.4128,
      "step": 398
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5430389642715454,
      "learning_rate": 7.852193995381063e-06,
      "loss": 0.9766,
      "step": 399
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1897504329681396,
      "learning_rate": 7.621247113163972e-06,
      "loss": 1.6631,
      "step": 400
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9911413788795471,
      "learning_rate": 7.3903002309468824e-06,
      "loss": 1.3587,
      "step": 401
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5336215496063232,
      "learning_rate": 7.159353348729793e-06,
      "loss": 1.1191,
      "step": 402
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6321917176246643,
      "learning_rate": 6.928406466512702e-06,
      "loss": 0.9782,
      "step": 403
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7602062225341797,
      "learning_rate": 6.6974595842956126e-06,
      "loss": 1.1411,
      "step": 404
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.560089111328125,
      "learning_rate": 6.466512702078523e-06,
      "loss": 1.0493,
      "step": 405
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8534475564956665,
      "learning_rate": 6.235565819861432e-06,
      "loss": 1.3302,
      "step": 406
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7205557227134705,
      "learning_rate": 6.004618937644342e-06,
      "loss": 1.0918,
      "step": 407
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.783995509147644,
      "learning_rate": 5.773672055427252e-06,
      "loss": 1.3652,
      "step": 408
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5600685477256775,
      "learning_rate": 5.5427251732101625e-06,
      "loss": 0.8581,
      "step": 409
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7258281707763672,
      "learning_rate": 5.311778290993072e-06,
      "loss": 1.2506,
      "step": 410
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.638174831867218,
      "learning_rate": 5.080831408775981e-06,
      "loss": 1.2452,
      "step": 411
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9520972371101379,
      "learning_rate": 4.849884526558892e-06,
      "loss": 1.3326,
      "step": 412
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.555042564868927,
      "learning_rate": 4.618937644341802e-06,
      "loss": 1.2895,
      "step": 413
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6640222072601318,
      "learning_rate": 4.3879907621247115e-06,
      "loss": 1.2166,
      "step": 414
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6695938110351562,
      "learning_rate": 4.157043879907621e-06,
      "loss": 1.2785,
      "step": 415
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6199811697006226,
      "learning_rate": 3.926096997690531e-06,
      "loss": 1.4049,
      "step": 416
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6540294885635376,
      "learning_rate": 3.6951501154734412e-06,
      "loss": 1.1304,
      "step": 417
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8126841187477112,
      "learning_rate": 3.464203233256351e-06,
      "loss": 1.0084,
      "step": 418
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5479701161384583,
      "learning_rate": 3.2332563510392614e-06,
      "loss": 0.9332,
      "step": 419
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6639834642410278,
      "learning_rate": 3.002309468822171e-06,
      "loss": 0.9619,
      "step": 420
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6356250643730164,
      "learning_rate": 2.7713625866050812e-06,
      "loss": 0.858,
      "step": 421
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5527121424674988,
      "learning_rate": 2.5404157043879907e-06,
      "loss": 1.3301,
      "step": 422
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5982433557510376,
      "learning_rate": 2.309468822170901e-06,
      "loss": 1.2748,
      "step": 423
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5894596576690674,
      "learning_rate": 2.0785219399538105e-06,
      "loss": 0.9656,
      "step": 424
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6226515769958496,
      "learning_rate": 1.8475750577367206e-06,
      "loss": 1.3148,
      "step": 425
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6193553805351257,
      "learning_rate": 1.6166281755196307e-06,
      "loss": 0.9348,
      "step": 426
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6331142783164978,
      "learning_rate": 1.3856812933025406e-06,
      "loss": 1.1052,
      "step": 427
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.8083781599998474,
      "learning_rate": 1.1547344110854505e-06,
      "loss": 1.2884,
      "step": 428
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.8217892050743103,
      "learning_rate": 9.237875288683603e-07,
      "loss": 1.1296,
      "step": 429
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.798355758190155,
      "learning_rate": 6.928406466512703e-07,
      "loss": 1.1947,
      "step": 430
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5520275235176086,
      "learning_rate": 4.6189376443418015e-07,
      "loss": 1.0995,
      "step": 431
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5632410645484924,
      "learning_rate": 2.3094688221709008e-07,
      "loss": 0.8671,
      "step": 432
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0363011360168457,
      "learning_rate": 0.0,
      "loss": 1.0433,
      "step": 433
    }
  ],
  "logging_steps": 1,
  "max_steps": 433,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 7.591291838162534e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
