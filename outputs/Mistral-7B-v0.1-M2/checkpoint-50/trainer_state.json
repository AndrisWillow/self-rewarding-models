{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3460207612456747,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 6.141585350036621,
      "learning_rate": 1.0000000000000002e-06,
      "logits/chosen": -3.346715211868286,
      "logits/rejected": -3.2444629669189453,
      "logps/chosen": -138.24136352539062,
      "logps/rejected": -150.94151306152344,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.989639759063721,
      "learning_rate": 2.0000000000000003e-06,
      "logits/chosen": -3.271775245666504,
      "logits/rejected": -3.2405569553375244,
      "logps/chosen": -143.83303833007812,
      "logps/rejected": -138.79763793945312,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.086217880249023,
      "learning_rate": 3e-06,
      "logits/chosen": -3.261810541152954,
      "logits/rejected": -3.2316901683807373,
      "logps/chosen": -141.06390380859375,
      "logps/rejected": -141.53182983398438,
      "loss": 0.6933,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 8.00132766016759e-05,
      "rewards/margins": -0.0003061771276406944,
      "rewards/rejected": 0.0003861904260702431,
      "step": 3
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.859605312347412,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -3.264397144317627,
      "logits/rejected": -3.232842445373535,
      "logps/chosen": -150.72149658203125,
      "logps/rejected": -139.00973510742188,
      "loss": 0.6937,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": -0.0029015541076660156,
      "rewards/margins": -0.0011773469159379601,
      "rewards/rejected": -0.0017242074245586991,
      "step": 4
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.5662407875061035,
      "learning_rate": 5e-06,
      "logits/chosen": -3.290571689605713,
      "logits/rejected": -3.298363447189331,
      "logps/chosen": -148.358154296875,
      "logps/rejected": -134.16754150390625,
      "loss": 0.6936,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": -0.004667234607040882,
      "rewards/margins": -0.0008547782781533897,
      "rewards/rejected": -0.003812456037849188,
      "step": 5
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.062233924865723,
      "learning_rate": 6e-06,
      "logits/chosen": -3.201636791229248,
      "logits/rejected": -3.1123669147491455,
      "logps/chosen": -153.441650390625,
      "logps/rejected": -134.43588256835938,
      "loss": 0.6918,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.0004753112734761089,
      "rewards/margins": 0.002639722777530551,
      "rewards/rejected": -0.0021644115913659334,
      "step": 6
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.859575271606445,
      "learning_rate": 7.000000000000001e-06,
      "logits/chosen": -3.3045454025268555,
      "logits/rejected": -3.286703586578369,
      "logps/chosen": -151.56591796875,
      "logps/rejected": -146.59869384765625,
      "loss": 0.6922,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0032695773988962173,
      "rewards/margins": 0.001950955716893077,
      "rewards/rejected": 0.0013186216820031404,
      "step": 7
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.027541637420654,
      "learning_rate": 8.000000000000001e-06,
      "logits/chosen": -3.1903135776519775,
      "logits/rejected": -3.2801167964935303,
      "logps/chosen": -147.8193359375,
      "logps/rejected": -141.56976318359375,
      "loss": 0.6923,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.01061716116964817,
      "rewards/margins": 0.001789378933608532,
      "rewards/rejected": 0.008827782236039639,
      "step": 8
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.912154674530029,
      "learning_rate": 9e-06,
      "logits/chosen": -3.326453924179077,
      "logits/rejected": -3.2121286392211914,
      "logps/chosen": -146.55613708496094,
      "logps/rejected": -129.68983459472656,
      "loss": 0.684,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.027178145945072174,
      "rewards/margins": 0.018522167578339577,
      "rewards/rejected": 0.008655977435410023,
      "step": 9
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.515043258666992,
      "learning_rate": 1e-05,
      "logits/chosen": -3.22833514213562,
      "logits/rejected": -3.118565082550049,
      "logps/chosen": -145.71188354492188,
      "logps/rejected": -138.9409637451172,
      "loss": 0.686,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.034871816635131836,
      "rewards/margins": 0.014553798362612724,
      "rewards/rejected": 0.02031802013516426,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.0281171798706055,
      "learning_rate": 1.1000000000000001e-05,
      "logits/chosen": -3.287292957305908,
      "logits/rejected": -3.216792106628418,
      "logps/chosen": -145.5790557861328,
      "logps/rejected": -142.43606567382812,
      "loss": 0.6879,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.048727847635746,
      "rewards/margins": 0.010821651667356491,
      "rewards/rejected": 0.03790619596838951,
      "step": 11
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.724010944366455,
      "learning_rate": 1.2e-05,
      "logits/chosen": -3.249142646789551,
      "logits/rejected": -3.214574098587036,
      "logps/chosen": -152.59796142578125,
      "logps/rejected": -141.43252563476562,
      "loss": 0.6913,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.05833544582128525,
      "rewards/margins": 0.00426635704934597,
      "rewards/rejected": 0.05406908690929413,
      "step": 12
    },
    {
      "epoch": 0.09,
      "grad_norm": 6.84904146194458,
      "learning_rate": 1.3000000000000001e-05,
      "logits/chosen": -3.2121529579162598,
      "logits/rejected": -3.1299824714660645,
      "logps/chosen": -142.16909790039062,
      "logps/rejected": -153.28271484375,
      "loss": 0.704,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.05987153202295303,
      "rewards/margins": -0.020838715136051178,
      "rewards/rejected": 0.08071024715900421,
      "step": 13
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.866154670715332,
      "learning_rate": 1.4000000000000001e-05,
      "logits/chosen": -3.2647433280944824,
      "logits/rejected": -3.2010202407836914,
      "logps/chosen": -131.82708740234375,
      "logps/rejected": -137.00526428222656,
      "loss": 0.6999,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.04401083290576935,
      "rewards/margins": -0.012804936617612839,
      "rewards/rejected": 0.05681576952338219,
      "step": 14
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.310549736022949,
      "learning_rate": 1.5e-05,
      "logits/chosen": -3.2926807403564453,
      "logits/rejected": -3.2725088596343994,
      "logps/chosen": -151.80209350585938,
      "logps/rejected": -155.89149475097656,
      "loss": 0.68,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.08516999334096909,
      "rewards/margins": 0.027340270578861237,
      "rewards/rejected": 0.057829711586236954,
      "step": 15
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.7516703605651855,
      "learning_rate": 1.6000000000000003e-05,
      "logits/chosen": -3.2754924297332764,
      "logits/rejected": -3.28617525100708,
      "logps/chosen": -136.51162719726562,
      "logps/rejected": -130.63442993164062,
      "loss": 0.6673,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.0831860601902008,
      "rewards/margins": 0.05432166904211044,
      "rewards/rejected": 0.028864383697509766,
      "step": 16
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.797226905822754,
      "learning_rate": 1.7000000000000003e-05,
      "logits/chosen": -3.296746253967285,
      "logits/rejected": -3.1935806274414062,
      "logps/chosen": -158.09046936035156,
      "logps/rejected": -151.04403686523438,
      "loss": 0.6894,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.10114370286464691,
      "rewards/margins": 0.008669639006257057,
      "rewards/rejected": 0.0924740582704544,
      "step": 17
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.225539207458496,
      "learning_rate": 1.8e-05,
      "logits/chosen": -3.268474817276001,
      "logits/rejected": -3.205653190612793,
      "logps/chosen": -139.9774627685547,
      "logps/rejected": -153.93798828125,
      "loss": 0.677,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.10045298933982849,
      "rewards/margins": 0.03345336765050888,
      "rewards/rejected": 0.06699962913990021,
      "step": 18
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.605353355407715,
      "learning_rate": 1.9e-05,
      "logits/chosen": -3.2743356227874756,
      "logits/rejected": -3.24658203125,
      "logps/chosen": -149.18650817871094,
      "logps/rejected": -142.71371459960938,
      "loss": 0.6788,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.11337576061487198,
      "rewards/margins": 0.030154800042510033,
      "rewards/rejected": 0.0832209587097168,
      "step": 19
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.870824337005615,
      "learning_rate": 2e-05,
      "logits/chosen": -3.3732457160949707,
      "logits/rejected": -3.39237904548645,
      "logps/chosen": -145.0191650390625,
      "logps/rejected": -148.88177490234375,
      "loss": 0.6762,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.15734362602233887,
      "rewards/margins": 0.0361139252781868,
      "rewards/rejected": 0.12122970074415207,
      "step": 20
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.742175579071045,
      "learning_rate": 2.1e-05,
      "logits/chosen": -3.292931079864502,
      "logits/rejected": -3.236729621887207,
      "logps/chosen": -150.2421417236328,
      "logps/rejected": -138.38890075683594,
      "loss": 0.6645,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.15239687263965607,
      "rewards/margins": 0.06025762856006622,
      "rewards/rejected": 0.09213924407958984,
      "step": 21
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.781131267547607,
      "learning_rate": 2.2000000000000003e-05,
      "logits/chosen": -3.206973075866699,
      "logits/rejected": -3.026340961456299,
      "logps/chosen": -146.58206176757812,
      "logps/rejected": -137.3058319091797,
      "loss": 0.641,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.13370281457901,
      "rewards/margins": 0.11375799775123596,
      "rewards/rejected": 0.0199448075145483,
      "step": 22
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.921952724456787,
      "learning_rate": 2.3000000000000003e-05,
      "logits/chosen": -3.270634174346924,
      "logits/rejected": -3.142695903778076,
      "logps/chosen": -138.81483459472656,
      "logps/rejected": -128.24649047851562,
      "loss": 0.6684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.1649819016456604,
      "rewards/margins": 0.05348759517073631,
      "rewards/rejected": 0.1114942878484726,
      "step": 23
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.7870774269104,
      "learning_rate": 2.4e-05,
      "logits/chosen": -3.219816207885742,
      "logits/rejected": -3.1576337814331055,
      "logps/chosen": -160.30322265625,
      "logps/rejected": -149.44801330566406,
      "loss": 0.6673,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.23202210664749146,
      "rewards/margins": 0.0566713809967041,
      "rewards/rejected": 0.17535072565078735,
      "step": 24
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.08160400390625,
      "learning_rate": 2.5e-05,
      "logits/chosen": -3.2069942951202393,
      "logits/rejected": -3.179584503173828,
      "logps/chosen": -143.78213500976562,
      "logps/rejected": -131.2345428466797,
      "loss": 0.6751,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.21495673060417175,
      "rewards/margins": 0.053181231021881104,
      "rewards/rejected": 0.16177548468112946,
      "step": 25
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.6014323234558105,
      "learning_rate": 2.6000000000000002e-05,
      "logits/chosen": -3.354249954223633,
      "logits/rejected": -3.3961715698242188,
      "logps/chosen": -146.30517578125,
      "logps/rejected": -131.28121948242188,
      "loss": 0.6657,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.30466461181640625,
      "rewards/margins": 0.06038656830787659,
      "rewards/rejected": 0.24427805840969086,
      "step": 26
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.624319553375244,
      "learning_rate": 2.7000000000000002e-05,
      "logits/chosen": -3.310346841812134,
      "logits/rejected": -3.2899203300476074,
      "logps/chosen": -137.28175354003906,
      "logps/rejected": -128.47076416015625,
      "loss": 0.6638,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.35366299748420715,
      "rewards/margins": 0.06835298240184784,
      "rewards/rejected": 0.2853100001811981,
      "step": 27
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.334454536437988,
      "learning_rate": 2.8000000000000003e-05,
      "logits/chosen": -3.1934821605682373,
      "logits/rejected": -3.2029857635498047,
      "logps/chosen": -159.27230834960938,
      "logps/rejected": -147.5938720703125,
      "loss": 0.7393,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.30865615606307983,
      "rewards/margins": -0.06403222680091858,
      "rewards/rejected": 0.3726884126663208,
      "step": 28
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.187200546264648,
      "learning_rate": 2.9e-05,
      "logits/chosen": -3.2371232509613037,
      "logits/rejected": -3.25355863571167,
      "logps/chosen": -147.38552856445312,
      "logps/rejected": -145.2686767578125,
      "loss": 0.616,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.36923137307167053,
      "rewards/margins": 0.18697531521320343,
      "rewards/rejected": 0.1822560578584671,
      "step": 29
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.5452351570129395,
      "learning_rate": 3e-05,
      "logits/chosen": -3.175556182861328,
      "logits/rejected": -3.0328381061553955,
      "logps/chosen": -150.96331787109375,
      "logps/rejected": -126.9589614868164,
      "loss": 0.5907,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.42621833086013794,
      "rewards/margins": 0.2467699944972992,
      "rewards/rejected": 0.17944836616516113,
      "step": 30
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.004733085632324,
      "learning_rate": 3.1e-05,
      "logits/chosen": -3.1870222091674805,
      "logits/rejected": -3.0686120986938477,
      "logps/chosen": -148.205078125,
      "logps/rejected": -136.6865234375,
      "loss": 0.6797,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.2748522162437439,
      "rewards/margins": 0.04066508263349533,
      "rewards/rejected": 0.23418711125850677,
      "step": 31
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.3970561027526855,
      "learning_rate": 3.2000000000000005e-05,
      "logits/chosen": -3.238502025604248,
      "logits/rejected": -3.122957944869995,
      "logps/chosen": -142.3126220703125,
      "logps/rejected": -134.23670959472656,
      "loss": 0.6114,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.31844544410705566,
      "rewards/margins": 0.18613338470458984,
      "rewards/rejected": 0.13231205940246582,
      "step": 32
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.220339775085449,
      "learning_rate": 3.3e-05,
      "logits/chosen": -3.346632480621338,
      "logits/rejected": -3.2708852291107178,
      "logps/chosen": -143.6239013671875,
      "logps/rejected": -148.83163452148438,
      "loss": 0.608,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.40731915831565857,
      "rewards/margins": 0.2013557106256485,
      "rewards/rejected": 0.20596347749233246,
      "step": 33
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.685837268829346,
      "learning_rate": 3.4000000000000007e-05,
      "logits/chosen": -3.3271188735961914,
      "logits/rejected": -3.282475233078003,
      "logps/chosen": -137.33920288085938,
      "logps/rejected": -128.36941528320312,
      "loss": 0.636,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.38574647903442383,
      "rewards/margins": 0.15486013889312744,
      "rewards/rejected": 0.23088636994361877,
      "step": 34
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.4545698165893555,
      "learning_rate": 3.5e-05,
      "logits/chosen": -3.20888352394104,
      "logits/rejected": -3.318234920501709,
      "logps/chosen": -161.35430908203125,
      "logps/rejected": -146.4923095703125,
      "loss": 0.5668,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.46077677607536316,
      "rewards/margins": 0.2978353500366211,
      "rewards/rejected": 0.16294141113758087,
      "step": 35
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.01379919052124,
      "learning_rate": 3.6e-05,
      "logits/chosen": -3.354652166366577,
      "logits/rejected": -3.217876672744751,
      "logps/chosen": -136.27059936523438,
      "logps/rejected": -141.99398803710938,
      "loss": 0.6673,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.5364944934844971,
      "rewards/margins": 0.07477405667304993,
      "rewards/rejected": 0.46172046661376953,
      "step": 36
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.105350494384766,
      "learning_rate": 3.7e-05,
      "logits/chosen": -3.359438896179199,
      "logits/rejected": -3.2696123123168945,
      "logps/chosen": -143.84423828125,
      "logps/rejected": -147.6449737548828,
      "loss": 0.5749,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4854781925678253,
      "rewards/margins": 0.27855589985847473,
      "rewards/rejected": 0.20692230761051178,
      "step": 37
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.856078624725342,
      "learning_rate": 3.8e-05,
      "logits/chosen": -3.3364107608795166,
      "logits/rejected": -3.2498703002929688,
      "logps/chosen": -141.42575073242188,
      "logps/rejected": -146.66183471679688,
      "loss": 0.7246,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.30602893233299255,
      "rewards/margins": 0.01204880140721798,
      "rewards/rejected": 0.29398012161254883,
      "step": 38
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.540553092956543,
      "learning_rate": 3.9000000000000006e-05,
      "logits/chosen": -3.161128044128418,
      "logits/rejected": -3.2630233764648438,
      "logps/chosen": -140.84796142578125,
      "logps/rejected": -136.1658935546875,
      "loss": 0.6663,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.4658937454223633,
      "rewards/margins": 0.11058767884969711,
      "rewards/rejected": 0.3553060293197632,
      "step": 39
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.718908309936523,
      "learning_rate": 4e-05,
      "logits/chosen": -3.2105162143707275,
      "logits/rejected": -3.2663917541503906,
      "logps/chosen": -150.45584106445312,
      "logps/rejected": -160.94448852539062,
      "loss": 0.7024,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.42014628648757935,
      "rewards/margins": 0.02507953718304634,
      "rewards/rejected": 0.3950667381286621,
      "step": 40
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.27574348449707,
      "learning_rate": 4.1e-05,
      "logits/chosen": -3.271210193634033,
      "logits/rejected": -3.09885311126709,
      "logps/chosen": -151.17410278320312,
      "logps/rejected": -132.6771697998047,
      "loss": 0.5689,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.6097215414047241,
      "rewards/margins": 0.3458341360092163,
      "rewards/rejected": 0.2638874650001526,
      "step": 41
    },
    {
      "epoch": 0.29,
      "grad_norm": 6.294437408447266,
      "learning_rate": 4.2e-05,
      "logits/chosen": -3.195157766342163,
      "logits/rejected": -3.137610673904419,
      "logps/chosen": -144.83059692382812,
      "logps/rejected": -130.96067810058594,
      "loss": 0.6007,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.4412651062011719,
      "rewards/margins": 0.29653841257095337,
      "rewards/rejected": 0.1447266936302185,
      "step": 42
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.978677749633789,
      "learning_rate": 4.3e-05,
      "logits/chosen": -3.377298593521118,
      "logits/rejected": -3.2460060119628906,
      "logps/chosen": -144.01370239257812,
      "logps/rejected": -125.0660629272461,
      "loss": 0.7012,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.4480781853199005,
      "rewards/margins": 0.055984582751989365,
      "rewards/rejected": 0.39209362864494324,
      "step": 43
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.02454137802124,
      "learning_rate": 4.4000000000000006e-05,
      "logits/chosen": -3.194570779800415,
      "logits/rejected": -3.1956052780151367,
      "logps/chosen": -150.6151123046875,
      "logps/rejected": -138.81678771972656,
      "loss": 0.5124,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5247686505317688,
      "rewards/margins": 0.4606677293777466,
      "rewards/rejected": 0.06410093605518341,
      "step": 44
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.88218879699707,
      "learning_rate": 4.5e-05,
      "logits/chosen": -3.2210142612457275,
      "logits/rejected": -3.0922698974609375,
      "logps/chosen": -138.84133911132812,
      "logps/rejected": -115.00912475585938,
      "loss": 0.542,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.37634703516960144,
      "rewards/margins": 0.4765305519104004,
      "rewards/rejected": -0.10018353909254074,
      "step": 45
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.6063361167907715,
      "learning_rate": 4.600000000000001e-05,
      "logits/chosen": -3.253997802734375,
      "logits/rejected": -3.197324275970459,
      "logps/chosen": -142.28045654296875,
      "logps/rejected": -140.87759399414062,
      "loss": 0.6774,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.5480910539627075,
      "rewards/margins": 0.14000165462493896,
      "rewards/rejected": 0.40808945894241333,
      "step": 46
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.994531631469727,
      "learning_rate": 4.7e-05,
      "logits/chosen": -3.3395047187805176,
      "logits/rejected": -3.340233325958252,
      "logps/chosen": -150.33120727539062,
      "logps/rejected": -149.67811584472656,
      "loss": 0.5854,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.6550723314285278,
      "rewards/margins": 0.30755239725112915,
      "rewards/rejected": 0.34751999378204346,
      "step": 47
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.010433197021484,
      "learning_rate": 4.8e-05,
      "logits/chosen": -3.061049461364746,
      "logits/rejected": -3.190965414047241,
      "logps/chosen": -141.98223876953125,
      "logps/rejected": -162.3213348388672,
      "loss": 0.5295,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.7802292704582214,
      "rewards/margins": 0.43033677339553833,
      "rewards/rejected": 0.3498925566673279,
      "step": 48
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.842787265777588,
      "learning_rate": 4.9e-05,
      "logits/chosen": -3.2858898639678955,
      "logits/rejected": -3.2713305950164795,
      "logps/chosen": -137.9637451171875,
      "logps/rejected": -130.29747009277344,
      "loss": 0.5476,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.9287186861038208,
      "rewards/margins": 0.4758918881416321,
      "rewards/rejected": 0.4528268575668335,
      "step": 49
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.1682868003845215,
      "learning_rate": 5e-05,
      "logits/chosen": -3.150071620941162,
      "logits/rejected": -3.141388416290283,
      "logps/chosen": -165.20672607421875,
      "logps/rejected": -136.3014678955078,
      "loss": 0.5994,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.9847253561019897,
      "rewards/margins": 0.3786589503288269,
      "rewards/rejected": 0.6060664653778076,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 144,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
