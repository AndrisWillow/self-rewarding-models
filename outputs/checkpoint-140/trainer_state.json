{
  "best_metric": 0.8635867238044739,
  "best_model_checkpoint": "outputs/checkpoint-140",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 140,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 5.120645523071289,
      "learning_rate": 9.952380952380953e-05,
      "loss": 3.0122,
      "step": 1
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4026033878326416,
      "learning_rate": 9.904761904761905e-05,
      "loss": 2.4669,
      "step": 2
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.365938663482666,
      "learning_rate": 9.857142857142858e-05,
      "loss": 2.4572,
      "step": 3
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0022354125976562,
      "learning_rate": 9.80952380952381e-05,
      "loss": 2.1368,
      "step": 4
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9722033739089966,
      "learning_rate": 9.761904761904762e-05,
      "loss": 1.9248,
      "step": 5
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6285748481750488,
      "learning_rate": 9.714285714285715e-05,
      "loss": 1.6472,
      "step": 6
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.456742525100708,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.5213,
      "step": 7
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2314800024032593,
      "learning_rate": 9.61904761904762e-05,
      "loss": 1.5166,
      "step": 8
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0283551216125488,
      "learning_rate": 9.571428571428573e-05,
      "loss": 1.3025,
      "step": 9
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8682361245155334,
      "learning_rate": 9.523809523809524e-05,
      "loss": 1.3363,
      "step": 10
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9765923023223877,
      "learning_rate": 9.476190476190476e-05,
      "loss": 1.4606,
      "step": 11
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.96860271692276,
      "learning_rate": 9.428571428571429e-05,
      "loss": 1.3359,
      "step": 12
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8567748069763184,
      "learning_rate": 9.380952380952381e-05,
      "loss": 1.3225,
      "step": 13
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8928311467170715,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.2446,
      "step": 14
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9519328474998474,
      "learning_rate": 9.285714285714286e-05,
      "loss": 1.2801,
      "step": 15
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9169092774391174,
      "learning_rate": 9.238095238095239e-05,
      "loss": 1.1976,
      "step": 16
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9239647388458252,
      "learning_rate": 9.19047619047619e-05,
      "loss": 1.3169,
      "step": 17
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9516721367835999,
      "learning_rate": 9.142857142857143e-05,
      "loss": 1.3946,
      "step": 18
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8438962697982788,
      "learning_rate": 9.095238095238096e-05,
      "loss": 1.0875,
      "step": 19
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.818696916103363,
      "learning_rate": 9.047619047619048e-05,
      "loss": 1.2671,
      "step": 20
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7721073031425476,
      "learning_rate": 9e-05,
      "loss": 1.3657,
      "step": 21
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8245837688446045,
      "learning_rate": 8.952380952380953e-05,
      "loss": 1.2839,
      "step": 22
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.829933226108551,
      "learning_rate": 8.904761904761905e-05,
      "loss": 1.2012,
      "step": 23
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7955179810523987,
      "learning_rate": 8.857142857142857e-05,
      "loss": 1.3065,
      "step": 24
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6953622102737427,
      "learning_rate": 8.80952380952381e-05,
      "loss": 1.1732,
      "step": 25
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7300974726676941,
      "learning_rate": 8.761904761904762e-05,
      "loss": 1.1722,
      "step": 26
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7761225700378418,
      "learning_rate": 8.714285714285715e-05,
      "loss": 1.3073,
      "step": 27
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8698718547821045,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.2848,
      "step": 28
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8517299294471741,
      "learning_rate": 8.61904761904762e-05,
      "loss": 1.3659,
      "step": 29
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8180528879165649,
      "learning_rate": 8.571428571428571e-05,
      "loss": 1.1977,
      "step": 30
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7853831648826599,
      "learning_rate": 8.523809523809524e-05,
      "loss": 1.233,
      "step": 31
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.795403003692627,
      "learning_rate": 8.476190476190477e-05,
      "loss": 1.2865,
      "step": 32
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7057116627693176,
      "learning_rate": 8.428571428571429e-05,
      "loss": 1.1186,
      "step": 33
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9095613360404968,
      "learning_rate": 8.380952380952382e-05,
      "loss": 1.2488,
      "step": 34
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7100194692611694,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.1702,
      "step": 35
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8228259086608887,
      "learning_rate": 8.285714285714287e-05,
      "loss": 1.3011,
      "step": 36
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8088642954826355,
      "learning_rate": 8.238095238095238e-05,
      "loss": 1.2075,
      "step": 37
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7242705821990967,
      "learning_rate": 8.19047619047619e-05,
      "loss": 1.3107,
      "step": 38
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7341094613075256,
      "learning_rate": 8.142857142857143e-05,
      "loss": 1.2329,
      "step": 39
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8294452428817749,
      "learning_rate": 8.095238095238096e-05,
      "loss": 1.3778,
      "step": 40
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7858331799507141,
      "learning_rate": 8.047619047619048e-05,
      "loss": 1.248,
      "step": 41
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.703276515007019,
      "learning_rate": 8e-05,
      "loss": 1.2599,
      "step": 42
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7194145917892456,
      "learning_rate": 7.952380952380952e-05,
      "loss": 1.2144,
      "step": 43
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.729668378829956,
      "learning_rate": 7.904761904761905e-05,
      "loss": 1.2199,
      "step": 44
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.672248363494873,
      "learning_rate": 7.857142857142858e-05,
      "loss": 1.1294,
      "step": 45
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.763018786907196,
      "learning_rate": 7.80952380952381e-05,
      "loss": 1.1468,
      "step": 46
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8250757455825806,
      "learning_rate": 7.761904761904762e-05,
      "loss": 1.1402,
      "step": 47
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7235530614852905,
      "learning_rate": 7.714285714285715e-05,
      "loss": 1.1692,
      "step": 48
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6878651976585388,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.184,
      "step": 49
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7022473812103271,
      "learning_rate": 7.619047619047618e-05,
      "loss": 1.218,
      "step": 50
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7029778957366943,
      "learning_rate": 7.571428571428571e-05,
      "loss": 1.0951,
      "step": 51
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7579712271690369,
      "learning_rate": 7.523809523809524e-05,
      "loss": 1.0942,
      "step": 52
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9205188155174255,
      "learning_rate": 7.476190476190477e-05,
      "loss": 1.3795,
      "step": 53
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7875801920890808,
      "learning_rate": 7.428571428571429e-05,
      "loss": 1.2646,
      "step": 54
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7797236442565918,
      "learning_rate": 7.380952380952382e-05,
      "loss": 1.1664,
      "step": 55
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7814587354660034,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.2552,
      "step": 56
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7284800410270691,
      "learning_rate": 7.285714285714286e-05,
      "loss": 1.0282,
      "step": 57
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6526520252227783,
      "learning_rate": 7.238095238095238e-05,
      "loss": 1.03,
      "step": 58
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.714015781879425,
      "learning_rate": 7.19047619047619e-05,
      "loss": 1.2104,
      "step": 59
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7638450264930725,
      "learning_rate": 7.142857142857143e-05,
      "loss": 1.2127,
      "step": 60
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6989523768424988,
      "learning_rate": 7.095238095238096e-05,
      "loss": 1.099,
      "step": 61
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7760294675827026,
      "learning_rate": 7.047619047619048e-05,
      "loss": 1.2965,
      "step": 62
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7859417796134949,
      "learning_rate": 7e-05,
      "loss": 1.1637,
      "step": 63
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7201381921768188,
      "learning_rate": 6.952380952380952e-05,
      "loss": 1.1279,
      "step": 64
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6948289275169373,
      "learning_rate": 6.904761904761905e-05,
      "loss": 1.1642,
      "step": 65
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7719758152961731,
      "learning_rate": 6.857142857142858e-05,
      "loss": 1.2364,
      "step": 66
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9616222381591797,
      "learning_rate": 6.80952380952381e-05,
      "loss": 1.2517,
      "step": 67
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7812451124191284,
      "learning_rate": 6.761904761904763e-05,
      "loss": 1.2184,
      "step": 68
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7739126682281494,
      "learning_rate": 6.714285714285714e-05,
      "loss": 1.1168,
      "step": 69
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8631308674812317,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.2839,
      "step": 70
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.092605471611023,
      "eval_runtime": 167.6478,
      "eval_samples_per_second": 6.675,
      "eval_steps_per_second": 1.67,
      "step": 70
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8215627670288086,
      "learning_rate": 6.619047619047619e-05,
      "loss": 1.0128,
      "step": 71
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7220388650894165,
      "learning_rate": 6.571428571428571e-05,
      "loss": 1.1749,
      "step": 72
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7025901079177856,
      "learning_rate": 6.523809523809524e-05,
      "loss": 1.1074,
      "step": 73
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.7821126580238342,
      "learning_rate": 6.476190476190477e-05,
      "loss": 0.9948,
      "step": 74
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6760462522506714,
      "learning_rate": 6.428571428571429e-05,
      "loss": 0.9833,
      "step": 75
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7142951488494873,
      "learning_rate": 6.38095238095238e-05,
      "loss": 1.1156,
      "step": 76
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8117240071296692,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.0386,
      "step": 77
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.7920854687690735,
      "learning_rate": 6.285714285714286e-05,
      "loss": 1.0876,
      "step": 78
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7345638871192932,
      "learning_rate": 6.238095238095239e-05,
      "loss": 1.0929,
      "step": 79
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.8437644243240356,
      "learning_rate": 6.19047619047619e-05,
      "loss": 0.9961,
      "step": 80
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7975677847862244,
      "learning_rate": 6.142857142857143e-05,
      "loss": 1.0618,
      "step": 81
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.830938994884491,
      "learning_rate": 6.0952380952380964e-05,
      "loss": 1.0402,
      "step": 82
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9085930585861206,
      "learning_rate": 6.047619047619047e-05,
      "loss": 1.0593,
      "step": 83
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8822325468063354,
      "learning_rate": 6e-05,
      "loss": 0.9878,
      "step": 84
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.9014511108398438,
      "learning_rate": 5.9523809523809524e-05,
      "loss": 1.0598,
      "step": 85
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9299266934394836,
      "learning_rate": 5.904761904761905e-05,
      "loss": 1.0309,
      "step": 86
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.8386176824569702,
      "learning_rate": 5.8571428571428575e-05,
      "loss": 0.9127,
      "step": 87
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9906712770462036,
      "learning_rate": 5.8095238095238104e-05,
      "loss": 1.0621,
      "step": 88
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8256516456604004,
      "learning_rate": 5.761904761904762e-05,
      "loss": 0.9889,
      "step": 89
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9741125106811523,
      "learning_rate": 5.714285714285714e-05,
      "loss": 1.0105,
      "step": 90
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.8193618059158325,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.0347,
      "step": 91
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.8678075075149536,
      "learning_rate": 5.619047619047619e-05,
      "loss": 1.0381,
      "step": 92
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.8806800246238708,
      "learning_rate": 5.571428571428572e-05,
      "loss": 0.9733,
      "step": 93
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8069075345993042,
      "learning_rate": 5.5238095238095244e-05,
      "loss": 0.9217,
      "step": 94
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.8799080848693848,
      "learning_rate": 5.4761904761904766e-05,
      "loss": 1.0287,
      "step": 95
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9101206660270691,
      "learning_rate": 5.428571428571428e-05,
      "loss": 1.0374,
      "step": 96
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9260501265525818,
      "learning_rate": 5.380952380952381e-05,
      "loss": 1.0714,
      "step": 97
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.9678851962089539,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.0192,
      "step": 98
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.8801904320716858,
      "learning_rate": 5.285714285714286e-05,
      "loss": 1.1093,
      "step": 99
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.9297381639480591,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 1.005,
      "step": 100
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9970452785491943,
      "learning_rate": 5.1904761904761913e-05,
      "loss": 1.0882,
      "step": 101
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0507205724716187,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.9232,
      "step": 102
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.0762566328048706,
      "learning_rate": 5.095238095238095e-05,
      "loss": 0.9414,
      "step": 103
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0938204526901245,
      "learning_rate": 5.047619047619048e-05,
      "loss": 1.0415,
      "step": 104
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.03409743309021,
      "learning_rate": 5e-05,
      "loss": 0.8824,
      "step": 105
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9589710831642151,
      "learning_rate": 4.9523809523809525e-05,
      "loss": 1.1458,
      "step": 106
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9726328253746033,
      "learning_rate": 4.904761904761905e-05,
      "loss": 0.9435,
      "step": 107
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0750893354415894,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 1.0282,
      "step": 108
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0388450622558594,
      "learning_rate": 4.80952380952381e-05,
      "loss": 0.9697,
      "step": 109
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.0926165580749512,
      "learning_rate": 4.761904761904762e-05,
      "loss": 1.0817,
      "step": 110
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.052056908607483,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.9736,
      "step": 111
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0154922008514404,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.0529,
      "step": 112
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.0214228630065918,
      "learning_rate": 4.6190476190476194e-05,
      "loss": 0.9142,
      "step": 113
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.139083981513977,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 1.045,
      "step": 114
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0338685512542725,
      "learning_rate": 4.523809523809524e-05,
      "loss": 0.8403,
      "step": 115
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0998977422714233,
      "learning_rate": 4.476190476190477e-05,
      "loss": 0.9968,
      "step": 116
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.0813210010528564,
      "learning_rate": 4.428571428571428e-05,
      "loss": 1.111,
      "step": 117
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2167361974716187,
      "learning_rate": 4.380952380952381e-05,
      "loss": 0.9805,
      "step": 118
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0763365030288696,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.0116,
      "step": 119
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1597263813018799,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 1.1164,
      "step": 120
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1250394582748413,
      "learning_rate": 4.2380952380952385e-05,
      "loss": 0.9006,
      "step": 121
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1274752616882324,
      "learning_rate": 4.190476190476191e-05,
      "loss": 0.9648,
      "step": 122
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.2871379852294922,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 1.0465,
      "step": 123
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.171984076499939,
      "learning_rate": 4.095238095238095e-05,
      "loss": 0.9579,
      "step": 124
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0700740814208984,
      "learning_rate": 4.047619047619048e-05,
      "loss": 0.9842,
      "step": 125
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.13491690158844,
      "learning_rate": 4e-05,
      "loss": 0.9988,
      "step": 126
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.036474347114563,
      "learning_rate": 3.9523809523809526e-05,
      "loss": 0.9104,
      "step": 127
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2042535543441772,
      "learning_rate": 3.904761904761905e-05,
      "loss": 0.931,
      "step": 128
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1451196670532227,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.9121,
      "step": 129
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.2269535064697266,
      "learning_rate": 3.809523809523809e-05,
      "loss": 1.0445,
      "step": 130
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.1647123098373413,
      "learning_rate": 3.761904761904762e-05,
      "loss": 0.9206,
      "step": 131
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.2946932315826416,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 1.0451,
      "step": 132
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2758840322494507,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.8813,
      "step": 133
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.199940800666809,
      "learning_rate": 3.619047619047619e-05,
      "loss": 0.9485,
      "step": 134
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.3452754020690918,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.9992,
      "step": 135
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.2876943349838257,
      "learning_rate": 3.523809523809524e-05,
      "loss": 0.9746,
      "step": 136
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.20418119430542,
      "learning_rate": 3.476190476190476e-05,
      "loss": 0.9369,
      "step": 137
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.2864607572555542,
      "learning_rate": 3.428571428571429e-05,
      "loss": 1.0505,
      "step": 138
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.2002177238464355,
      "learning_rate": 3.380952380952381e-05,
      "loss": 0.9793,
      "step": 139
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.2489463090896606,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.0082,
      "step": 140
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8635867238044739,
      "eval_runtime": 168.0817,
      "eval_samples_per_second": 6.657,
      "eval_steps_per_second": 1.666,
      "step": 140
    }
  ],
  "logging_steps": 1,
  "max_steps": 210,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 1.1104347932811264e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
