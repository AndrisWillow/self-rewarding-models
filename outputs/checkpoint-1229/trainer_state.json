{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1229,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.873427152633667,
      "learning_rate": 9.991863303498779e-05,
      "loss": 1.5625,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.8333532810211182,
      "learning_rate": 9.98372660699756e-05,
      "loss": 1.9819,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.1687076091766357,
      "learning_rate": 9.97558991049634e-05,
      "loss": 2.7624,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1664751768112183,
      "learning_rate": 9.967453213995118e-05,
      "loss": 1.246,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1601567268371582,
      "learning_rate": 9.959316517493899e-05,
      "loss": 1.5577,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.8456381559371948,
      "learning_rate": 9.951179820992677e-05,
      "loss": 0.9863,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": NaN,
      "learning_rate": 9.951179820992677e-05,
      "loss": 1.8866,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9647862911224365,
      "learning_rate": 9.943043124491456e-05,
      "loss": 1.1125,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.020851492881775,
      "learning_rate": 9.934906427990236e-05,
      "loss": 1.1623,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5795596837997437,
      "learning_rate": 9.926769731489017e-05,
      "loss": 1.5236,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3320623636245728,
      "learning_rate": 9.918633034987795e-05,
      "loss": 1.173,
      "step": 11
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1971383094787598,
      "learning_rate": 9.910496338486574e-05,
      "loss": 1.3554,
      "step": 12
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3096213340759277,
      "learning_rate": 9.902359641985354e-05,
      "loss": 1.2284,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3180301189422607,
      "learning_rate": 9.894222945484133e-05,
      "loss": 1.3733,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4220004081726074,
      "learning_rate": 9.886086248982913e-05,
      "loss": 1.2884,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.096331000328064,
      "learning_rate": 9.877949552481694e-05,
      "loss": 1.2742,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0601911544799805,
      "learning_rate": 9.869812855980472e-05,
      "loss": 1.0029,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3878910541534424,
      "learning_rate": 9.861676159479251e-05,
      "loss": 1.197,
      "step": 18
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5079317092895508,
      "learning_rate": 9.853539462978031e-05,
      "loss": 1.8193,
      "step": 19
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0179451704025269,
      "learning_rate": 9.845402766476812e-05,
      "loss": 1.1161,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1024280786514282,
      "learning_rate": 9.83726606997559e-05,
      "loss": 1.2731,
      "step": 21
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.080916404724121,
      "learning_rate": 9.829129373474369e-05,
      "loss": 1.0014,
      "step": 22
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.019272804260254,
      "learning_rate": 9.82099267697315e-05,
      "loss": 0.9018,
      "step": 23
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.595402717590332,
      "learning_rate": 9.812855980471928e-05,
      "loss": 1.0974,
      "step": 24
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0421478748321533,
      "learning_rate": 9.804719283970708e-05,
      "loss": 0.7225,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7846493721008301,
      "learning_rate": 9.796582587469489e-05,
      "loss": 0.8831,
      "step": 26
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3338634967803955,
      "learning_rate": 9.788445890968267e-05,
      "loss": 1.5147,
      "step": 27
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1735308170318604,
      "learning_rate": 9.780309194467046e-05,
      "loss": 1.0978,
      "step": 28
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9790582060813904,
      "learning_rate": 9.772172497965825e-05,
      "loss": 1.0857,
      "step": 29
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.663752555847168,
      "learning_rate": 9.764035801464607e-05,
      "loss": 0.7579,
      "step": 30
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.00522780418396,
      "learning_rate": 9.755899104963385e-05,
      "loss": 0.5991,
      "step": 31
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7490984201431274,
      "learning_rate": 9.747762408462164e-05,
      "loss": 0.9283,
      "step": 32
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5627354383468628,
      "learning_rate": 9.739625711960944e-05,
      "loss": 1.0514,
      "step": 33
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5456465482711792,
      "learning_rate": 9.731489015459723e-05,
      "loss": 1.3685,
      "step": 34
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4236201047897339,
      "learning_rate": 9.723352318958503e-05,
      "loss": 1.02,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.261845588684082,
      "learning_rate": 9.715215622457284e-05,
      "loss": 1.1228,
      "step": 36
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9048014879226685,
      "learning_rate": 9.707078925956062e-05,
      "loss": 0.6275,
      "step": 37
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.681974470615387,
      "learning_rate": 9.698942229454841e-05,
      "loss": 1.0783,
      "step": 38
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.558843731880188,
      "learning_rate": 9.690805532953621e-05,
      "loss": 0.8281,
      "step": 39
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9308075904846191,
      "learning_rate": 9.6826688364524e-05,
      "loss": 1.1487,
      "step": 40
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7448236346244812,
      "learning_rate": 9.67453213995118e-05,
      "loss": 0.8345,
      "step": 41
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9046546220779419,
      "learning_rate": 9.666395443449959e-05,
      "loss": 0.8759,
      "step": 42
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6259196996688843,
      "learning_rate": 9.65825874694874e-05,
      "loss": 0.8887,
      "step": 43
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5251179337501526,
      "learning_rate": 9.650122050447518e-05,
      "loss": 0.4781,
      "step": 44
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9579532742500305,
      "learning_rate": 9.641985353946298e-05,
      "loss": 0.8949,
      "step": 45
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0757205486297607,
      "learning_rate": 9.633848657445079e-05,
      "loss": 0.8494,
      "step": 46
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1250009536743164,
      "learning_rate": 9.625711960943857e-05,
      "loss": 0.872,
      "step": 47
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7571477293968201,
      "learning_rate": 9.617575264442636e-05,
      "loss": 0.7639,
      "step": 48
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4401874542236328,
      "learning_rate": 9.609438567941416e-05,
      "loss": 1.0081,
      "step": 49
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1463431119918823,
      "learning_rate": 9.601301871440195e-05,
      "loss": 1.0706,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3120408058166504,
      "learning_rate": 9.593165174938975e-05,
      "loss": 1.5452,
      "step": 51
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8288110494613647,
      "learning_rate": 9.585028478437754e-05,
      "loss": 1.1713,
      "step": 52
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.772030234336853,
      "learning_rate": 9.576891781936534e-05,
      "loss": 0.6372,
      "step": 53
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.6983550786972046,
      "learning_rate": 9.568755085435313e-05,
      "loss": 1.2174,
      "step": 54
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6719931364059448,
      "learning_rate": 9.560618388934092e-05,
      "loss": 0.9156,
      "step": 55
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8559918999671936,
      "learning_rate": 9.552481692432874e-05,
      "loss": 1.0877,
      "step": 56
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5863596200942993,
      "learning_rate": 9.544344995931652e-05,
      "loss": 1.4839,
      "step": 57
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0271857976913452,
      "learning_rate": 9.536208299430431e-05,
      "loss": 1.3176,
      "step": 58
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.700171172618866,
      "learning_rate": 9.528071602929211e-05,
      "loss": 1.051,
      "step": 59
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1727311611175537,
      "learning_rate": 9.51993490642799e-05,
      "loss": 1.442,
      "step": 60
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.919262707233429,
      "learning_rate": 9.51179820992677e-05,
      "loss": 0.9671,
      "step": 61
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9442678093910217,
      "learning_rate": 9.50366151342555e-05,
      "loss": 1.4718,
      "step": 62
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.203112244606018,
      "learning_rate": 9.49552481692433e-05,
      "loss": 1.349,
      "step": 63
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6333518624305725,
      "learning_rate": 9.487388120423108e-05,
      "loss": 0.82,
      "step": 64
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7943847179412842,
      "learning_rate": 9.479251423921887e-05,
      "loss": 1.125,
      "step": 65
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4929627180099487,
      "learning_rate": 9.471114727420667e-05,
      "loss": 1.0345,
      "step": 66
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4072429835796356,
      "learning_rate": 9.462978030919447e-05,
      "loss": 0.443,
      "step": 67
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8652993440628052,
      "learning_rate": 9.454841334418226e-05,
      "loss": 0.7667,
      "step": 68
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8882049322128296,
      "learning_rate": 9.446704637917006e-05,
      "loss": 0.9461,
      "step": 69
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7961397767066956,
      "learning_rate": 9.438567941415785e-05,
      "loss": 0.5682,
      "step": 70
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0871915817260742,
      "learning_rate": 9.430431244914565e-05,
      "loss": 1.0293,
      "step": 71
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8554556369781494,
      "learning_rate": 9.422294548413346e-05,
      "loss": 0.8658,
      "step": 72
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.725692868232727,
      "learning_rate": 9.414157851912124e-05,
      "loss": 1.0228,
      "step": 73
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.709217369556427,
      "learning_rate": 9.406021155410903e-05,
      "loss": 0.9504,
      "step": 74
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6551284193992615,
      "learning_rate": 9.397884458909682e-05,
      "loss": 0.9418,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5986579656600952,
      "learning_rate": 9.389747762408462e-05,
      "loss": 0.582,
      "step": 76
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1751744747161865,
      "learning_rate": 9.381611065907242e-05,
      "loss": 0.9963,
      "step": 77
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6797464489936829,
      "learning_rate": 9.373474369406021e-05,
      "loss": 1.0037,
      "step": 78
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1292093992233276,
      "learning_rate": 9.365337672904801e-05,
      "loss": 1.0425,
      "step": 79
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7852675914764404,
      "learning_rate": 9.35720097640358e-05,
      "loss": 1.0828,
      "step": 80
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7492812871932983,
      "learning_rate": 9.349064279902359e-05,
      "loss": 0.8253,
      "step": 81
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6676674485206604,
      "learning_rate": 9.34092758340114e-05,
      "loss": 0.8765,
      "step": 82
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.920588731765747,
      "learning_rate": 9.33279088689992e-05,
      "loss": 1.8059,
      "step": 83
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0305770635604858,
      "learning_rate": 9.324654190398698e-05,
      "loss": 1.1025,
      "step": 84
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8694610595703125,
      "learning_rate": 9.316517493897477e-05,
      "loss": 1.428,
      "step": 85
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8388648629188538,
      "learning_rate": 9.308380797396257e-05,
      "loss": 0.8596,
      "step": 86
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9252086877822876,
      "learning_rate": 9.300244100895037e-05,
      "loss": 1.1117,
      "step": 87
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4830755293369293,
      "learning_rate": 9.292107404393816e-05,
      "loss": 0.707,
      "step": 88
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9405911564826965,
      "learning_rate": 9.283970707892596e-05,
      "loss": 1.4535,
      "step": 89
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8453549742698669,
      "learning_rate": 9.275834011391375e-05,
      "loss": 1.2543,
      "step": 90
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.14490807056427,
      "learning_rate": 9.267697314890154e-05,
      "loss": 1.1417,
      "step": 91
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0815300941467285,
      "learning_rate": 9.259560618388934e-05,
      "loss": 1.4193,
      "step": 92
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8376227617263794,
      "learning_rate": 9.251423921887714e-05,
      "loss": 0.6896,
      "step": 93
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8647570610046387,
      "learning_rate": 9.243287225386493e-05,
      "loss": 1.2704,
      "step": 94
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1103116273880005,
      "learning_rate": 9.235150528885273e-05,
      "loss": 0.9409,
      "step": 95
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8882825374603271,
      "learning_rate": 9.227013832384052e-05,
      "loss": 1.1703,
      "step": 96
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7806837558746338,
      "learning_rate": 9.218877135882832e-05,
      "loss": 0.9744,
      "step": 97
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4669398069381714,
      "learning_rate": 9.210740439381611e-05,
      "loss": 0.425,
      "step": 98
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7186583280563354,
      "learning_rate": 9.202603742880391e-05,
      "loss": 0.9162,
      "step": 99
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5251961946487427,
      "learning_rate": 9.19446704637917e-05,
      "loss": 0.5719,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8372094631195068,
      "learning_rate": 9.186330349877949e-05,
      "loss": 1.0406,
      "step": 101
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8935187458992004,
      "learning_rate": 9.178193653376729e-05,
      "loss": 0.9728,
      "step": 102
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1886495351791382,
      "learning_rate": 9.17005695687551e-05,
      "loss": 1.2229,
      "step": 103
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1242637634277344,
      "learning_rate": 9.161920260374288e-05,
      "loss": 1.1944,
      "step": 104
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2497299909591675,
      "learning_rate": 9.153783563873068e-05,
      "loss": 0.8693,
      "step": 105
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7718040943145752,
      "learning_rate": 9.145646867371847e-05,
      "loss": 1.1835,
      "step": 106
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6159906387329102,
      "learning_rate": 9.137510170870626e-05,
      "loss": 1.1001,
      "step": 107
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8556502461433411,
      "learning_rate": 9.129373474369406e-05,
      "loss": 0.5868,
      "step": 108
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7806926369667053,
      "learning_rate": 9.121236777868186e-05,
      "loss": 0.9692,
      "step": 109
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2322611808776855,
      "learning_rate": 9.113100081366965e-05,
      "loss": 1.6185,
      "step": 110
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8478716015815735,
      "learning_rate": 9.104963384865744e-05,
      "loss": 0.7925,
      "step": 111
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6478410959243774,
      "learning_rate": 9.096826688364524e-05,
      "loss": 1.7685,
      "step": 112
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4846673607826233,
      "learning_rate": 9.088689991863304e-05,
      "loss": 0.5393,
      "step": 113
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0553609132766724,
      "learning_rate": 9.080553295362083e-05,
      "loss": 1.0273,
      "step": 114
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8186814785003662,
      "learning_rate": 9.072416598860863e-05,
      "loss": 1.1493,
      "step": 115
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9449856877326965,
      "learning_rate": 9.064279902359642e-05,
      "loss": 1.0269,
      "step": 116
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8969419002532959,
      "learning_rate": 9.056143205858421e-05,
      "loss": 0.7196,
      "step": 117
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8863484859466553,
      "learning_rate": 9.048006509357201e-05,
      "loss": 0.652,
      "step": 118
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4269940853118896,
      "learning_rate": 9.039869812855981e-05,
      "loss": 0.983,
      "step": 119
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7701963186264038,
      "learning_rate": 9.03173311635476e-05,
      "loss": 0.685,
      "step": 120
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9031931161880493,
      "learning_rate": 9.023596419853539e-05,
      "loss": 1.0977,
      "step": 121
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7785775661468506,
      "learning_rate": 9.015459723352319e-05,
      "loss": 0.9213,
      "step": 122
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.088948369026184,
      "learning_rate": 9.0073230268511e-05,
      "loss": 0.9452,
      "step": 123
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1603882312774658,
      "learning_rate": 8.999186330349878e-05,
      "loss": 0.9752,
      "step": 124
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3032928705215454,
      "learning_rate": 8.991049633848658e-05,
      "loss": 0.8862,
      "step": 125
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6920095086097717,
      "learning_rate": 8.982912937347437e-05,
      "loss": 1.0559,
      "step": 126
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.801251232624054,
      "learning_rate": 8.974776240846216e-05,
      "loss": 0.9807,
      "step": 127
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4817392826080322,
      "learning_rate": 8.966639544344996e-05,
      "loss": 0.9006,
      "step": 128
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9603695869445801,
      "learning_rate": 8.958502847843776e-05,
      "loss": 1.1951,
      "step": 129
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8295333981513977,
      "learning_rate": 8.950366151342555e-05,
      "loss": 0.9562,
      "step": 130
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0996074676513672,
      "learning_rate": 8.942229454841334e-05,
      "loss": 1.39,
      "step": 131
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.041487216949463,
      "learning_rate": 8.934092758340114e-05,
      "loss": 1.2912,
      "step": 132
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9568464159965515,
      "learning_rate": 8.925956061838893e-05,
      "loss": 0.9518,
      "step": 133
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1611342430114746,
      "learning_rate": 8.917819365337673e-05,
      "loss": 0.6315,
      "step": 134
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8814486265182495,
      "learning_rate": 8.909682668836453e-05,
      "loss": 1.3565,
      "step": 135
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7029633522033691,
      "learning_rate": 8.901545972335232e-05,
      "loss": 0.6101,
      "step": 136
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0005053281784058,
      "learning_rate": 8.893409275834011e-05,
      "loss": 1.2496,
      "step": 137
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9380620121955872,
      "learning_rate": 8.885272579332791e-05,
      "loss": 0.6948,
      "step": 138
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5184106826782227,
      "learning_rate": 8.877135882831571e-05,
      "loss": 0.5397,
      "step": 139
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.375817060470581,
      "learning_rate": 8.86899918633035e-05,
      "loss": 1.9629,
      "step": 140
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.189353108406067,
      "learning_rate": 8.860862489829129e-05,
      "loss": 1.3505,
      "step": 141
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5320550203323364,
      "learning_rate": 8.852725793327909e-05,
      "loss": 0.6283,
      "step": 142
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9292370676994324,
      "learning_rate": 8.844589096826688e-05,
      "loss": 0.9017,
      "step": 143
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5691075921058655,
      "learning_rate": 8.836452400325468e-05,
      "loss": 0.6131,
      "step": 144
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7987635135650635,
      "learning_rate": 8.828315703824248e-05,
      "loss": 0.7208,
      "step": 145
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6416978240013123,
      "learning_rate": 8.820179007323027e-05,
      "loss": 0.6961,
      "step": 146
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8334004878997803,
      "learning_rate": 8.812042310821806e-05,
      "loss": 0.9118,
      "step": 147
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7024468779563904,
      "learning_rate": 8.803905614320586e-05,
      "loss": 1.1693,
      "step": 148
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.8272862434387207,
      "learning_rate": 8.795768917819366e-05,
      "loss": 1.3016,
      "step": 149
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.091168761253357,
      "learning_rate": 8.787632221318145e-05,
      "loss": 1.1641,
      "step": 150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8807317018508911,
      "learning_rate": 8.779495524816925e-05,
      "loss": 1.1384,
      "step": 151
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5185666084289551,
      "learning_rate": 8.771358828315704e-05,
      "loss": 0.7346,
      "step": 152
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0350303649902344,
      "learning_rate": 8.763222131814483e-05,
      "loss": 0.8102,
      "step": 153
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7097352743148804,
      "learning_rate": 8.755085435313263e-05,
      "loss": 1.1355,
      "step": 154
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5626447796821594,
      "learning_rate": 8.746948738812043e-05,
      "loss": 0.8808,
      "step": 155
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.983668327331543,
      "learning_rate": 8.738812042310822e-05,
      "loss": 1.2272,
      "step": 156
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.122885823249817,
      "learning_rate": 8.730675345809601e-05,
      "loss": 1.2743,
      "step": 157
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7302535772323608,
      "learning_rate": 8.722538649308381e-05,
      "loss": 0.8485,
      "step": 158
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5237191319465637,
      "learning_rate": 8.71440195280716e-05,
      "loss": 1.0239,
      "step": 159
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.52228844165802,
      "learning_rate": 8.70626525630594e-05,
      "loss": 0.9379,
      "step": 160
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8322095274925232,
      "learning_rate": 8.69812855980472e-05,
      "loss": 1.3327,
      "step": 161
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.46838077902793884,
      "learning_rate": 8.689991863303499e-05,
      "loss": 0.4848,
      "step": 162
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5994396209716797,
      "learning_rate": 8.681855166802278e-05,
      "loss": 1.0811,
      "step": 163
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4435322880744934,
      "learning_rate": 8.673718470301058e-05,
      "loss": 0.7242,
      "step": 164
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1253163814544678,
      "learning_rate": 8.665581773799838e-05,
      "loss": 1.2116,
      "step": 165
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4904593527317047,
      "learning_rate": 8.657445077298617e-05,
      "loss": 0.9185,
      "step": 166
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7382278442382812,
      "learning_rate": 8.649308380797396e-05,
      "loss": 1.0137,
      "step": 167
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8124029636383057,
      "learning_rate": 8.641171684296176e-05,
      "loss": 1.0742,
      "step": 168
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1314234733581543,
      "learning_rate": 8.633034987794955e-05,
      "loss": 1.3729,
      "step": 169
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6049458980560303,
      "learning_rate": 8.624898291293735e-05,
      "loss": 1.0985,
      "step": 170
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6370680332183838,
      "learning_rate": 8.616761594792515e-05,
      "loss": 0.8228,
      "step": 171
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.688125491142273,
      "learning_rate": 8.608624898291294e-05,
      "loss": 1.1993,
      "step": 172
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5912895798683167,
      "learning_rate": 8.600488201790073e-05,
      "loss": 0.6084,
      "step": 173
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5212342739105225,
      "learning_rate": 8.592351505288853e-05,
      "loss": 0.62,
      "step": 174
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6586201190948486,
      "learning_rate": 8.584214808787633e-05,
      "loss": 0.8049,
      "step": 175
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0264381170272827,
      "learning_rate": 8.576078112286412e-05,
      "loss": 1.0706,
      "step": 176
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9236500263214111,
      "learning_rate": 8.567941415785191e-05,
      "loss": 1.0832,
      "step": 177
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6493169069290161,
      "learning_rate": 8.559804719283971e-05,
      "loss": 1.0031,
      "step": 178
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6948145627975464,
      "learning_rate": 8.55166802278275e-05,
      "loss": 0.9354,
      "step": 179
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7634241580963135,
      "learning_rate": 8.54353132628153e-05,
      "loss": 0.5515,
      "step": 180
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0953929424285889,
      "learning_rate": 8.53539462978031e-05,
      "loss": 0.8523,
      "step": 181
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48020118474960327,
      "learning_rate": 8.527257933279089e-05,
      "loss": 0.5827,
      "step": 182
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.63273286819458,
      "learning_rate": 8.519121236777868e-05,
      "loss": 0.7659,
      "step": 183
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7023401260375977,
      "learning_rate": 8.510984540276648e-05,
      "loss": 0.9709,
      "step": 184
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.45918869972229,
      "learning_rate": 8.502847843775427e-05,
      "loss": 1.1425,
      "step": 185
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4595968425273895,
      "learning_rate": 8.494711147274207e-05,
      "loss": 0.9452,
      "step": 186
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5880702137947083,
      "learning_rate": 8.486574450772986e-05,
      "loss": 0.9021,
      "step": 187
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7224741578102112,
      "learning_rate": 8.478437754271766e-05,
      "loss": 1.1007,
      "step": 188
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5942838191986084,
      "learning_rate": 8.470301057770545e-05,
      "loss": 0.6539,
      "step": 189
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6674469113349915,
      "learning_rate": 8.462164361269325e-05,
      "loss": 0.9393,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.827826201915741,
      "learning_rate": 8.454027664768105e-05,
      "loss": 1.0878,
      "step": 191
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4861767292022705,
      "learning_rate": 8.445890968266884e-05,
      "loss": 0.8871,
      "step": 192
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6825034618377686,
      "learning_rate": 8.437754271765663e-05,
      "loss": 0.7557,
      "step": 193
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8358235359191895,
      "learning_rate": 8.429617575264443e-05,
      "loss": 0.9383,
      "step": 194
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2809193134307861,
      "learning_rate": 8.421480878763222e-05,
      "loss": 1.0834,
      "step": 195
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6265550255775452,
      "learning_rate": 8.413344182262002e-05,
      "loss": 0.6918,
      "step": 196
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6366375684738159,
      "learning_rate": 8.405207485760781e-05,
      "loss": 0.8114,
      "step": 197
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6160252094268799,
      "learning_rate": 8.397070789259561e-05,
      "loss": 0.6753,
      "step": 198
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0216808319091797,
      "learning_rate": 8.38893409275834e-05,
      "loss": 1.2757,
      "step": 199
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.87281334400177,
      "learning_rate": 8.380797396257119e-05,
      "loss": 0.7759,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5348724126815796,
      "learning_rate": 8.3726606997559e-05,
      "loss": 0.4312,
      "step": 201
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0184317827224731,
      "learning_rate": 8.364524003254679e-05,
      "loss": 0.9578,
      "step": 202
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9603676199913025,
      "learning_rate": 8.356387306753458e-05,
      "loss": 1.2883,
      "step": 203
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2454389333724976,
      "learning_rate": 8.348250610252238e-05,
      "loss": 0.9298,
      "step": 204
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8570653200149536,
      "learning_rate": 8.340113913751017e-05,
      "loss": 0.834,
      "step": 205
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.48534053564071655,
      "learning_rate": 8.331977217249797e-05,
      "loss": 0.5217,
      "step": 206
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0246684551239014,
      "learning_rate": 8.323840520748577e-05,
      "loss": 1.0476,
      "step": 207
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7359203100204468,
      "learning_rate": 8.315703824247356e-05,
      "loss": 0.9464,
      "step": 208
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9176381230354309,
      "learning_rate": 8.307567127746135e-05,
      "loss": 1.2712,
      "step": 209
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6850501894950867,
      "learning_rate": 8.299430431244914e-05,
      "loss": 1.007,
      "step": 210
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9934954643249512,
      "learning_rate": 8.291293734743694e-05,
      "loss": 1.4164,
      "step": 211
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7763270139694214,
      "learning_rate": 8.283157038242474e-05,
      "loss": 1.0034,
      "step": 212
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.3100372552871704,
      "learning_rate": 8.275020341741253e-05,
      "loss": 1.1564,
      "step": 213
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4118320643901825,
      "learning_rate": 8.266883645240033e-05,
      "loss": 0.8888,
      "step": 214
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.860974133014679,
      "learning_rate": 8.258746948738812e-05,
      "loss": 1.0377,
      "step": 215
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8441981077194214,
      "learning_rate": 8.250610252237592e-05,
      "loss": 1.4034,
      "step": 216
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1306883096694946,
      "learning_rate": 8.242473555736373e-05,
      "loss": 0.7451,
      "step": 217
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7596166729927063,
      "learning_rate": 8.234336859235151e-05,
      "loss": 0.8197,
      "step": 218
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8062911033630371,
      "learning_rate": 8.22620016273393e-05,
      "loss": 0.8009,
      "step": 219
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2645468711853027,
      "learning_rate": 8.218063466232709e-05,
      "loss": 0.8184,
      "step": 220
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1775882244110107,
      "learning_rate": 8.209926769731489e-05,
      "loss": 0.9322,
      "step": 221
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.01056706905365,
      "learning_rate": 8.20179007323027e-05,
      "loss": 1.0017,
      "step": 222
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0481847524642944,
      "learning_rate": 8.193653376729048e-05,
      "loss": 0.7569,
      "step": 223
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0955002307891846,
      "learning_rate": 8.185516680227828e-05,
      "loss": 1.0892,
      "step": 224
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7776452898979187,
      "learning_rate": 8.177379983726607e-05,
      "loss": 1.1064,
      "step": 225
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1249736547470093,
      "learning_rate": 8.169243287225386e-05,
      "loss": 0.516,
      "step": 226
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5566588044166565,
      "learning_rate": 8.161106590724168e-05,
      "loss": 0.6624,
      "step": 227
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8405013084411621,
      "learning_rate": 8.152969894222946e-05,
      "loss": 1.5202,
      "step": 228
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6846686601638794,
      "learning_rate": 8.144833197721725e-05,
      "loss": 0.8596,
      "step": 229
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5628703236579895,
      "learning_rate": 8.136696501220505e-05,
      "loss": 0.6935,
      "step": 230
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8540120124816895,
      "learning_rate": 8.128559804719284e-05,
      "loss": 0.9272,
      "step": 231
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6023880839347839,
      "learning_rate": 8.120423108218064e-05,
      "loss": 0.9148,
      "step": 232
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6889072060585022,
      "learning_rate": 8.112286411716843e-05,
      "loss": 0.7457,
      "step": 233
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8458930253982544,
      "learning_rate": 8.104149715215623e-05,
      "loss": 1.3762,
      "step": 234
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7616665959358215,
      "learning_rate": 8.096013018714402e-05,
      "loss": 0.9639,
      "step": 235
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8191320896148682,
      "learning_rate": 8.087876322213181e-05,
      "loss": 0.8748,
      "step": 236
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.769304633140564,
      "learning_rate": 8.079739625711961e-05,
      "loss": 1.1204,
      "step": 237
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4963595867156982,
      "learning_rate": 8.071602929210741e-05,
      "loss": 1.5195,
      "step": 238
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9851006269454956,
      "learning_rate": 8.06346623270952e-05,
      "loss": 1.3773,
      "step": 239
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9923756718635559,
      "learning_rate": 8.0553295362083e-05,
      "loss": 1.3258,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8739251494407654,
      "learning_rate": 8.047192839707079e-05,
      "loss": 0.8743,
      "step": 241
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35989078879356384,
      "learning_rate": 8.03905614320586e-05,
      "loss": 0.4335,
      "step": 242
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1716892719268799,
      "learning_rate": 8.030919446704638e-05,
      "loss": 1.1896,
      "step": 243
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7265473008155823,
      "learning_rate": 8.022782750203418e-05,
      "loss": 0.5711,
      "step": 244
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7170820236206055,
      "learning_rate": 8.014646053702197e-05,
      "loss": 0.6752,
      "step": 245
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8239875435829163,
      "learning_rate": 8.006509357200976e-05,
      "loss": 0.7177,
      "step": 246
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1597892045974731,
      "learning_rate": 7.998372660699756e-05,
      "loss": 1.3475,
      "step": 247
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6328451037406921,
      "learning_rate": 7.990235964198536e-05,
      "loss": 0.6878,
      "step": 248
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6868391036987305,
      "learning_rate": 7.982099267697315e-05,
      "loss": 0.9889,
      "step": 249
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.4832675457000732,
      "learning_rate": 7.973962571196095e-05,
      "loss": 1.2957,
      "step": 250
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5298596024513245,
      "learning_rate": 7.965825874694874e-05,
      "loss": 0.7782,
      "step": 251
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7985543012619019,
      "learning_rate": 7.957689178193653e-05,
      "loss": 0.9177,
      "step": 252
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.35354745388031,
      "learning_rate": 7.949552481692433e-05,
      "loss": 0.8934,
      "step": 253
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6254401803016663,
      "learning_rate": 7.941415785191213e-05,
      "loss": 0.6927,
      "step": 254
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6039944291114807,
      "learning_rate": 7.933279088689992e-05,
      "loss": 1.0851,
      "step": 255
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8129953742027283,
      "learning_rate": 7.925142392188771e-05,
      "loss": 0.7952,
      "step": 256
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2744266986846924,
      "learning_rate": 7.917005695687551e-05,
      "loss": 0.8279,
      "step": 257
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.309273600578308,
      "learning_rate": 7.908868999186331e-05,
      "loss": 1.1184,
      "step": 258
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2349010705947876,
      "learning_rate": 7.90073230268511e-05,
      "loss": 1.3791,
      "step": 259
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.094040036201477,
      "learning_rate": 7.89259560618389e-05,
      "loss": 0.7175,
      "step": 260
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.47801095247268677,
      "learning_rate": 7.884458909682669e-05,
      "loss": 0.668,
      "step": 261
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.401993989944458,
      "learning_rate": 7.876322213181448e-05,
      "loss": 0.7489,
      "step": 262
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6126648783683777,
      "learning_rate": 7.868185516680228e-05,
      "loss": 0.7928,
      "step": 263
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42304208874702454,
      "learning_rate": 7.860048820179008e-05,
      "loss": 0.6373,
      "step": 264
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8994589447975159,
      "learning_rate": 7.851912123677787e-05,
      "loss": 1.1897,
      "step": 265
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.080236792564392,
      "learning_rate": 7.843775427176566e-05,
      "loss": 1.1784,
      "step": 266
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0970335006713867,
      "learning_rate": 7.835638730675346e-05,
      "loss": 1.1725,
      "step": 267
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46109044551849365,
      "learning_rate": 7.827502034174125e-05,
      "loss": 0.4722,
      "step": 268
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7218025922775269,
      "learning_rate": 7.819365337672905e-05,
      "loss": 0.6878,
      "step": 269
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7124725580215454,
      "learning_rate": 7.811228641171685e-05,
      "loss": 0.9998,
      "step": 270
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6013875007629395,
      "learning_rate": 7.803091944670464e-05,
      "loss": 0.8391,
      "step": 271
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8137897253036499,
      "learning_rate": 7.794955248169243e-05,
      "loss": 0.7943,
      "step": 272
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9901459217071533,
      "learning_rate": 7.786818551668023e-05,
      "loss": 1.3918,
      "step": 273
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6921635866165161,
      "learning_rate": 7.778681855166803e-05,
      "loss": 1.1638,
      "step": 274
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7112687230110168,
      "learning_rate": 7.770545158665582e-05,
      "loss": 0.8874,
      "step": 275
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5780413150787354,
      "learning_rate": 7.762408462164361e-05,
      "loss": 0.6008,
      "step": 276
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7525396347045898,
      "learning_rate": 7.754271765663141e-05,
      "loss": 0.54,
      "step": 277
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4149994850158691,
      "learning_rate": 7.74613506916192e-05,
      "loss": 1.1949,
      "step": 278
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9016391038894653,
      "learning_rate": 7.7379983726607e-05,
      "loss": 1.4628,
      "step": 279
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9361776113510132,
      "learning_rate": 7.72986167615948e-05,
      "loss": 0.9081,
      "step": 280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7828213572502136,
      "learning_rate": 7.721724979658259e-05,
      "loss": 1.1499,
      "step": 281
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6292231678962708,
      "learning_rate": 7.713588283157038e-05,
      "loss": 0.8148,
      "step": 282
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5175703167915344,
      "learning_rate": 7.705451586655818e-05,
      "loss": 1.0692,
      "step": 283
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.49116215109825134,
      "learning_rate": 7.697314890154598e-05,
      "loss": 0.6462,
      "step": 284
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4688495099544525,
      "learning_rate": 7.689178193653377e-05,
      "loss": 0.5029,
      "step": 285
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1212632656097412,
      "learning_rate": 7.681041497152156e-05,
      "loss": 0.9406,
      "step": 286
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7015420794487,
      "learning_rate": 7.672904800650936e-05,
      "loss": 0.9291,
      "step": 287
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0744693279266357,
      "learning_rate": 7.664768104149715e-05,
      "loss": 1.3218,
      "step": 288
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0553035736083984,
      "learning_rate": 7.656631407648495e-05,
      "loss": 1.2972,
      "step": 289
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7707547545433044,
      "learning_rate": 7.648494711147275e-05,
      "loss": 0.952,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.710246205329895,
      "learning_rate": 7.640358014646054e-05,
      "loss": 1.0667,
      "step": 291
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6811090111732483,
      "learning_rate": 7.632221318144833e-05,
      "loss": 0.934,
      "step": 292
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3625935316085815,
      "learning_rate": 7.624084621643613e-05,
      "loss": 1.0783,
      "step": 293
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5059481263160706,
      "learning_rate": 7.615947925142392e-05,
      "loss": 0.6864,
      "step": 294
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9218428134918213,
      "learning_rate": 7.607811228641172e-05,
      "loss": 1.113,
      "step": 295
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5322257280349731,
      "learning_rate": 7.599674532139952e-05,
      "loss": 0.4301,
      "step": 296
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5421004891395569,
      "learning_rate": 7.591537835638731e-05,
      "loss": 0.7091,
      "step": 297
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1144580841064453,
      "learning_rate": 7.58340113913751e-05,
      "loss": 1.6122,
      "step": 298
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5199196934700012,
      "learning_rate": 7.57526444263629e-05,
      "loss": 0.7664,
      "step": 299
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8993476629257202,
      "learning_rate": 7.56712774613507e-05,
      "loss": 1.1142,
      "step": 300
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7027885317802429,
      "learning_rate": 7.558991049633849e-05,
      "loss": 0.9296,
      "step": 301
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9098472595214844,
      "learning_rate": 7.550854353132628e-05,
      "loss": 0.7872,
      "step": 302
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7392101883888245,
      "learning_rate": 7.542717656631408e-05,
      "loss": 0.6179,
      "step": 303
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8441509008407593,
      "learning_rate": 7.534580960130187e-05,
      "loss": 0.7733,
      "step": 304
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6096581220626831,
      "learning_rate": 7.526444263628967e-05,
      "loss": 0.5022,
      "step": 305
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1801069974899292,
      "learning_rate": 7.518307567127747e-05,
      "loss": 1.0968,
      "step": 306
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.5840404033660889,
      "learning_rate": 7.510170870626526e-05,
      "loss": 1.2173,
      "step": 307
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7190548777580261,
      "learning_rate": 7.502034174125305e-05,
      "loss": 1.0383,
      "step": 308
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7271626591682434,
      "learning_rate": 7.493897477624084e-05,
      "loss": 1.223,
      "step": 309
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3926056623458862,
      "learning_rate": 7.485760781122865e-05,
      "loss": 1.5856,
      "step": 310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5509179830551147,
      "learning_rate": 7.477624084621644e-05,
      "loss": 0.7699,
      "step": 311
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.876136839389801,
      "learning_rate": 7.469487388120423e-05,
      "loss": 0.8156,
      "step": 312
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.131638765335083,
      "learning_rate": 7.461350691619203e-05,
      "loss": 1.5437,
      "step": 313
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4757815897464752,
      "learning_rate": 7.453213995117982e-05,
      "loss": 0.576,
      "step": 314
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1802740097045898,
      "learning_rate": 7.445077298616762e-05,
      "loss": 0.9228,
      "step": 315
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2230538129806519,
      "learning_rate": 7.436940602115542e-05,
      "loss": 1.29,
      "step": 316
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.09650456905365,
      "learning_rate": 7.428803905614321e-05,
      "loss": 1.2472,
      "step": 317
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1040197610855103,
      "learning_rate": 7.4206672091131e-05,
      "loss": 1.3105,
      "step": 318
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5601142048835754,
      "learning_rate": 7.41253051261188e-05,
      "loss": 0.6809,
      "step": 319
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5811443328857422,
      "learning_rate": 7.404393816110659e-05,
      "loss": 0.5418,
      "step": 320
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0015718936920166,
      "learning_rate": 7.396257119609439e-05,
      "loss": 1.1585,
      "step": 321
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6324251294136047,
      "learning_rate": 7.388120423108218e-05,
      "loss": 0.703,
      "step": 322
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6138088703155518,
      "learning_rate": 7.379983726606998e-05,
      "loss": 0.8626,
      "step": 323
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.720207929611206,
      "learning_rate": 7.371847030105777e-05,
      "loss": 1.177,
      "step": 324
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1528124809265137,
      "learning_rate": 7.363710333604557e-05,
      "loss": 0.9603,
      "step": 325
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2195322513580322,
      "learning_rate": 7.355573637103337e-05,
      "loss": 0.9905,
      "step": 326
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7583556175231934,
      "learning_rate": 7.347436940602116e-05,
      "loss": 0.7718,
      "step": 327
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.4487440586090088,
      "learning_rate": 7.339300244100895e-05,
      "loss": 1.1305,
      "step": 328
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2215105295181274,
      "learning_rate": 7.331163547599675e-05,
      "loss": 1.3478,
      "step": 329
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.781321108341217,
      "learning_rate": 7.323026851098454e-05,
      "loss": 0.9837,
      "step": 330
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8281465172767639,
      "learning_rate": 7.314890154597234e-05,
      "loss": 1.1684,
      "step": 331
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8301222324371338,
      "learning_rate": 7.306753458096013e-05,
      "loss": 0.9012,
      "step": 332
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6686298251152039,
      "learning_rate": 7.298616761594793e-05,
      "loss": 0.807,
      "step": 333
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.029314398765564,
      "learning_rate": 7.290480065093572e-05,
      "loss": 1.5083,
      "step": 334
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9293639063835144,
      "learning_rate": 7.282343368592351e-05,
      "loss": 0.7222,
      "step": 335
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7939097285270691,
      "learning_rate": 7.274206672091132e-05,
      "loss": 0.8728,
      "step": 336
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5548182725906372,
      "learning_rate": 7.266069975589911e-05,
      "loss": 0.6808,
      "step": 337
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5412890911102295,
      "learning_rate": 7.25793327908869e-05,
      "loss": 0.3699,
      "step": 338
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6055892109870911,
      "learning_rate": 7.24979658258747e-05,
      "loss": 0.5368,
      "step": 339
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8645841479301453,
      "learning_rate": 7.241659886086249e-05,
      "loss": 0.9837,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.44897398352622986,
      "learning_rate": 7.233523189585029e-05,
      "loss": 0.6006,
      "step": 341
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9151071310043335,
      "learning_rate": 7.225386493083808e-05,
      "loss": 1.0415,
      "step": 342
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8605282306671143,
      "learning_rate": 7.217249796582588e-05,
      "loss": 1.0773,
      "step": 343
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1333786249160767,
      "learning_rate": 7.209113100081367e-05,
      "loss": 1.1691,
      "step": 344
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7468938827514648,
      "learning_rate": 7.200976403580146e-05,
      "loss": 0.8873,
      "step": 345
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.45303961634635925,
      "learning_rate": 7.192839707078926e-05,
      "loss": 0.553,
      "step": 346
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2582523822784424,
      "learning_rate": 7.184703010577706e-05,
      "loss": 1.2316,
      "step": 347
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5601436495780945,
      "learning_rate": 7.176566314076485e-05,
      "loss": 0.6065,
      "step": 348
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.158089280128479,
      "learning_rate": 7.168429617575265e-05,
      "loss": 0.9999,
      "step": 349
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5752043724060059,
      "learning_rate": 7.160292921074044e-05,
      "loss": 0.8318,
      "step": 350
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0750114917755127,
      "learning_rate": 7.152156224572824e-05,
      "loss": 1.0455,
      "step": 351
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7209867835044861,
      "learning_rate": 7.144019528071604e-05,
      "loss": 0.5852,
      "step": 352
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8065118193626404,
      "learning_rate": 7.135882831570383e-05,
      "loss": 1.2667,
      "step": 353
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8726412057876587,
      "learning_rate": 7.127746135069162e-05,
      "loss": 1.1423,
      "step": 354
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7360326647758484,
      "learning_rate": 7.119609438567941e-05,
      "loss": 0.6189,
      "step": 355
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8475087285041809,
      "learning_rate": 7.111472742066721e-05,
      "loss": 0.7894,
      "step": 356
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0157675743103027,
      "learning_rate": 7.103336045565501e-05,
      "loss": 1.0488,
      "step": 357
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6275478601455688,
      "learning_rate": 7.09519934906428e-05,
      "loss": 0.8889,
      "step": 358
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5299341082572937,
      "learning_rate": 7.08706265256306e-05,
      "loss": 0.8325,
      "step": 359
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6463274359703064,
      "learning_rate": 7.078925956061839e-05,
      "loss": 1.0402,
      "step": 360
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0324066877365112,
      "learning_rate": 7.070789259560618e-05,
      "loss": 1.0157,
      "step": 361
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7876360416412354,
      "learning_rate": 7.0626525630594e-05,
      "loss": 0.7815,
      "step": 362
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8632786273956299,
      "learning_rate": 7.054515866558178e-05,
      "loss": 0.9324,
      "step": 363
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41354286670684814,
      "learning_rate": 7.046379170056957e-05,
      "loss": 0.6231,
      "step": 364
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3238896131515503,
      "learning_rate": 7.038242473555736e-05,
      "loss": 1.316,
      "step": 365
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7859655022621155,
      "learning_rate": 7.030105777054516e-05,
      "loss": 0.8611,
      "step": 366
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4642760455608368,
      "learning_rate": 7.021969080553296e-05,
      "loss": 0.4884,
      "step": 367
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7969459891319275,
      "learning_rate": 7.013832384052075e-05,
      "loss": 0.8053,
      "step": 368
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9356877207756042,
      "learning_rate": 7.005695687550855e-05,
      "loss": 1.0065,
      "step": 369
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9073131680488586,
      "learning_rate": 6.997558991049634e-05,
      "loss": 0.8167,
      "step": 370
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9955530762672424,
      "learning_rate": 6.989422294548413e-05,
      "loss": 0.9638,
      "step": 371
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3395203649997711,
      "learning_rate": 6.981285598047193e-05,
      "loss": 0.4883,
      "step": 372
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7193959951400757,
      "learning_rate": 6.973148901545973e-05,
      "loss": 1.1615,
      "step": 373
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8892784118652344,
      "learning_rate": 6.965012205044752e-05,
      "loss": 1.1104,
      "step": 374
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9464267492294312,
      "learning_rate": 6.956875508543532e-05,
      "loss": 0.7149,
      "step": 375
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2020570039749146,
      "learning_rate": 6.948738812042311e-05,
      "loss": 1.5454,
      "step": 376
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7072005271911621,
      "learning_rate": 6.940602115541091e-05,
      "loss": 1.2628,
      "step": 377
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7358663082122803,
      "learning_rate": 6.93246541903987e-05,
      "loss": 0.938,
      "step": 378
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5370103716850281,
      "learning_rate": 6.92432872253865e-05,
      "loss": 0.809,
      "step": 379
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2304867506027222,
      "learning_rate": 6.916192026037429e-05,
      "loss": 1.1237,
      "step": 380
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.917971670627594,
      "learning_rate": 6.908055329536208e-05,
      "loss": 1.0866,
      "step": 381
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0093944072723389,
      "learning_rate": 6.899918633034988e-05,
      "loss": 0.9113,
      "step": 382
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9909367561340332,
      "learning_rate": 6.891781936533768e-05,
      "loss": 1.4253,
      "step": 383
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.512016773223877,
      "learning_rate": 6.883645240032547e-05,
      "loss": 0.8827,
      "step": 384
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0255626440048218,
      "learning_rate": 6.875508543531327e-05,
      "loss": 1.0548,
      "step": 385
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7610288262367249,
      "learning_rate": 6.867371847030106e-05,
      "loss": 0.8119,
      "step": 386
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8561001420021057,
      "learning_rate": 6.859235150528885e-05,
      "loss": 1.4018,
      "step": 387
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44941219687461853,
      "learning_rate": 6.851098454027665e-05,
      "loss": 0.8535,
      "step": 388
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6087060570716858,
      "learning_rate": 6.842961757526445e-05,
      "loss": 0.9055,
      "step": 389
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9571650624275208,
      "learning_rate": 6.834825061025224e-05,
      "loss": 1.2005,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8718775510787964,
      "learning_rate": 6.826688364524003e-05,
      "loss": 1.1093,
      "step": 391
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5876571536064148,
      "learning_rate": 6.818551668022783e-05,
      "loss": 0.5635,
      "step": 392
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4578257203102112,
      "learning_rate": 6.810414971521563e-05,
      "loss": 0.4968,
      "step": 393
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.43109622597694397,
      "learning_rate": 6.802278275020342e-05,
      "loss": 0.5988,
      "step": 394
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39121371507644653,
      "learning_rate": 6.794141578519122e-05,
      "loss": 0.4829,
      "step": 395
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.871369481086731,
      "learning_rate": 6.786004882017901e-05,
      "loss": 1.0992,
      "step": 396
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5165542364120483,
      "learning_rate": 6.77786818551668e-05,
      "loss": 0.7876,
      "step": 397
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6273494958877563,
      "learning_rate": 6.76973148901546e-05,
      "loss": 0.7647,
      "step": 398
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7162122130393982,
      "learning_rate": 6.76159479251424e-05,
      "loss": 0.6193,
      "step": 399
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4669828414916992,
      "learning_rate": 6.753458096013019e-05,
      "loss": 0.9702,
      "step": 400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6708078384399414,
      "learning_rate": 6.745321399511798e-05,
      "loss": 1.1509,
      "step": 401
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7443182468414307,
      "learning_rate": 6.737184703010578e-05,
      "loss": 1.0896,
      "step": 402
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5418397188186646,
      "learning_rate": 6.729048006509358e-05,
      "loss": 0.4949,
      "step": 403
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6758734583854675,
      "learning_rate": 6.720911310008137e-05,
      "loss": 0.8718,
      "step": 404
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4677419662475586,
      "learning_rate": 6.712774613506917e-05,
      "loss": 1.3438,
      "step": 405
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1408543586730957,
      "learning_rate": 6.704637917005696e-05,
      "loss": 1.2811,
      "step": 406
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.650711178779602,
      "learning_rate": 6.696501220504475e-05,
      "loss": 1.0335,
      "step": 407
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9792209267616272,
      "learning_rate": 6.688364524003255e-05,
      "loss": 0.868,
      "step": 408
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1181983947753906,
      "learning_rate": 6.680227827502035e-05,
      "loss": 1.2212,
      "step": 409
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9368398189544678,
      "learning_rate": 6.672091131000814e-05,
      "loss": 1.2547,
      "step": 410
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7561774253845215,
      "learning_rate": 6.663954434499593e-05,
      "loss": 0.9668,
      "step": 411
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0116153955459595,
      "learning_rate": 6.655817737998373e-05,
      "loss": 0.8023,
      "step": 412
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.283531665802002,
      "learning_rate": 6.647681041497152e-05,
      "loss": 0.9929,
      "step": 413
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4699971377849579,
      "learning_rate": 6.639544344995932e-05,
      "loss": 0.7679,
      "step": 414
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8930302858352661,
      "learning_rate": 6.631407648494712e-05,
      "loss": 1.2194,
      "step": 415
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5503711700439453,
      "learning_rate": 6.623270951993491e-05,
      "loss": 0.6616,
      "step": 416
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.737409770488739,
      "learning_rate": 6.61513425549227e-05,
      "loss": 0.9524,
      "step": 417
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5856195688247681,
      "learning_rate": 6.60699755899105e-05,
      "loss": 0.6645,
      "step": 418
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5497475266456604,
      "learning_rate": 6.59886086248983e-05,
      "loss": 0.6409,
      "step": 419
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.107007622718811,
      "learning_rate": 6.590724165988609e-05,
      "loss": 1.2247,
      "step": 420
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5265471935272217,
      "learning_rate": 6.582587469487388e-05,
      "loss": 0.8116,
      "step": 421
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6831372976303101,
      "learning_rate": 6.574450772986168e-05,
      "loss": 0.8372,
      "step": 422
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2975950241088867,
      "learning_rate": 6.566314076484947e-05,
      "loss": 1.0404,
      "step": 423
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5288728475570679,
      "learning_rate": 6.558177379983727e-05,
      "loss": 0.6672,
      "step": 424
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.231726884841919,
      "learning_rate": 6.550040683482507e-05,
      "loss": 1.7103,
      "step": 425
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0241070985794067,
      "learning_rate": 6.541903986981286e-05,
      "loss": 0.8321,
      "step": 426
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7389037609100342,
      "learning_rate": 6.533767290480065e-05,
      "loss": 0.7638,
      "step": 427
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6965824961662292,
      "learning_rate": 6.525630593978845e-05,
      "loss": 0.5504,
      "step": 428
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6298758387565613,
      "learning_rate": 6.517493897477625e-05,
      "loss": 0.6997,
      "step": 429
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5472612977027893,
      "learning_rate": 6.509357200976404e-05,
      "loss": 0.7455,
      "step": 430
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.033562183380127,
      "learning_rate": 6.501220504475184e-05,
      "loss": 1.0594,
      "step": 431
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3518221080303192,
      "learning_rate": 6.493083807973963e-05,
      "loss": 0.4576,
      "step": 432
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8664668202400208,
      "learning_rate": 6.484947111472742e-05,
      "loss": 1.0701,
      "step": 433
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6917628049850464,
      "learning_rate": 6.476810414971522e-05,
      "loss": 0.546,
      "step": 434
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0502201318740845,
      "learning_rate": 6.468673718470302e-05,
      "loss": 1.3114,
      "step": 435
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8451330661773682,
      "learning_rate": 6.460537021969081e-05,
      "loss": 0.8158,
      "step": 436
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0063819885253906,
      "learning_rate": 6.45240032546786e-05,
      "loss": 0.7434,
      "step": 437
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9401328563690186,
      "learning_rate": 6.44426362896664e-05,
      "loss": 1.3714,
      "step": 438
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.317338228225708,
      "learning_rate": 6.436126932465419e-05,
      "loss": 1.0678,
      "step": 439
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5921875834465027,
      "learning_rate": 6.427990235964199e-05,
      "loss": 0.7665,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.82649827003479,
      "learning_rate": 6.419853539462979e-05,
      "loss": 0.7946,
      "step": 441
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9025183916091919,
      "learning_rate": 6.411716842961758e-05,
      "loss": 0.9385,
      "step": 442
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.800669252872467,
      "learning_rate": 6.403580146460537e-05,
      "loss": 0.8116,
      "step": 443
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6892164945602417,
      "learning_rate": 6.395443449959317e-05,
      "loss": 0.7693,
      "step": 444
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6246453523635864,
      "learning_rate": 6.387306753458097e-05,
      "loss": 1.2855,
      "step": 445
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1366223096847534,
      "learning_rate": 6.379170056956876e-05,
      "loss": 1.059,
      "step": 446
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6056963801383972,
      "learning_rate": 6.371033360455655e-05,
      "loss": 0.7721,
      "step": 447
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8446245193481445,
      "learning_rate": 6.362896663954435e-05,
      "loss": 1.3435,
      "step": 448
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.166771650314331,
      "learning_rate": 6.354759967453214e-05,
      "loss": 1.2129,
      "step": 449
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.91486656665802,
      "learning_rate": 6.346623270951994e-05,
      "loss": 0.9543,
      "step": 450
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.44242480397224426,
      "learning_rate": 6.338486574450774e-05,
      "loss": 0.8505,
      "step": 451
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1194523572921753,
      "learning_rate": 6.330349877949553e-05,
      "loss": 1.0951,
      "step": 452
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5160027146339417,
      "learning_rate": 6.322213181448332e-05,
      "loss": 0.538,
      "step": 453
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7970009446144104,
      "learning_rate": 6.31407648494711e-05,
      "loss": 0.895,
      "step": 454
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0738459825515747,
      "learning_rate": 6.305939788445892e-05,
      "loss": 0.7148,
      "step": 455
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.742664098739624,
      "learning_rate": 6.297803091944671e-05,
      "loss": 1.0399,
      "step": 456
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7320007681846619,
      "learning_rate": 6.28966639544345e-05,
      "loss": 0.8672,
      "step": 457
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9153456091880798,
      "learning_rate": 6.28152969894223e-05,
      "loss": 1.0339,
      "step": 458
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8207343220710754,
      "learning_rate": 6.273393002441009e-05,
      "loss": 0.8955,
      "step": 459
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7629144191741943,
      "learning_rate": 6.265256305939789e-05,
      "loss": 1.1963,
      "step": 460
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8628401756286621,
      "learning_rate": 6.257119609438569e-05,
      "loss": 0.9058,
      "step": 461
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7695673704147339,
      "learning_rate": 6.248982912937348e-05,
      "loss": 0.8775,
      "step": 462
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9616317749023438,
      "learning_rate": 6.240846216436127e-05,
      "loss": 1.1074,
      "step": 463
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8759949207305908,
      "learning_rate": 6.232709519934907e-05,
      "loss": 0.8622,
      "step": 464
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5710090398788452,
      "learning_rate": 6.224572823433686e-05,
      "loss": 0.6089,
      "step": 465
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6876572370529175,
      "learning_rate": 6.216436126932466e-05,
      "loss": 0.9672,
      "step": 466
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3696891069412231,
      "learning_rate": 6.208299430431245e-05,
      "loss": 1.0802,
      "step": 467
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5885778069496155,
      "learning_rate": 6.200162733930025e-05,
      "loss": 0.8641,
      "step": 468
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7974477410316467,
      "learning_rate": 6.192026037428804e-05,
      "loss": 0.7488,
      "step": 469
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8569568395614624,
      "learning_rate": 6.183889340927584e-05,
      "loss": 1.0022,
      "step": 470
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3305455446243286,
      "learning_rate": 6.175752644426364e-05,
      "loss": 1.6913,
      "step": 471
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6669621467590332,
      "learning_rate": 6.167615947925143e-05,
      "loss": 1.1418,
      "step": 472
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6345348954200745,
      "learning_rate": 6.159479251423922e-05,
      "loss": 0.36,
      "step": 473
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6098847985267639,
      "learning_rate": 6.151342554922702e-05,
      "loss": 0.5261,
      "step": 474
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.6980525255203247,
      "learning_rate": 6.143205858421481e-05,
      "loss": 1.4956,
      "step": 475
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.645382821559906,
      "learning_rate": 6.135069161920261e-05,
      "loss": 1.1345,
      "step": 476
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7746870517730713,
      "learning_rate": 6.12693246541904e-05,
      "loss": 0.741,
      "step": 477
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6493061780929565,
      "learning_rate": 6.11879576891782e-05,
      "loss": 1.0487,
      "step": 478
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6235073208808899,
      "learning_rate": 6.110659072416599e-05,
      "loss": 0.9948,
      "step": 479
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3207913637161255,
      "learning_rate": 6.102522375915378e-05,
      "loss": 0.7505,
      "step": 480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5473882555961609,
      "learning_rate": 6.0943856794141585e-05,
      "loss": 0.8281,
      "step": 481
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0207306146621704,
      "learning_rate": 6.086248982912938e-05,
      "loss": 1.0188,
      "step": 482
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6652854084968567,
      "learning_rate": 6.078112286411717e-05,
      "loss": 0.666,
      "step": 483
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1074491739273071,
      "learning_rate": 6.069975589910497e-05,
      "loss": 0.9439,
      "step": 484
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4938315749168396,
      "learning_rate": 6.0618388934092765e-05,
      "loss": 1.1503,
      "step": 485
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6556141376495361,
      "learning_rate": 6.053702196908055e-05,
      "loss": 0.8335,
      "step": 486
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9830357432365417,
      "learning_rate": 6.0455655004068355e-05,
      "loss": 1.2016,
      "step": 487
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9373745918273926,
      "learning_rate": 6.037428803905615e-05,
      "loss": 0.8111,
      "step": 488
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0152666568756104,
      "learning_rate": 6.029292107404394e-05,
      "loss": 1.2972,
      "step": 489
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5249193906784058,
      "learning_rate": 6.021155410903173e-05,
      "loss": 0.6687,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3804837763309479,
      "learning_rate": 6.0130187144019535e-05,
      "loss": 0.3194,
      "step": 491
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9609169960021973,
      "learning_rate": 6.004882017900732e-05,
      "loss": 0.7614,
      "step": 492
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5550928115844727,
      "learning_rate": 5.996745321399512e-05,
      "loss": 0.5762,
      "step": 493
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3122117519378662,
      "learning_rate": 5.988608624898292e-05,
      "loss": 1.09,
      "step": 494
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1992322206497192,
      "learning_rate": 5.980471928397071e-05,
      "loss": 2.0544,
      "step": 495
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9384532570838928,
      "learning_rate": 5.97233523189585e-05,
      "loss": 1.2275,
      "step": 496
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9384461045265198,
      "learning_rate": 5.9641985353946305e-05,
      "loss": 0.8211,
      "step": 497
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8706845045089722,
      "learning_rate": 5.95606183889341e-05,
      "loss": 0.8245,
      "step": 498
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1116446256637573,
      "learning_rate": 5.947925142392189e-05,
      "loss": 1.3079,
      "step": 499
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9395408034324646,
      "learning_rate": 5.939788445890968e-05,
      "loss": 1.1743,
      "step": 500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5768899917602539,
      "learning_rate": 5.9316517493897485e-05,
      "loss": 0.7841,
      "step": 501
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7825543880462646,
      "learning_rate": 5.923515052888527e-05,
      "loss": 1.2244,
      "step": 502
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9724684953689575,
      "learning_rate": 5.915378356387307e-05,
      "loss": 0.3741,
      "step": 503
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5898157358169556,
      "learning_rate": 5.907241659886087e-05,
      "loss": 1.1093,
      "step": 504
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6565450429916382,
      "learning_rate": 5.899104963384866e-05,
      "loss": 1.0379,
      "step": 505
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5678112506866455,
      "learning_rate": 5.890968266883645e-05,
      "loss": 0.79,
      "step": 506
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7878627777099609,
      "learning_rate": 5.8828315703824255e-05,
      "loss": 1.13,
      "step": 507
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0655958652496338,
      "learning_rate": 5.874694873881204e-05,
      "loss": 1.073,
      "step": 508
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5989378094673157,
      "learning_rate": 5.866558177379984e-05,
      "loss": 0.9132,
      "step": 509
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.676837146282196,
      "learning_rate": 5.8584214808787626e-05,
      "loss": 1.1176,
      "step": 510
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.773410975933075,
      "learning_rate": 5.8502847843775435e-05,
      "loss": 0.8352,
      "step": 511
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4093351364135742,
      "learning_rate": 5.842148087876322e-05,
      "loss": 0.4185,
      "step": 512
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3071671724319458,
      "learning_rate": 5.834011391375102e-05,
      "loss": 1.0548,
      "step": 513
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4849462509155273,
      "learning_rate": 5.825874694873882e-05,
      "loss": 1.5715,
      "step": 514
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4369949698448181,
      "learning_rate": 5.817737998372661e-05,
      "loss": 0.5277,
      "step": 515
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0520869493484497,
      "learning_rate": 5.80960130187144e-05,
      "loss": 0.686,
      "step": 516
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8211096525192261,
      "learning_rate": 5.8014646053702205e-05,
      "loss": 0.9865,
      "step": 517
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0036351680755615,
      "learning_rate": 5.793327908868999e-05,
      "loss": 1.3146,
      "step": 518
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0019102096557617,
      "learning_rate": 5.785191212367779e-05,
      "loss": 1.1309,
      "step": 519
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9783061146736145,
      "learning_rate": 5.777054515866559e-05,
      "loss": 0.8236,
      "step": 520
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0357855558395386,
      "learning_rate": 5.768917819365338e-05,
      "loss": 1.0627,
      "step": 521
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0410206317901611,
      "learning_rate": 5.760781122864117e-05,
      "loss": 0.8052,
      "step": 522
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7793325781822205,
      "learning_rate": 5.752644426362896e-05,
      "loss": 0.6948,
      "step": 523
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1461197137832642,
      "learning_rate": 5.744507729861677e-05,
      "loss": 0.9385,
      "step": 524
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7803934216499329,
      "learning_rate": 5.736371033360456e-05,
      "loss": 0.7662,
      "step": 525
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.785191535949707,
      "learning_rate": 5.728234336859235e-05,
      "loss": 1.1711,
      "step": 526
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9716213941574097,
      "learning_rate": 5.7200976403580155e-05,
      "loss": 0.9955,
      "step": 527
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8566750884056091,
      "learning_rate": 5.711960943856794e-05,
      "loss": 0.9201,
      "step": 528
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7638450264930725,
      "learning_rate": 5.703824247355574e-05,
      "loss": 1.0648,
      "step": 529
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5762718319892883,
      "learning_rate": 5.695687550854354e-05,
      "loss": 0.651,
      "step": 530
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6613500714302063,
      "learning_rate": 5.687550854353133e-05,
      "loss": 0.9233,
      "step": 531
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9975193738937378,
      "learning_rate": 5.679414157851912e-05,
      "loss": 1.3106,
      "step": 532
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.30861234664917,
      "learning_rate": 5.671277461350691e-05,
      "loss": 1.3278,
      "step": 533
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7056947946548462,
      "learning_rate": 5.663140764849471e-05,
      "loss": 1.1203,
      "step": 534
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6406270265579224,
      "learning_rate": 5.655004068348251e-05,
      "loss": 0.951,
      "step": 535
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7916213870048523,
      "learning_rate": 5.6468673718470296e-05,
      "loss": 0.878,
      "step": 536
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5218969583511353,
      "learning_rate": 5.6387306753458105e-05,
      "loss": 1.462,
      "step": 537
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9210233688354492,
      "learning_rate": 5.630593978844589e-05,
      "loss": 1.0394,
      "step": 538
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6508886218070984,
      "learning_rate": 5.622457282343369e-05,
      "loss": 0.921,
      "step": 539
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6823954582214355,
      "learning_rate": 5.614320585842149e-05,
      "loss": 1.0303,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.36254772543907166,
      "learning_rate": 5.606183889340928e-05,
      "loss": 0.5343,
      "step": 541
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.032105565071106,
      "learning_rate": 5.598047192839707e-05,
      "loss": 1.3575,
      "step": 542
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6127286553382874,
      "learning_rate": 5.589910496338486e-05,
      "loss": 0.7139,
      "step": 543
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2080950736999512,
      "learning_rate": 5.581773799837266e-05,
      "loss": 0.8086,
      "step": 544
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4490814208984375,
      "learning_rate": 5.573637103336046e-05,
      "loss": 1.1097,
      "step": 545
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5848093032836914,
      "learning_rate": 5.5655004068348246e-05,
      "loss": 0.5484,
      "step": 546
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6163774728775024,
      "learning_rate": 5.557363710333605e-05,
      "loss": 0.8011,
      "step": 547
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8966221213340759,
      "learning_rate": 5.549227013832384e-05,
      "loss": 0.7287,
      "step": 548
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.471868097782135,
      "learning_rate": 5.541090317331163e-05,
      "loss": 0.5517,
      "step": 549
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.399962067604065,
      "learning_rate": 5.532953620829944e-05,
      "loss": 1.2831,
      "step": 550
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9186580181121826,
      "learning_rate": 5.524816924328723e-05,
      "loss": 0.7694,
      "step": 551
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6334792375564575,
      "learning_rate": 5.516680227827502e-05,
      "loss": 0.7696,
      "step": 552
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7273058891296387,
      "learning_rate": 5.5085435313262825e-05,
      "loss": 0.8228,
      "step": 553
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.506654679775238,
      "learning_rate": 5.500406834825061e-05,
      "loss": 0.6971,
      "step": 554
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7382021546363831,
      "learning_rate": 5.492270138323841e-05,
      "loss": 1.0973,
      "step": 555
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1680047512054443,
      "learning_rate": 5.4841334418226196e-05,
      "loss": 1.7315,
      "step": 556
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0544523000717163,
      "learning_rate": 5.4759967453214e-05,
      "loss": 0.8512,
      "step": 557
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.194690704345703,
      "learning_rate": 5.467860048820179e-05,
      "loss": 1.0339,
      "step": 558
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6848272681236267,
      "learning_rate": 5.459723352318958e-05,
      "loss": 0.841,
      "step": 559
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5489332675933838,
      "learning_rate": 5.451586655817738e-05,
      "loss": 0.8169,
      "step": 560
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.827978789806366,
      "learning_rate": 5.443449959316518e-05,
      "loss": 1.0224,
      "step": 561
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9488615989685059,
      "learning_rate": 5.4353132628152966e-05,
      "loss": 1.1663,
      "step": 562
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6355089545249939,
      "learning_rate": 5.4271765663140775e-05,
      "loss": 1.0231,
      "step": 563
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7735033631324768,
      "learning_rate": 5.419039869812856e-05,
      "loss": 0.7995,
      "step": 564
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0531034469604492,
      "learning_rate": 5.410903173311636e-05,
      "loss": 0.7098,
      "step": 565
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.49042603373527527,
      "learning_rate": 5.4027664768104146e-05,
      "loss": 0.5171,
      "step": 566
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5784401297569275,
      "learning_rate": 5.394629780309195e-05,
      "loss": 0.9932,
      "step": 567
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.556158721446991,
      "learning_rate": 5.386493083807974e-05,
      "loss": 0.8725,
      "step": 568
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7331648468971252,
      "learning_rate": 5.378356387306753e-05,
      "loss": 1.1201,
      "step": 569
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2879635095596313,
      "learning_rate": 5.370219690805533e-05,
      "loss": 0.9299,
      "step": 570
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5415328145027161,
      "learning_rate": 5.362082994304313e-05,
      "loss": 0.6817,
      "step": 571
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9359896779060364,
      "learning_rate": 5.3539462978030916e-05,
      "loss": 1.2725,
      "step": 572
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7566179037094116,
      "learning_rate": 5.345809601301872e-05,
      "loss": 1.2597,
      "step": 573
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4654691219329834,
      "learning_rate": 5.337672904800651e-05,
      "loss": 1.3989,
      "step": 574
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7490683197975159,
      "learning_rate": 5.32953620829943e-05,
      "loss": 1.0177,
      "step": 575
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8375152945518494,
      "learning_rate": 5.321399511798211e-05,
      "loss": 0.7854,
      "step": 576
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9425846338272095,
      "learning_rate": 5.31326281529699e-05,
      "loss": 1.1336,
      "step": 577
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2229481935501099,
      "learning_rate": 5.305126118795769e-05,
      "loss": 1.5329,
      "step": 578
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1513750553131104,
      "learning_rate": 5.296989422294548e-05,
      "loss": 1.1218,
      "step": 579
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.64730304479599,
      "learning_rate": 5.288852725793328e-05,
      "loss": 0.6937,
      "step": 580
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3473070859909058,
      "learning_rate": 5.280716029292108e-05,
      "loss": 1.2724,
      "step": 581
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3204020261764526,
      "learning_rate": 5.2725793327908866e-05,
      "loss": 1.6099,
      "step": 582
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8414969444274902,
      "learning_rate": 5.264442636289667e-05,
      "loss": 1.1175,
      "step": 583
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.45897701382637024,
      "learning_rate": 5.256305939788446e-05,
      "loss": 0.5246,
      "step": 584
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3900439441204071,
      "learning_rate": 5.248169243287225e-05,
      "loss": 0.4702,
      "step": 585
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7965313196182251,
      "learning_rate": 5.240032546786005e-05,
      "loss": 0.8713,
      "step": 586
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5038793683052063,
      "learning_rate": 5.231895850284785e-05,
      "loss": 0.7453,
      "step": 587
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0061637163162231,
      "learning_rate": 5.2237591537835636e-05,
      "loss": 0.9101,
      "step": 588
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.864578366279602,
      "learning_rate": 5.215622457282343e-05,
      "loss": 0.9706,
      "step": 589
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7505999207496643,
      "learning_rate": 5.207485760781123e-05,
      "loss": 0.8715,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4567958116531372,
      "learning_rate": 5.199349064279903e-05,
      "loss": 1.4202,
      "step": 591
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9761587977409363,
      "learning_rate": 5.1912123677786816e-05,
      "loss": 0.745,
      "step": 592
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9056228399276733,
      "learning_rate": 5.183075671277462e-05,
      "loss": 0.799,
      "step": 593
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7841175198554993,
      "learning_rate": 5.174938974776241e-05,
      "loss": 1.1661,
      "step": 594
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.37965917587280273,
      "learning_rate": 5.16680227827502e-05,
      "loss": 0.7451,
      "step": 595
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0737446546554565,
      "learning_rate": 5.1586655817738e-05,
      "loss": 1.1649,
      "step": 596
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.45824235677719116,
      "learning_rate": 5.15052888527258e-05,
      "loss": 0.3909,
      "step": 597
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8324745893478394,
      "learning_rate": 5.1423921887713586e-05,
      "loss": 0.7454,
      "step": 598
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9642035365104675,
      "learning_rate": 5.134255492270138e-05,
      "loss": 0.9408,
      "step": 599
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.605208158493042,
      "learning_rate": 5.126118795768918e-05,
      "loss": 0.6611,
      "step": 600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6478846669197083,
      "learning_rate": 5.117982099267697e-05,
      "loss": 1.2217,
      "step": 601
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4937068819999695,
      "learning_rate": 5.1098454027664766e-05,
      "loss": 0.4881,
      "step": 602
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3149962425231934,
      "learning_rate": 5.101708706265257e-05,
      "loss": 1.1353,
      "step": 603
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5535268783569336,
      "learning_rate": 5.093572009764036e-05,
      "loss": 0.6373,
      "step": 604
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3846652507781982,
      "learning_rate": 5.085435313262815e-05,
      "loss": 1.5607,
      "step": 605
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7455015182495117,
      "learning_rate": 5.077298616761595e-05,
      "loss": 0.9412,
      "step": 606
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4460599422454834,
      "learning_rate": 5.069161920260375e-05,
      "loss": 0.5704,
      "step": 607
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.44915664196014404,
      "learning_rate": 5.0610252237591537e-05,
      "loss": 0.5996,
      "step": 608
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9187003970146179,
      "learning_rate": 5.052888527257934e-05,
      "loss": 1.2566,
      "step": 609
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5787679553031921,
      "learning_rate": 5.044751830756713e-05,
      "loss": 0.6097,
      "step": 610
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5719014406204224,
      "learning_rate": 5.036615134255492e-05,
      "loss": 1.1938,
      "step": 611
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7997685670852661,
      "learning_rate": 5.0284784377542717e-05,
      "loss": 0.9675,
      "step": 612
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8483803868293762,
      "learning_rate": 5.020341741253052e-05,
      "loss": 0.7648,
      "step": 613
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5841324329376221,
      "learning_rate": 5.0122050447518307e-05,
      "loss": 0.6547,
      "step": 614
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7415092587471008,
      "learning_rate": 5.00406834825061e-05,
      "loss": 0.9036,
      "step": 615
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2518030405044556,
      "learning_rate": 4.9959316517493897e-05,
      "loss": 0.8281,
      "step": 616
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5524792671203613,
      "learning_rate": 4.98779495524817e-05,
      "loss": 0.9753,
      "step": 617
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.39180442690849304,
      "learning_rate": 4.979658258746949e-05,
      "loss": 0.4938,
      "step": 618
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0513949394226074,
      "learning_rate": 4.971521562245728e-05,
      "loss": 0.9724,
      "step": 619
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8261446356773376,
      "learning_rate": 4.963384865744508e-05,
      "loss": 0.7171,
      "step": 620
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2737104892730713,
      "learning_rate": 4.955248169243287e-05,
      "loss": 0.9929,
      "step": 621
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1933541297912598,
      "learning_rate": 4.9471114727420667e-05,
      "loss": 0.8718,
      "step": 622
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6769242882728577,
      "learning_rate": 4.938974776240847e-05,
      "loss": 0.6743,
      "step": 623
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.49497872591018677,
      "learning_rate": 4.9308380797396257e-05,
      "loss": 0.6648,
      "step": 624
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5892050862312317,
      "learning_rate": 4.922701383238406e-05,
      "loss": 0.6452,
      "step": 625
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6386793851852417,
      "learning_rate": 4.9145646867371847e-05,
      "loss": 0.5373,
      "step": 626
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.192048192024231,
      "learning_rate": 4.906427990235964e-05,
      "loss": 1.6053,
      "step": 627
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9975814819335938,
      "learning_rate": 4.898291293734744e-05,
      "loss": 1.194,
      "step": 628
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9773938655853271,
      "learning_rate": 4.890154597233523e-05,
      "loss": 0.992,
      "step": 629
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7016297578811646,
      "learning_rate": 4.882017900732303e-05,
      "loss": 0.705,
      "step": 630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8211454749107361,
      "learning_rate": 4.873881204231082e-05,
      "loss": 0.9291,
      "step": 631
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6446359157562256,
      "learning_rate": 4.8657445077298617e-05,
      "loss": 0.6298,
      "step": 632
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0344001054763794,
      "learning_rate": 4.857607811228642e-05,
      "loss": 1.3298,
      "step": 633
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7511570453643799,
      "learning_rate": 4.8494711147274207e-05,
      "loss": 1.2522,
      "step": 634
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0963902473449707,
      "learning_rate": 4.8413344182262e-05,
      "loss": 1.2429,
      "step": 635
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7671720385551453,
      "learning_rate": 4.8331977217249797e-05,
      "loss": 1.2642,
      "step": 636
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5058213472366333,
      "learning_rate": 4.825061025223759e-05,
      "loss": 1.1551,
      "step": 637
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7555751800537109,
      "learning_rate": 4.816924328722539e-05,
      "loss": 0.6866,
      "step": 638
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7937266826629639,
      "learning_rate": 4.808787632221318e-05,
      "loss": 0.9287,
      "step": 639
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38538458943367004,
      "learning_rate": 4.8006509357200977e-05,
      "loss": 0.5244,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8669441938400269,
      "learning_rate": 4.792514239218877e-05,
      "loss": 1.0702,
      "step": 641
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.44227585196495056,
      "learning_rate": 4.7843775427176567e-05,
      "loss": 0.3924,
      "step": 642
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.985666036605835,
      "learning_rate": 4.776240846216437e-05,
      "loss": 1.0199,
      "step": 643
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6030688285827637,
      "learning_rate": 4.7681041497152157e-05,
      "loss": 0.613,
      "step": 644
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3146442174911499,
      "learning_rate": 4.759967453213995e-05,
      "loss": 0.3,
      "step": 645
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5997203588485718,
      "learning_rate": 4.751830756712775e-05,
      "loss": 0.6382,
      "step": 646
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.44549262523651123,
      "learning_rate": 4.743694060211554e-05,
      "loss": 0.5455,
      "step": 647
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7415521740913391,
      "learning_rate": 4.7355573637103337e-05,
      "loss": 0.7539,
      "step": 648
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5136470794677734,
      "learning_rate": 4.727420667209113e-05,
      "loss": 0.4792,
      "step": 649
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7254831790924072,
      "learning_rate": 4.7192839707078927e-05,
      "loss": 0.668,
      "step": 650
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45922207832336426,
      "learning_rate": 4.711147274206673e-05,
      "loss": 0.6449,
      "step": 651
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1948802471160889,
      "learning_rate": 4.7030105777054517e-05,
      "loss": 0.7639,
      "step": 652
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8625102043151855,
      "learning_rate": 4.694873881204231e-05,
      "loss": 0.8038,
      "step": 653
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9254575967788696,
      "learning_rate": 4.6867371847030107e-05,
      "loss": 1.5385,
      "step": 654
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9435878396034241,
      "learning_rate": 4.67860048820179e-05,
      "loss": 0.9019,
      "step": 655
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4459647834300995,
      "learning_rate": 4.67046379170057e-05,
      "loss": 0.564,
      "step": 656
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7479492425918579,
      "learning_rate": 4.662327095199349e-05,
      "loss": 1.0159,
      "step": 657
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8064311742782593,
      "learning_rate": 4.6541903986981287e-05,
      "loss": 0.976,
      "step": 658
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.713878870010376,
      "learning_rate": 4.646053702196908e-05,
      "loss": 0.7492,
      "step": 659
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7902646660804749,
      "learning_rate": 4.6379170056956877e-05,
      "loss": 1.068,
      "step": 660
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.35591578483581543,
      "learning_rate": 4.629780309194467e-05,
      "loss": 0.3859,
      "step": 661
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6699565649032593,
      "learning_rate": 4.6216436126932467e-05,
      "loss": 1.2578,
      "step": 662
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6236169338226318,
      "learning_rate": 4.613506916192026e-05,
      "loss": 0.7726,
      "step": 663
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1721365451812744,
      "learning_rate": 4.6053702196908057e-05,
      "loss": 1.2917,
      "step": 664
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6692968010902405,
      "learning_rate": 4.597233523189585e-05,
      "loss": 0.8267,
      "step": 665
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4460706114768982,
      "learning_rate": 4.5890968266883647e-05,
      "loss": 0.4199,
      "step": 666
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9971643090248108,
      "learning_rate": 4.580960130187144e-05,
      "loss": 1.0854,
      "step": 667
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6862235069274902,
      "learning_rate": 4.5728234336859237e-05,
      "loss": 1.0171,
      "step": 668
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8020022511482239,
      "learning_rate": 4.564686737184703e-05,
      "loss": 1.4386,
      "step": 669
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8966377377510071,
      "learning_rate": 4.5565500406834827e-05,
      "loss": 0.635,
      "step": 670
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7647009491920471,
      "learning_rate": 4.548413344182262e-05,
      "loss": 1.1895,
      "step": 671
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6924013495445251,
      "learning_rate": 4.5402766476810417e-05,
      "loss": 0.9337,
      "step": 672
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.541563868522644,
      "learning_rate": 4.532139951179821e-05,
      "loss": 0.8598,
      "step": 673
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0430595874786377,
      "learning_rate": 4.5240032546786007e-05,
      "loss": 0.5907,
      "step": 674
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4499457776546478,
      "learning_rate": 4.51586655817738e-05,
      "loss": 0.6515,
      "step": 675
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0917026996612549,
      "learning_rate": 4.5077298616761597e-05,
      "loss": 1.3175,
      "step": 676
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6603482365608215,
      "learning_rate": 4.499593165174939e-05,
      "loss": 0.7785,
      "step": 677
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9380740523338318,
      "learning_rate": 4.4914564686737187e-05,
      "loss": 1.0733,
      "step": 678
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9584208130836487,
      "learning_rate": 4.483319772172498e-05,
      "loss": 1.0372,
      "step": 679
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6880402565002441,
      "learning_rate": 4.4751830756712777e-05,
      "loss": 0.931,
      "step": 680
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.325890064239502,
      "learning_rate": 4.467046379170057e-05,
      "loss": 1.6312,
      "step": 681
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7511489391326904,
      "learning_rate": 4.4589096826688367e-05,
      "loss": 0.7519,
      "step": 682
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8345388770103455,
      "learning_rate": 4.450772986167616e-05,
      "loss": 1.2523,
      "step": 683
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5821621417999268,
      "learning_rate": 4.4426362896663957e-05,
      "loss": 0.6221,
      "step": 684
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.818987250328064,
      "learning_rate": 4.434499593165175e-05,
      "loss": 1.207,
      "step": 685
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6340928077697754,
      "learning_rate": 4.4263628966639547e-05,
      "loss": 1.0693,
      "step": 686
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.06805419921875,
      "learning_rate": 4.418226200162734e-05,
      "loss": 1.0132,
      "step": 687
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8738368153572083,
      "learning_rate": 4.4100895036615137e-05,
      "loss": 1.0408,
      "step": 688
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8460438251495361,
      "learning_rate": 4.401952807160293e-05,
      "loss": 1.019,
      "step": 689
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47332051396369934,
      "learning_rate": 4.3938161106590727e-05,
      "loss": 0.5097,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6060498952865601,
      "learning_rate": 4.385679414157852e-05,
      "loss": 0.8645,
      "step": 691
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5517999529838562,
      "learning_rate": 4.3775427176566317e-05,
      "loss": 0.9599,
      "step": 692
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8024367690086365,
      "learning_rate": 4.369406021155411e-05,
      "loss": 1.2018,
      "step": 693
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4857267141342163,
      "learning_rate": 4.3612693246541907e-05,
      "loss": 0.6174,
      "step": 694
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.84770667552948,
      "learning_rate": 4.35313262815297e-05,
      "loss": 1.2914,
      "step": 695
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.741579532623291,
      "learning_rate": 4.3449959316517497e-05,
      "loss": 0.6853,
      "step": 696
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6185899376869202,
      "learning_rate": 4.336859235150529e-05,
      "loss": 0.594,
      "step": 697
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7421301603317261,
      "learning_rate": 4.3287225386493087e-05,
      "loss": 0.4541,
      "step": 698
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7620511651039124,
      "learning_rate": 4.320585842148088e-05,
      "loss": 1.2018,
      "step": 699
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6589945554733276,
      "learning_rate": 4.3124491456468677e-05,
      "loss": 0.9539,
      "step": 700
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8586084842681885,
      "learning_rate": 4.304312449145647e-05,
      "loss": 1.018,
      "step": 701
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2735835313796997,
      "learning_rate": 4.2961757526444267e-05,
      "loss": 1.3515,
      "step": 702
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.99994295835495,
      "learning_rate": 4.288039056143206e-05,
      "loss": 1.1195,
      "step": 703
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.471490740776062,
      "learning_rate": 4.2799023596419857e-05,
      "loss": 1.1936,
      "step": 704
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.08476722240448,
      "learning_rate": 4.271765663140765e-05,
      "loss": 0.9589,
      "step": 705
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7830626964569092,
      "learning_rate": 4.2636289666395447e-05,
      "loss": 0.8343,
      "step": 706
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4328559935092926,
      "learning_rate": 4.255492270138324e-05,
      "loss": 0.7342,
      "step": 707
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3586026728153229,
      "learning_rate": 4.2473555736371037e-05,
      "loss": 0.4374,
      "step": 708
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0029528141021729,
      "learning_rate": 4.239218877135883e-05,
      "loss": 1.1443,
      "step": 709
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8175105452537537,
      "learning_rate": 4.2310821806346627e-05,
      "loss": 0.6034,
      "step": 710
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.599618673324585,
      "learning_rate": 4.222945484133442e-05,
      "loss": 1.0322,
      "step": 711
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8362835049629211,
      "learning_rate": 4.2148087876322217e-05,
      "loss": 0.9065,
      "step": 712
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3160823583602905,
      "learning_rate": 4.206672091131001e-05,
      "loss": 1.2973,
      "step": 713
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5681240558624268,
      "learning_rate": 4.1985353946297807e-05,
      "loss": 0.7772,
      "step": 714
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1791846752166748,
      "learning_rate": 4.1903986981285595e-05,
      "loss": 1.2029,
      "step": 715
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2430154085159302,
      "learning_rate": 4.1822620016273397e-05,
      "loss": 1.7974,
      "step": 716
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5669133067131042,
      "learning_rate": 4.174125305126119e-05,
      "loss": 0.8525,
      "step": 717
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7002121210098267,
      "learning_rate": 4.1659886086248987e-05,
      "loss": 1.219,
      "step": 718
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5461600422859192,
      "learning_rate": 4.157851912123678e-05,
      "loss": 0.7534,
      "step": 719
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7542722821235657,
      "learning_rate": 4.149715215622457e-05,
      "loss": 1.4786,
      "step": 720
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2513837814331055,
      "learning_rate": 4.141578519121237e-05,
      "loss": 1.3907,
      "step": 721
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9117551445960999,
      "learning_rate": 4.1334418226200167e-05,
      "loss": 0.7827,
      "step": 722
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2727720737457275,
      "learning_rate": 4.125305126118796e-05,
      "loss": 0.7747,
      "step": 723
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.595603883266449,
      "learning_rate": 4.117168429617576e-05,
      "loss": 0.8986,
      "step": 724
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5357148051261902,
      "learning_rate": 4.1090317331163545e-05,
      "loss": 0.646,
      "step": 725
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6100726127624512,
      "learning_rate": 4.100895036615135e-05,
      "loss": 0.6857,
      "step": 726
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7082017660140991,
      "learning_rate": 4.092758340113914e-05,
      "loss": 0.9418,
      "step": 727
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5061252117156982,
      "learning_rate": 4.084621643612693e-05,
      "loss": 1.1461,
      "step": 728
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6834163665771484,
      "learning_rate": 4.076484947111473e-05,
      "loss": 0.9096,
      "step": 729
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0887123346328735,
      "learning_rate": 4.068348250610253e-05,
      "loss": 1.726,
      "step": 730
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6967318654060364,
      "learning_rate": 4.060211554109032e-05,
      "loss": 0.8709,
      "step": 731
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7580143213272095,
      "learning_rate": 4.052074857607812e-05,
      "loss": 1.2627,
      "step": 732
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5992588996887207,
      "learning_rate": 4.0439381611065905e-05,
      "loss": 0.8177,
      "step": 733
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.961589515209198,
      "learning_rate": 4.035801464605371e-05,
      "loss": 0.7521,
      "step": 734
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8922193050384521,
      "learning_rate": 4.02766476810415e-05,
      "loss": 1.1243,
      "step": 735
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7500666975975037,
      "learning_rate": 4.01952807160293e-05,
      "loss": 1.1668,
      "step": 736
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.4200454950332642,
      "learning_rate": 4.011391375101709e-05,
      "loss": 1.5653,
      "step": 737
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1898313760757446,
      "learning_rate": 4.003254678600488e-05,
      "loss": 1.1405,
      "step": 738
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4287097156047821,
      "learning_rate": 3.995117982099268e-05,
      "loss": 0.5293,
      "step": 739
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9825762510299683,
      "learning_rate": 3.986981285598048e-05,
      "loss": 1.5076,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5708979368209839,
      "learning_rate": 3.9788445890968265e-05,
      "loss": 0.6923,
      "step": 741
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0963433980941772,
      "learning_rate": 3.970707892595607e-05,
      "loss": 1.2209,
      "step": 742
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4229811429977417,
      "learning_rate": 3.9625711960943855e-05,
      "loss": 0.396,
      "step": 743
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7732272148132324,
      "learning_rate": 3.954434499593166e-05,
      "loss": 0.712,
      "step": 744
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.427558034658432,
      "learning_rate": 3.946297803091945e-05,
      "loss": 0.4647,
      "step": 745
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0658998489379883,
      "learning_rate": 3.938161106590724e-05,
      "loss": 1.0703,
      "step": 746
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4730564057826996,
      "learning_rate": 3.930024410089504e-05,
      "loss": 0.7235,
      "step": 747
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.39631107449531555,
      "learning_rate": 3.921887713588283e-05,
      "loss": 0.3787,
      "step": 748
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5938348770141602,
      "learning_rate": 3.9137510170870625e-05,
      "loss": 0.7058,
      "step": 749
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.528150737285614,
      "learning_rate": 3.905614320585843e-05,
      "loss": 0.5529,
      "step": 750
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9201925992965698,
      "learning_rate": 3.8974776240846215e-05,
      "loss": 1.1654,
      "step": 751
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0759317874908447,
      "learning_rate": 3.889340927583402e-05,
      "loss": 1.0193,
      "step": 752
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8843478560447693,
      "learning_rate": 3.8812042310821805e-05,
      "loss": 0.676,
      "step": 753
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1233241558074951,
      "learning_rate": 3.87306753458096e-05,
      "loss": 1.221,
      "step": 754
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2792974710464478,
      "learning_rate": 3.86493083807974e-05,
      "loss": 0.9336,
      "step": 755
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6508893370628357,
      "learning_rate": 3.856794141578519e-05,
      "loss": 0.7829,
      "step": 756
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3631695508956909,
      "learning_rate": 3.848657445077299e-05,
      "loss": 0.421,
      "step": 757
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.028435230255127,
      "learning_rate": 3.840520748576078e-05,
      "loss": 1.1663,
      "step": 758
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.802836000919342,
      "learning_rate": 3.8323840520748575e-05,
      "loss": 0.9454,
      "step": 759
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7131638526916504,
      "learning_rate": 3.824247355573638e-05,
      "loss": 1.1027,
      "step": 760
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6875905394554138,
      "learning_rate": 3.8161106590724165e-05,
      "loss": 0.8237,
      "step": 761
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0412311553955078,
      "learning_rate": 3.807973962571196e-05,
      "loss": 1.3028,
      "step": 762
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8023827075958252,
      "learning_rate": 3.799837266069976e-05,
      "loss": 1.064,
      "step": 763
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9834877848625183,
      "learning_rate": 3.791700569568755e-05,
      "loss": 1.0293,
      "step": 764
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8472090363502502,
      "learning_rate": 3.783563873067535e-05,
      "loss": 1.145,
      "step": 765
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0014245510101318,
      "learning_rate": 3.775427176566314e-05,
      "loss": 1.2681,
      "step": 766
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5210903882980347,
      "learning_rate": 3.7672904800650935e-05,
      "loss": 0.6047,
      "step": 767
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.998654305934906,
      "learning_rate": 3.759153783563874e-05,
      "loss": 1.2297,
      "step": 768
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.989334225654602,
      "learning_rate": 3.7510170870626525e-05,
      "loss": 1.2762,
      "step": 769
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4972486197948456,
      "learning_rate": 3.742880390561433e-05,
      "loss": 0.6763,
      "step": 770
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.49694931507110596,
      "learning_rate": 3.7347436940602115e-05,
      "loss": 0.8296,
      "step": 771
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5744380950927734,
      "learning_rate": 3.726606997558991e-05,
      "loss": 0.6322,
      "step": 772
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5798662900924683,
      "learning_rate": 3.718470301057771e-05,
      "loss": 0.6966,
      "step": 773
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7841179370880127,
      "learning_rate": 3.71033360455655e-05,
      "loss": 1.0055,
      "step": 774
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9549476504325867,
      "learning_rate": 3.7021969080553295e-05,
      "loss": 0.9294,
      "step": 775
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8991192579269409,
      "learning_rate": 3.694060211554109e-05,
      "loss": 1.0284,
      "step": 776
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6789273619651794,
      "learning_rate": 3.6859235150528885e-05,
      "loss": 0.7317,
      "step": 777
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.704237699508667,
      "learning_rate": 3.677786818551669e-05,
      "loss": 0.834,
      "step": 778
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.46653157472610474,
      "learning_rate": 3.6696501220504475e-05,
      "loss": 0.4878,
      "step": 779
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6012082695960999,
      "learning_rate": 3.661513425549227e-05,
      "loss": 0.7876,
      "step": 780
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0944557189941406,
      "learning_rate": 3.6533767290480065e-05,
      "loss": 1.1976,
      "step": 781
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5643728971481323,
      "learning_rate": 3.645240032546786e-05,
      "loss": 0.6474,
      "step": 782
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3991302251815796,
      "learning_rate": 3.637103336045566e-05,
      "loss": 1.0434,
      "step": 783
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.532550036907196,
      "learning_rate": 3.628966639544345e-05,
      "loss": 0.9098,
      "step": 784
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7142561078071594,
      "learning_rate": 3.6208299430431245e-05,
      "loss": 0.7501,
      "step": 785
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5472295880317688,
      "learning_rate": 3.612693246541904e-05,
      "loss": 0.7726,
      "step": 786
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9250215291976929,
      "learning_rate": 3.6045565500406835e-05,
      "loss": 0.9385,
      "step": 787
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9085770845413208,
      "learning_rate": 3.596419853539463e-05,
      "loss": 0.6321,
      "step": 788
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4650097191333771,
      "learning_rate": 3.5882831570382425e-05,
      "loss": 0.621,
      "step": 789
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5393809676170349,
      "learning_rate": 3.580146460537022e-05,
      "loss": 1.0584,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.694887101650238,
      "learning_rate": 3.572009764035802e-05,
      "loss": 0.9449,
      "step": 791
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3165102005004883,
      "learning_rate": 3.563873067534581e-05,
      "loss": 1.6949,
      "step": 792
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6493645310401917,
      "learning_rate": 3.5557363710333605e-05,
      "loss": 0.7613,
      "step": 793
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5908887982368469,
      "learning_rate": 3.54759967453214e-05,
      "loss": 1.1143,
      "step": 794
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6887881755828857,
      "learning_rate": 3.5394629780309195e-05,
      "loss": 1.0942,
      "step": 795
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.46542060375213623,
      "learning_rate": 3.5313262815297e-05,
      "loss": 0.4841,
      "step": 796
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.8544599413871765,
      "learning_rate": 3.5231895850284785e-05,
      "loss": 1.3441,
      "step": 797
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9126409888267517,
      "learning_rate": 3.515052888527258e-05,
      "loss": 0.9656,
      "step": 798
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6273937225341797,
      "learning_rate": 3.5069161920260375e-05,
      "loss": 0.9508,
      "step": 799
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7638962864875793,
      "learning_rate": 3.498779495524817e-05,
      "loss": 0.8777,
      "step": 800
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.099315881729126,
      "learning_rate": 3.4906427990235965e-05,
      "loss": 1.2548,
      "step": 801
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5755983591079712,
      "learning_rate": 3.482506102522376e-05,
      "loss": 0.6703,
      "step": 802
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7018863558769226,
      "learning_rate": 3.4743694060211555e-05,
      "loss": 0.4832,
      "step": 803
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5334758162498474,
      "learning_rate": 3.466232709519935e-05,
      "loss": 0.7261,
      "step": 804
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7525936961174011,
      "learning_rate": 3.4580960130187145e-05,
      "loss": 0.9153,
      "step": 805
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9193288683891296,
      "learning_rate": 3.449959316517494e-05,
      "loss": 1.1014,
      "step": 806
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4483650326728821,
      "learning_rate": 3.4418226200162735e-05,
      "loss": 0.6885,
      "step": 807
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5421421527862549,
      "learning_rate": 3.433685923515053e-05,
      "loss": 0.5712,
      "step": 808
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.48090213537216187,
      "learning_rate": 3.4255492270138325e-05,
      "loss": 0.5417,
      "step": 809
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.353551983833313,
      "learning_rate": 3.417412530512612e-05,
      "loss": 0.3837,
      "step": 810
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4099329710006714,
      "learning_rate": 3.4092758340113915e-05,
      "loss": 0.3985,
      "step": 811
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8785415291786194,
      "learning_rate": 3.401139137510171e-05,
      "loss": 1.0222,
      "step": 812
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.3323451280593872,
      "learning_rate": 3.3930024410089505e-05,
      "loss": 1.8458,
      "step": 813
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7491573691368103,
      "learning_rate": 3.38486574450773e-05,
      "loss": 0.8522,
      "step": 814
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.532863974571228,
      "learning_rate": 3.3767290480065095e-05,
      "loss": 0.9712,
      "step": 815
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9759769439697266,
      "learning_rate": 3.368592351505289e-05,
      "loss": 1.5845,
      "step": 816
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8484341502189636,
      "learning_rate": 3.3604556550040685e-05,
      "loss": 0.6919,
      "step": 817
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.902672529220581,
      "learning_rate": 3.352318958502848e-05,
      "loss": 0.7272,
      "step": 818
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8709877729415894,
      "learning_rate": 3.3441822620016275e-05,
      "loss": 1.0954,
      "step": 819
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6603831052780151,
      "learning_rate": 3.336045565500407e-05,
      "loss": 1.3937,
      "step": 820
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4878169000148773,
      "learning_rate": 3.3279088689991865e-05,
      "loss": 0.8231,
      "step": 821
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6345359683036804,
      "learning_rate": 3.319772172497966e-05,
      "loss": 1.0037,
      "step": 822
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7012572288513184,
      "learning_rate": 3.3116354759967455e-05,
      "loss": 0.9043,
      "step": 823
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6387019753456116,
      "learning_rate": 3.303498779495525e-05,
      "loss": 0.9145,
      "step": 824
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7729818224906921,
      "learning_rate": 3.2953620829943045e-05,
      "loss": 1.3881,
      "step": 825
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4378615617752075,
      "learning_rate": 3.287225386493084e-05,
      "loss": 0.8492,
      "step": 826
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.45044657588005066,
      "learning_rate": 3.2790886899918635e-05,
      "loss": 1.1333,
      "step": 827
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5214044451713562,
      "learning_rate": 3.270951993490643e-05,
      "loss": 0.6035,
      "step": 828
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5362012386322021,
      "learning_rate": 3.2628152969894225e-05,
      "loss": 0.6199,
      "step": 829
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5986891984939575,
      "learning_rate": 3.254678600488202e-05,
      "loss": 0.54,
      "step": 830
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7497842907905579,
      "learning_rate": 3.2465419039869815e-05,
      "loss": 1.1499,
      "step": 831
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.983135998249054,
      "learning_rate": 3.238405207485761e-05,
      "loss": 0.6209,
      "step": 832
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.667595624923706,
      "learning_rate": 3.2302685109845405e-05,
      "loss": 1.4474,
      "step": 833
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9979485869407654,
      "learning_rate": 3.22213181448332e-05,
      "loss": 0.9665,
      "step": 834
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9402105808258057,
      "learning_rate": 3.2139951179820995e-05,
      "loss": 1.2093,
      "step": 835
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5769686102867126,
      "learning_rate": 3.205858421480879e-05,
      "loss": 0.8913,
      "step": 836
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5096705555915833,
      "learning_rate": 3.1977217249796585e-05,
      "loss": 0.727,
      "step": 837
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0517306327819824,
      "learning_rate": 3.189585028478438e-05,
      "loss": 1.0448,
      "step": 838
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5120102763175964,
      "learning_rate": 3.1814483319772175e-05,
      "loss": 0.3814,
      "step": 839
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8576168417930603,
      "learning_rate": 3.173311635475997e-05,
      "loss": 1.1743,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2236217260360718,
      "learning_rate": 3.1651749389747765e-05,
      "loss": 1.2318,
      "step": 841
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6395673751831055,
      "learning_rate": 3.157038242473555e-05,
      "loss": 0.8194,
      "step": 842
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.577704906463623,
      "learning_rate": 3.1489015459723355e-05,
      "loss": 0.7227,
      "step": 843
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6758931279182434,
      "learning_rate": 3.140764849471115e-05,
      "loss": 0.7756,
      "step": 844
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.45482170581817627,
      "learning_rate": 3.1326281529698945e-05,
      "loss": 0.6033,
      "step": 845
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8117891550064087,
      "learning_rate": 3.124491456468674e-05,
      "loss": 1.0236,
      "step": 846
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7889865636825562,
      "learning_rate": 3.1163547599674535e-05,
      "loss": 0.9032,
      "step": 847
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6391516923904419,
      "learning_rate": 3.108218063466233e-05,
      "loss": 0.6321,
      "step": 848
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6009100675582886,
      "learning_rate": 3.1000813669650125e-05,
      "loss": 0.6069,
      "step": 849
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.135136604309082,
      "learning_rate": 3.091944670463792e-05,
      "loss": 0.9754,
      "step": 850
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5407469868659973,
      "learning_rate": 3.0838079739625715e-05,
      "loss": 0.7214,
      "step": 851
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6286512017250061,
      "learning_rate": 3.075671277461351e-05,
      "loss": 0.8066,
      "step": 852
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5446959137916565,
      "learning_rate": 3.0675345809601305e-05,
      "loss": 0.9243,
      "step": 853
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7093413472175598,
      "learning_rate": 3.05939788445891e-05,
      "loss": 1.0332,
      "step": 854
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1228461265563965,
      "learning_rate": 3.051261187957689e-05,
      "loss": 1.1124,
      "step": 855
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7908097505569458,
      "learning_rate": 3.043124491456469e-05,
      "loss": 1.1709,
      "step": 856
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5247457027435303,
      "learning_rate": 3.0349877949552485e-05,
      "loss": 1.3394,
      "step": 857
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8109400868415833,
      "learning_rate": 3.0268510984540277e-05,
      "loss": 0.6774,
      "step": 858
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6743257641792297,
      "learning_rate": 3.0187144019528075e-05,
      "loss": 0.8273,
      "step": 859
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.16413152217865,
      "learning_rate": 3.0105777054515867e-05,
      "loss": 0.749,
      "step": 860
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3895835280418396,
      "learning_rate": 3.002441008950366e-05,
      "loss": 0.3709,
      "step": 861
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7127348184585571,
      "learning_rate": 2.994304312449146e-05,
      "loss": 0.9575,
      "step": 862
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6156625151634216,
      "learning_rate": 2.986167615947925e-05,
      "loss": 0.7271,
      "step": 863
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.056102991104126,
      "learning_rate": 2.978030919446705e-05,
      "loss": 0.7461,
      "step": 864
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5326695442199707,
      "learning_rate": 2.969894222945484e-05,
      "loss": 0.5984,
      "step": 865
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6583024263381958,
      "learning_rate": 2.9617575264442637e-05,
      "loss": 0.6103,
      "step": 866
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4106707572937012,
      "learning_rate": 2.9536208299430435e-05,
      "loss": 1.3563,
      "step": 867
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7487939596176147,
      "learning_rate": 2.9454841334418227e-05,
      "loss": 1.2866,
      "step": 868
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8162034749984741,
      "learning_rate": 2.937347436940602e-05,
      "loss": 0.8809,
      "step": 869
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9603247046470642,
      "learning_rate": 2.9292107404393813e-05,
      "loss": 1.2424,
      "step": 870
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5068535208702087,
      "learning_rate": 2.921074043938161e-05,
      "loss": 1.1452,
      "step": 871
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3899012506008148,
      "learning_rate": 2.912937347436941e-05,
      "loss": 0.752,
      "step": 872
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9035749435424805,
      "learning_rate": 2.90480065093572e-05,
      "loss": 0.7811,
      "step": 873
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5961137413978577,
      "learning_rate": 2.8966639544344997e-05,
      "loss": 0.5224,
      "step": 874
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7100725173950195,
      "learning_rate": 2.8885272579332795e-05,
      "loss": 0.8187,
      "step": 875
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.59129399061203,
      "learning_rate": 2.8803905614320587e-05,
      "loss": 1.052,
      "step": 876
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5723069906234741,
      "learning_rate": 2.8722538649308385e-05,
      "loss": 0.8344,
      "step": 877
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9860458970069885,
      "learning_rate": 2.8641171684296177e-05,
      "loss": 0.6288,
      "step": 878
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4085463583469391,
      "learning_rate": 2.855980471928397e-05,
      "loss": 0.5184,
      "step": 879
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8994569182395935,
      "learning_rate": 2.847843775427177e-05,
      "loss": 1.325,
      "step": 880
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.398379921913147,
      "learning_rate": 2.839707078925956e-05,
      "loss": 1.0611,
      "step": 881
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3717762231826782,
      "learning_rate": 2.8315703824247357e-05,
      "loss": 1.3042,
      "step": 882
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.993515133857727,
      "learning_rate": 2.8234336859235148e-05,
      "loss": 1.3482,
      "step": 883
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.44206252694129944,
      "learning_rate": 2.8152969894222947e-05,
      "loss": 0.8101,
      "step": 884
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8474324941635132,
      "learning_rate": 2.8071602929210745e-05,
      "loss": 0.8938,
      "step": 885
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1743578910827637,
      "learning_rate": 2.7990235964198537e-05,
      "loss": 1.1482,
      "step": 886
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4701985120773315,
      "learning_rate": 2.790886899918633e-05,
      "loss": 1.6853,
      "step": 887
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7805278897285461,
      "learning_rate": 2.7827502034174123e-05,
      "loss": 1.0022,
      "step": 888
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6049081683158875,
      "learning_rate": 2.774613506916192e-05,
      "loss": 0.7135,
      "step": 889
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3097714185714722,
      "learning_rate": 2.766476810414972e-05,
      "loss": 0.8429,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3151520788669586,
      "learning_rate": 2.758340113913751e-05,
      "loss": 0.3047,
      "step": 891
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6075563430786133,
      "learning_rate": 2.7502034174125307e-05,
      "loss": 0.6602,
      "step": 892
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.414554625749588,
      "learning_rate": 2.7420667209113098e-05,
      "loss": 0.4156,
      "step": 893
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3850794732570648,
      "learning_rate": 2.7339300244100897e-05,
      "loss": 0.6031,
      "step": 894
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5692932605743408,
      "learning_rate": 2.725793327908869e-05,
      "loss": 0.5068,
      "step": 895
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3615329265594482,
      "learning_rate": 2.7176566314076483e-05,
      "loss": 1.6724,
      "step": 896
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9930843114852905,
      "learning_rate": 2.709519934906428e-05,
      "loss": 1.1853,
      "step": 897
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5507053136825562,
      "learning_rate": 2.7013832384052073e-05,
      "loss": 0.9274,
      "step": 898
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6108000874519348,
      "learning_rate": 2.693246541903987e-05,
      "loss": 0.891,
      "step": 899
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8529710173606873,
      "learning_rate": 2.6851098454027667e-05,
      "loss": 1.2966,
      "step": 900
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8491669297218323,
      "learning_rate": 2.6769731489015458e-05,
      "loss": 0.9126,
      "step": 901
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.737540602684021,
      "learning_rate": 2.6688364524003257e-05,
      "loss": 0.9166,
      "step": 902
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7585926651954651,
      "learning_rate": 2.6606997558991055e-05,
      "loss": 0.9502,
      "step": 903
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9786536693572998,
      "learning_rate": 2.6525630593978847e-05,
      "loss": 0.8826,
      "step": 904
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5035683512687683,
      "learning_rate": 2.644426362896664e-05,
      "loss": 0.8912,
      "step": 905
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4409862756729126,
      "learning_rate": 2.6362896663954433e-05,
      "loss": 1.8465,
      "step": 906
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9745793342590332,
      "learning_rate": 2.628152969894223e-05,
      "loss": 1.4007,
      "step": 907
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6839967966079712,
      "learning_rate": 2.6200162733930027e-05,
      "loss": 0.7248,
      "step": 908
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9367371201515198,
      "learning_rate": 2.6118795768917818e-05,
      "loss": 1.0664,
      "step": 909
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6822268962860107,
      "learning_rate": 2.6037428803905617e-05,
      "loss": 0.6442,
      "step": 910
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4980712831020355,
      "learning_rate": 2.5956061838893408e-05,
      "loss": 0.3826,
      "step": 911
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5559752583503723,
      "learning_rate": 2.5874694873881207e-05,
      "loss": 0.8724,
      "step": 912
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6131584644317627,
      "learning_rate": 2.5793327908869e-05,
      "loss": 0.7963,
      "step": 913
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6360956430435181,
      "learning_rate": 2.5711960943856793e-05,
      "loss": 1.0988,
      "step": 914
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9528998136520386,
      "learning_rate": 2.563059397884459e-05,
      "loss": 1.5463,
      "step": 915
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5373332500457764,
      "learning_rate": 2.5549227013832383e-05,
      "loss": 0.6662,
      "step": 916
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6522638201713562,
      "learning_rate": 2.546786004882018e-05,
      "loss": 0.9064,
      "step": 917
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.021056056022644,
      "learning_rate": 2.5386493083807977e-05,
      "loss": 0.7382,
      "step": 918
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7712917923927307,
      "learning_rate": 2.5305126118795768e-05,
      "loss": 0.7196,
      "step": 919
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6175127029418945,
      "learning_rate": 2.5223759153783567e-05,
      "loss": 0.7872,
      "step": 920
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1227771043777466,
      "learning_rate": 2.5142392188771358e-05,
      "loss": 1.0811,
      "step": 921
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2768512964248657,
      "learning_rate": 2.5061025223759153e-05,
      "loss": 0.8719,
      "step": 922
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6381909847259521,
      "learning_rate": 2.4979658258746948e-05,
      "loss": 0.6537,
      "step": 923
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8256102204322815,
      "learning_rate": 2.4898291293734747e-05,
      "loss": 1.0029,
      "step": 924
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.41677960753440857,
      "learning_rate": 2.481692432872254e-05,
      "loss": 0.4731,
      "step": 925
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9925524592399597,
      "learning_rate": 2.4735557363710333e-05,
      "loss": 1.3583,
      "step": 926
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8449323177337646,
      "learning_rate": 2.4654190398698128e-05,
      "loss": 0.7543,
      "step": 927
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9876735806465149,
      "learning_rate": 2.4572823433685923e-05,
      "loss": 1.4171,
      "step": 928
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8686320185661316,
      "learning_rate": 2.449145646867372e-05,
      "loss": 1.0728,
      "step": 929
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6222969889640808,
      "learning_rate": 2.4410089503661517e-05,
      "loss": 0.4567,
      "step": 930
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8920950293540955,
      "learning_rate": 2.4328722538649308e-05,
      "loss": 1.2967,
      "step": 931
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.1922335624694824,
      "learning_rate": 2.4247355573637103e-05,
      "loss": 0.7323,
      "step": 932
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.725536048412323,
      "learning_rate": 2.4165988608624898e-05,
      "loss": 0.993,
      "step": 933
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5823298692703247,
      "learning_rate": 2.4084621643612697e-05,
      "loss": 1.1366,
      "step": 934
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.700393795967102,
      "learning_rate": 2.4003254678600488e-05,
      "loss": 0.8192,
      "step": 935
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9364913702011108,
      "learning_rate": 2.3921887713588283e-05,
      "loss": 1.2717,
      "step": 936
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7728438973426819,
      "learning_rate": 2.3840520748576078e-05,
      "loss": 0.7992,
      "step": 937
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.374300241470337,
      "learning_rate": 2.3759153783563877e-05,
      "loss": 0.9299,
      "step": 938
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6228323578834534,
      "learning_rate": 2.3677786818551668e-05,
      "loss": 1.3152,
      "step": 939
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9264567494392395,
      "learning_rate": 2.3596419853539463e-05,
      "loss": 1.2919,
      "step": 940
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6493892669677734,
      "learning_rate": 2.3515052888527258e-05,
      "loss": 0.7994,
      "step": 941
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3491864800453186,
      "learning_rate": 2.3433685923515053e-05,
      "loss": 0.3379,
      "step": 942
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0224934816360474,
      "learning_rate": 2.335231895850285e-05,
      "loss": 1.4821,
      "step": 943
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.94791579246521,
      "learning_rate": 2.3270951993490643e-05,
      "loss": 0.7851,
      "step": 944
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6287748217582703,
      "learning_rate": 2.3189585028478438e-05,
      "loss": 0.7635,
      "step": 945
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6307311654090881,
      "learning_rate": 2.3108218063466233e-05,
      "loss": 1.1237,
      "step": 946
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.634832501411438,
      "learning_rate": 2.3026851098454028e-05,
      "loss": 0.7227,
      "step": 947
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4242796897888184,
      "learning_rate": 2.2945484133441823e-05,
      "loss": 1.4472,
      "step": 948
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3971571922302246,
      "learning_rate": 2.2864117168429618e-05,
      "loss": 0.5907,
      "step": 949
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5331014394760132,
      "learning_rate": 2.2782750203417413e-05,
      "loss": 0.9747,
      "step": 950
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3646831512451172,
      "learning_rate": 2.2701383238405208e-05,
      "loss": 1.1019,
      "step": 951
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5767607688903809,
      "learning_rate": 2.2620016273393003e-05,
      "loss": 0.8077,
      "step": 952
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5452460646629333,
      "learning_rate": 2.2538649308380798e-05,
      "loss": 0.5772,
      "step": 953
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0731713771820068,
      "learning_rate": 2.2457282343368593e-05,
      "loss": 1.5301,
      "step": 954
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7902076840400696,
      "learning_rate": 2.2375915378356388e-05,
      "loss": 1.1833,
      "step": 955
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.061841607093811,
      "learning_rate": 2.2294548413344183e-05,
      "loss": 1.0242,
      "step": 956
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5384378433227539,
      "learning_rate": 2.2213181448331978e-05,
      "loss": 0.677,
      "step": 957
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7337107062339783,
      "learning_rate": 2.2131814483319773e-05,
      "loss": 1.6129,
      "step": 958
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6196166276931763,
      "learning_rate": 2.2050447518307568e-05,
      "loss": 0.803,
      "step": 959
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5577006936073303,
      "learning_rate": 2.1969080553295363e-05,
      "loss": 0.5843,
      "step": 960
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4326939582824707,
      "learning_rate": 2.1887713588283158e-05,
      "loss": 0.415,
      "step": 961
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8354480862617493,
      "learning_rate": 2.1806346623270953e-05,
      "loss": 0.8332,
      "step": 962
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0437448024749756,
      "learning_rate": 2.1724979658258748e-05,
      "loss": 1.0617,
      "step": 963
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5996738076210022,
      "learning_rate": 2.1643612693246543e-05,
      "loss": 0.6867,
      "step": 964
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7398732900619507,
      "learning_rate": 2.1562245728234338e-05,
      "loss": 0.958,
      "step": 965
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8098617196083069,
      "learning_rate": 2.1480878763222133e-05,
      "loss": 1.2949,
      "step": 966
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5189195871353149,
      "learning_rate": 2.1399511798209928e-05,
      "loss": 0.627,
      "step": 967
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8017902970314026,
      "learning_rate": 2.1318144833197723e-05,
      "loss": 1.3407,
      "step": 968
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7034856081008911,
      "learning_rate": 2.1236777868185518e-05,
      "loss": 0.6252,
      "step": 969
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7421129941940308,
      "learning_rate": 2.1155410903173313e-05,
      "loss": 1.1693,
      "step": 970
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8082679510116577,
      "learning_rate": 2.1074043938161108e-05,
      "loss": 0.9603,
      "step": 971
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1771620512008667,
      "learning_rate": 2.0992676973148903e-05,
      "loss": 1.1509,
      "step": 972
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.497104674577713,
      "learning_rate": 2.0911310008136698e-05,
      "loss": 0.6744,
      "step": 973
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6271973252296448,
      "learning_rate": 2.0829943043124493e-05,
      "loss": 0.7443,
      "step": 974
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8269640207290649,
      "learning_rate": 2.0748576078112285e-05,
      "loss": 0.7246,
      "step": 975
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7339803576469421,
      "learning_rate": 2.0667209113100083e-05,
      "loss": 0.8167,
      "step": 976
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8121602535247803,
      "learning_rate": 2.058584214808788e-05,
      "loss": 0.722,
      "step": 977
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6993901133537292,
      "learning_rate": 2.0504475183075673e-05,
      "loss": 0.8177,
      "step": 978
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5007294416427612,
      "learning_rate": 2.0423108218063465e-05,
      "loss": 0.6606,
      "step": 979
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1082876920700073,
      "learning_rate": 2.0341741253051263e-05,
      "loss": 1.1459,
      "step": 980
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6939299702644348,
      "learning_rate": 2.026037428803906e-05,
      "loss": 0.841,
      "step": 981
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5874921679496765,
      "learning_rate": 2.0179007323026853e-05,
      "loss": 1.075,
      "step": 982
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4229390025138855,
      "learning_rate": 2.009764035801465e-05,
      "loss": 0.6808,
      "step": 983
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.812351644039154,
      "learning_rate": 2.001627339300244e-05,
      "loss": 1.051,
      "step": 984
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7193613648414612,
      "learning_rate": 1.993490642799024e-05,
      "loss": 0.6362,
      "step": 985
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.42756280303001404,
      "learning_rate": 1.9853539462978033e-05,
      "loss": 0.9299,
      "step": 986
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9714949131011963,
      "learning_rate": 1.977217249796583e-05,
      "loss": 1.2518,
      "step": 987
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5695365071296692,
      "learning_rate": 1.969080553295362e-05,
      "loss": 0.8637,
      "step": 988
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.00016188621521,
      "learning_rate": 1.9609438567941415e-05,
      "loss": 1.0516,
      "step": 989
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6226596832275391,
      "learning_rate": 1.9528071602929213e-05,
      "loss": 1.25,
      "step": 990
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8979021310806274,
      "learning_rate": 1.944670463791701e-05,
      "loss": 0.7168,
      "step": 991
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.721117377281189,
      "learning_rate": 1.93653376729048e-05,
      "loss": 0.9458,
      "step": 992
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8425675630569458,
      "learning_rate": 1.9283970707892595e-05,
      "loss": 0.6632,
      "step": 993
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.997604489326477,
      "learning_rate": 1.920260374288039e-05,
      "loss": 1.3758,
      "step": 994
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7278200387954712,
      "learning_rate": 1.912123677786819e-05,
      "loss": 0.9984,
      "step": 995
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6561513543128967,
      "learning_rate": 1.903986981285598e-05,
      "loss": 0.9505,
      "step": 996
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.6709476709365845,
      "learning_rate": 1.8958502847843775e-05,
      "loss": 1.6583,
      "step": 997
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3706902265548706,
      "learning_rate": 1.887713588283157e-05,
      "loss": 0.3703,
      "step": 998
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8321095705032349,
      "learning_rate": 1.879576891781937e-05,
      "loss": 1.0944,
      "step": 999
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6064452528953552,
      "learning_rate": 1.8714401952807163e-05,
      "loss": 0.9334,
      "step": 1000
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.370278239250183,
      "learning_rate": 1.8633034987794955e-05,
      "loss": 0.6951,
      "step": 1001
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2633346319198608,
      "learning_rate": 1.855166802278275e-05,
      "loss": 1.2485,
      "step": 1002
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5877443552017212,
      "learning_rate": 1.8470301057770545e-05,
      "loss": 0.9255,
      "step": 1003
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.01278555393219,
      "learning_rate": 1.8388934092758343e-05,
      "loss": 0.9393,
      "step": 1004
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6247031688690186,
      "learning_rate": 1.8307567127746135e-05,
      "loss": 0.88,
      "step": 1005
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5120595693588257,
      "learning_rate": 1.822620016273393e-05,
      "loss": 0.9401,
      "step": 1006
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8801118731498718,
      "learning_rate": 1.8144833197721725e-05,
      "loss": 1.7572,
      "step": 1007
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5489539504051208,
      "learning_rate": 1.806346623270952e-05,
      "loss": 0.6653,
      "step": 1008
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2166434526443481,
      "learning_rate": 1.7982099267697315e-05,
      "loss": 1.624,
      "step": 1009
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5007724165916443,
      "learning_rate": 1.790073230268511e-05,
      "loss": 0.8665,
      "step": 1010
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4502287805080414,
      "learning_rate": 1.7819365337672905e-05,
      "loss": 0.6286,
      "step": 1011
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5954713225364685,
      "learning_rate": 1.77379983726607e-05,
      "loss": 0.9749,
      "step": 1012
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5908361077308655,
      "learning_rate": 1.76566314076485e-05,
      "loss": 1.0437,
      "step": 1013
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2643263339996338,
      "learning_rate": 1.757526444263629e-05,
      "loss": 1.1844,
      "step": 1014
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7259504199028015,
      "learning_rate": 1.7493897477624085e-05,
      "loss": 0.6694,
      "step": 1015
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6516733765602112,
      "learning_rate": 1.741253051261188e-05,
      "loss": 0.6568,
      "step": 1016
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.34007754921913147,
      "learning_rate": 1.7331163547599675e-05,
      "loss": 0.2778,
      "step": 1017
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6465380787849426,
      "learning_rate": 1.724979658258747e-05,
      "loss": 0.8954,
      "step": 1018
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4127596318721771,
      "learning_rate": 1.7168429617575265e-05,
      "loss": 0.5546,
      "step": 1019
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9870937466621399,
      "learning_rate": 1.708706265256306e-05,
      "loss": 1.0496,
      "step": 1020
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.571208655834198,
      "learning_rate": 1.7005695687550855e-05,
      "loss": 0.7809,
      "step": 1021
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6021596789360046,
      "learning_rate": 1.692432872253865e-05,
      "loss": 0.9676,
      "step": 1022
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5660828351974487,
      "learning_rate": 1.6842961757526445e-05,
      "loss": 1.0385,
      "step": 1023
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0768663883209229,
      "learning_rate": 1.676159479251424e-05,
      "loss": 0.8883,
      "step": 1024
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4610041081905365,
      "learning_rate": 1.6680227827502035e-05,
      "loss": 0.5943,
      "step": 1025
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8234534859657288,
      "learning_rate": 1.659886086248983e-05,
      "loss": 1.3534,
      "step": 1026
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5356155037879944,
      "learning_rate": 1.6517493897477625e-05,
      "loss": 0.605,
      "step": 1027
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9606783390045166,
      "learning_rate": 1.643612693246542e-05,
      "loss": 0.9604,
      "step": 1028
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7779091000556946,
      "learning_rate": 1.6354759967453215e-05,
      "loss": 0.8151,
      "step": 1029
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5895540118217468,
      "learning_rate": 1.627339300244101e-05,
      "loss": 0.9877,
      "step": 1030
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1293134689331055,
      "learning_rate": 1.6192026037428805e-05,
      "loss": 1.1829,
      "step": 1031
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.699958086013794,
      "learning_rate": 1.61106590724166e-05,
      "loss": 1.0232,
      "step": 1032
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7953755855560303,
      "learning_rate": 1.6029292107404395e-05,
      "loss": 0.7424,
      "step": 1033
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2629529237747192,
      "learning_rate": 1.594792514239219e-05,
      "loss": 1.1084,
      "step": 1034
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.719675600528717,
      "learning_rate": 1.5866558177379985e-05,
      "loss": 0.6076,
      "step": 1035
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2767565250396729,
      "learning_rate": 1.5785191212367777e-05,
      "loss": 1.614,
      "step": 1036
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6427747011184692,
      "learning_rate": 1.5703824247355575e-05,
      "loss": 0.7524,
      "step": 1037
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6620892882347107,
      "learning_rate": 1.562245728234337e-05,
      "loss": 0.7837,
      "step": 1038
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5591115355491638,
      "learning_rate": 1.5541090317331165e-05,
      "loss": 0.6203,
      "step": 1039
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9566155672073364,
      "learning_rate": 1.545972335231896e-05,
      "loss": 1.2496,
      "step": 1040
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6501581072807312,
      "learning_rate": 1.5378356387306755e-05,
      "loss": 0.6273,
      "step": 1041
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.35930997133255005,
      "learning_rate": 1.529698942229455e-05,
      "loss": 0.4855,
      "step": 1042
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6112452745437622,
      "learning_rate": 1.5215622457282345e-05,
      "loss": 0.978,
      "step": 1043
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.046998143196106,
      "learning_rate": 1.5134255492270138e-05,
      "loss": 1.099,
      "step": 1044
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1357227563858032,
      "learning_rate": 1.5052888527257933e-05,
      "loss": 0.9066,
      "step": 1045
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6134514212608337,
      "learning_rate": 1.497152156224573e-05,
      "loss": 0.7463,
      "step": 1046
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6730765104293823,
      "learning_rate": 1.4890154597233525e-05,
      "loss": 0.7528,
      "step": 1047
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9821071028709412,
      "learning_rate": 1.4808787632221318e-05,
      "loss": 0.9263,
      "step": 1048
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5350639224052429,
      "learning_rate": 1.4727420667209113e-05,
      "loss": 0.4722,
      "step": 1049
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1447292566299438,
      "learning_rate": 1.4646053702196907e-05,
      "loss": 1.4849,
      "step": 1050
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7721055746078491,
      "learning_rate": 1.4564686737184705e-05,
      "loss": 0.5976,
      "step": 1051
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5884009003639221,
      "learning_rate": 1.4483319772172498e-05,
      "loss": 1.1434,
      "step": 1052
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7414312362670898,
      "learning_rate": 1.4401952807160293e-05,
      "loss": 1.1575,
      "step": 1053
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5670698881149292,
      "learning_rate": 1.4320585842148088e-05,
      "loss": 0.5895,
      "step": 1054
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6010870337486267,
      "learning_rate": 1.4239218877135885e-05,
      "loss": 0.8304,
      "step": 1055
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.867940366268158,
      "learning_rate": 1.4157851912123678e-05,
      "loss": 0.4758,
      "step": 1056
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2840397357940674,
      "learning_rate": 1.4076484947111473e-05,
      "loss": 0.8905,
      "step": 1057
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.153625726699829,
      "learning_rate": 1.3995117982099268e-05,
      "loss": 0.8975,
      "step": 1058
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0904569625854492,
      "learning_rate": 1.3913751017087062e-05,
      "loss": 1.1182,
      "step": 1059
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9538509249687195,
      "learning_rate": 1.383238405207486e-05,
      "loss": 1.4266,
      "step": 1060
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9440047740936279,
      "learning_rate": 1.3751017087062653e-05,
      "loss": 1.277,
      "step": 1061
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7980865836143494,
      "learning_rate": 1.3669650122050448e-05,
      "loss": 0.6508,
      "step": 1062
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8264139890670776,
      "learning_rate": 1.3588283157038242e-05,
      "loss": 0.8891,
      "step": 1063
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6703367829322815,
      "learning_rate": 1.3506916192026037e-05,
      "loss": 0.4497,
      "step": 1064
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7030877470970154,
      "learning_rate": 1.3425549227013833e-05,
      "loss": 0.8258,
      "step": 1065
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6595141887664795,
      "learning_rate": 1.3344182262001628e-05,
      "loss": 0.7273,
      "step": 1066
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5115280747413635,
      "learning_rate": 1.3262815296989423e-05,
      "loss": 0.5689,
      "step": 1067
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.376262903213501,
      "learning_rate": 1.3181448331977217e-05,
      "loss": 1.6062,
      "step": 1068
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.631250262260437,
      "learning_rate": 1.3100081366965013e-05,
      "loss": 0.6664,
      "step": 1069
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.48465678095817566,
      "learning_rate": 1.3018714401952808e-05,
      "loss": 0.603,
      "step": 1070
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7038664221763611,
      "learning_rate": 1.2937347436940603e-05,
      "loss": 0.8231,
      "step": 1071
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8961575627326965,
      "learning_rate": 1.2855980471928397e-05,
      "loss": 0.8919,
      "step": 1072
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8070135712623596,
      "learning_rate": 1.2774613506916192e-05,
      "loss": 0.8848,
      "step": 1073
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.37844783067703247,
      "learning_rate": 1.2693246541903988e-05,
      "loss": 0.4975,
      "step": 1074
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.805067777633667,
      "learning_rate": 1.2611879576891783e-05,
      "loss": 1.1655,
      "step": 1075
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5958682298660278,
      "learning_rate": 1.2530512611879577e-05,
      "loss": 0.9261,
      "step": 1076
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9151514768600464,
      "learning_rate": 1.2449145646867373e-05,
      "loss": 1.0855,
      "step": 1077
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5809083580970764,
      "learning_rate": 1.2367778681855167e-05,
      "loss": 0.5333,
      "step": 1078
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0363878011703491,
      "learning_rate": 1.2286411716842962e-05,
      "loss": 1.1349,
      "step": 1079
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7009278535842896,
      "learning_rate": 1.2205044751830758e-05,
      "loss": 1.2927,
      "step": 1080
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6838194131851196,
      "learning_rate": 1.2123677786818552e-05,
      "loss": 1.1202,
      "step": 1081
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7300849556922913,
      "learning_rate": 1.2042310821806348e-05,
      "loss": 0.7392,
      "step": 1082
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.49895793199539185,
      "learning_rate": 1.1960943856794142e-05,
      "loss": 0.8458,
      "step": 1083
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.8758068680763245,
      "learning_rate": 1.1879576891781938e-05,
      "loss": 1.1396,
      "step": 1084
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.41010233759880066,
      "learning_rate": 1.1798209926769732e-05,
      "loss": 0.362,
      "step": 1085
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5932076573371887,
      "learning_rate": 1.1716842961757527e-05,
      "loss": 0.7852,
      "step": 1086
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5796735286712646,
      "learning_rate": 1.1635475996745322e-05,
      "loss": 0.9242,
      "step": 1087
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5028085708618164,
      "learning_rate": 1.1554109031733117e-05,
      "loss": 0.5972,
      "step": 1088
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.869286060333252,
      "learning_rate": 1.1472742066720912e-05,
      "loss": 1.1434,
      "step": 1089
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.625803530216217,
      "learning_rate": 1.1391375101708707e-05,
      "loss": 0.8371,
      "step": 1090
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7936268448829651,
      "learning_rate": 1.1310008136696502e-05,
      "loss": 0.7988,
      "step": 1091
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9021692872047424,
      "learning_rate": 1.1228641171684297e-05,
      "loss": 0.7782,
      "step": 1092
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6204783916473389,
      "learning_rate": 1.1147274206672092e-05,
      "loss": 0.7906,
      "step": 1093
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8153030276298523,
      "learning_rate": 1.1065907241659887e-05,
      "loss": 1.005,
      "step": 1094
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.44524234533309937,
      "learning_rate": 1.0984540276647682e-05,
      "loss": 0.8684,
      "step": 1095
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6118280291557312,
      "learning_rate": 1.0903173311635477e-05,
      "loss": 0.6927,
      "step": 1096
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8736697435379028,
      "learning_rate": 1.0821806346623272e-05,
      "loss": 1.0551,
      "step": 1097
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6102264523506165,
      "learning_rate": 1.0740439381611067e-05,
      "loss": 0.8527,
      "step": 1098
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6111932992935181,
      "learning_rate": 1.0659072416598862e-05,
      "loss": 0.6845,
      "step": 1099
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4117012023925781,
      "learning_rate": 1.0577705451586657e-05,
      "loss": 1.437,
      "step": 1100
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7246676087379456,
      "learning_rate": 1.0496338486574452e-05,
      "loss": 0.7467,
      "step": 1101
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0956026315689087,
      "learning_rate": 1.0414971521562247e-05,
      "loss": 1.1113,
      "step": 1102
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6319539546966553,
      "learning_rate": 1.0333604556550042e-05,
      "loss": 1.3624,
      "step": 1103
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8858901858329773,
      "learning_rate": 1.0252237591537837e-05,
      "loss": 0.826,
      "step": 1104
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2531664371490479,
      "learning_rate": 1.0170870626525632e-05,
      "loss": 0.9723,
      "step": 1105
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6271974444389343,
      "learning_rate": 1.0089503661513427e-05,
      "loss": 0.9925,
      "step": 1106
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.37647414207458496,
      "learning_rate": 1.000813669650122e-05,
      "loss": 0.3788,
      "step": 1107
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9538700580596924,
      "learning_rate": 9.926769731489017e-06,
      "loss": 1.0458,
      "step": 1108
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8315201997756958,
      "learning_rate": 9.84540276647681e-06,
      "loss": 1.209,
      "step": 1109
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0001946687698364,
      "learning_rate": 9.764035801464607e-06,
      "loss": 1.2624,
      "step": 1110
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6625629663467407,
      "learning_rate": 9.6826688364524e-06,
      "loss": 1.0789,
      "step": 1111
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6085095405578613,
      "learning_rate": 9.601301871440195e-06,
      "loss": 0.7289,
      "step": 1112
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8279817700386047,
      "learning_rate": 9.51993490642799e-06,
      "loss": 1.0032,
      "step": 1113
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3763190805912018,
      "learning_rate": 9.438567941415785e-06,
      "loss": 0.4913,
      "step": 1114
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1587321758270264,
      "learning_rate": 9.357200976403582e-06,
      "loss": 1.149,
      "step": 1115
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.49711063504219055,
      "learning_rate": 9.275834011391375e-06,
      "loss": 0.3825,
      "step": 1116
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7241173982620239,
      "learning_rate": 9.194467046379172e-06,
      "loss": 0.9434,
      "step": 1117
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4650067090988159,
      "learning_rate": 9.113100081366965e-06,
      "loss": 0.8117,
      "step": 1118
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.51382976770401,
      "learning_rate": 9.03173311635476e-06,
      "loss": 0.7459,
      "step": 1119
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7907054424285889,
      "learning_rate": 8.950366151342555e-06,
      "loss": 1.1351,
      "step": 1120
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7215039134025574,
      "learning_rate": 8.86899918633035e-06,
      "loss": 0.9468,
      "step": 1121
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.520499587059021,
      "learning_rate": 8.787632221318145e-06,
      "loss": 0.831,
      "step": 1122
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6127926111221313,
      "learning_rate": 8.70626525630594e-06,
      "loss": 0.686,
      "step": 1123
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6874351501464844,
      "learning_rate": 8.624898291293735e-06,
      "loss": 0.948,
      "step": 1124
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8302257657051086,
      "learning_rate": 8.54353132628153e-06,
      "loss": 1.1373,
      "step": 1125
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7617927193641663,
      "learning_rate": 8.462164361269325e-06,
      "loss": 0.9518,
      "step": 1126
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.690131425857544,
      "learning_rate": 8.38079739625712e-06,
      "loss": 0.685,
      "step": 1127
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5143394470214844,
      "learning_rate": 8.299430431244915e-06,
      "loss": 0.6912,
      "step": 1128
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5057500600814819,
      "learning_rate": 8.21806346623271e-06,
      "loss": 0.9016,
      "step": 1129
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.666587769985199,
      "learning_rate": 8.136696501220505e-06,
      "loss": 0.9412,
      "step": 1130
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6844056844711304,
      "learning_rate": 8.0553295362083e-06,
      "loss": 0.7654,
      "step": 1131
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2698469161987305,
      "learning_rate": 7.973962571196095e-06,
      "loss": 1.105,
      "step": 1132
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0262058973312378,
      "learning_rate": 7.892595606183888e-06,
      "loss": 1.1812,
      "step": 1133
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8659920692443848,
      "learning_rate": 7.811228641171685e-06,
      "loss": 0.9127,
      "step": 1134
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9761414527893066,
      "learning_rate": 7.72986167615948e-06,
      "loss": 1.0405,
      "step": 1135
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9034793972969055,
      "learning_rate": 7.648494711147275e-06,
      "loss": 1.0908,
      "step": 1136
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8523866534233093,
      "learning_rate": 7.567127746135069e-06,
      "loss": 0.7723,
      "step": 1137
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.634445071220398,
      "learning_rate": 7.485760781122865e-06,
      "loss": 0.9527,
      "step": 1138
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5633783936500549,
      "learning_rate": 7.404393816110659e-06,
      "loss": 0.7891,
      "step": 1139
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.859828770160675,
      "learning_rate": 7.323026851098453e-06,
      "loss": 1.2472,
      "step": 1140
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4347021281719208,
      "learning_rate": 7.241659886086249e-06,
      "loss": 0.6423,
      "step": 1141
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7439098358154297,
      "learning_rate": 7.160292921074044e-06,
      "loss": 1.2657,
      "step": 1142
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4266698658466339,
      "learning_rate": 7.078925956061839e-06,
      "loss": 0.4188,
      "step": 1143
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.1098055839538574,
      "learning_rate": 6.997558991049634e-06,
      "loss": 1.5236,
      "step": 1144
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4702966213226318,
      "learning_rate": 6.91619202603743e-06,
      "loss": 1.2172,
      "step": 1145
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8946666121482849,
      "learning_rate": 6.834825061025224e-06,
      "loss": 0.6393,
      "step": 1146
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9425874352455139,
      "learning_rate": 6.753458096013018e-06,
      "loss": 1.0108,
      "step": 1147
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8454223275184631,
      "learning_rate": 6.672091131000814e-06,
      "loss": 0.6246,
      "step": 1148
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0484504699707031,
      "learning_rate": 6.590724165988608e-06,
      "loss": 1.0296,
      "step": 1149
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1648423671722412,
      "learning_rate": 6.509357200976404e-06,
      "loss": 1.2558,
      "step": 1150
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6179511547088623,
      "learning_rate": 6.427990235964198e-06,
      "loss": 0.5723,
      "step": 1151
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7166746854782104,
      "learning_rate": 6.346623270951994e-06,
      "loss": 0.9043,
      "step": 1152
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5174070596694946,
      "learning_rate": 6.265256305939788e-06,
      "loss": 0.769,
      "step": 1153
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.637438178062439,
      "learning_rate": 6.183889340927583e-06,
      "loss": 0.5817,
      "step": 1154
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8979949951171875,
      "learning_rate": 6.102522375915379e-06,
      "loss": 0.7297,
      "step": 1155
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4718722105026245,
      "learning_rate": 6.021155410903174e-06,
      "loss": 1.1594,
      "step": 1156
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1542917490005493,
      "learning_rate": 5.939788445890969e-06,
      "loss": 0.8903,
      "step": 1157
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0502285957336426,
      "learning_rate": 5.858421480878763e-06,
      "loss": 1.7199,
      "step": 1158
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7318522334098816,
      "learning_rate": 5.777054515866558e-06,
      "loss": 1.3055,
      "step": 1159
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.44838282465934753,
      "learning_rate": 5.695687550854353e-06,
      "loss": 0.88,
      "step": 1160
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7792357802391052,
      "learning_rate": 5.614320585842148e-06,
      "loss": 1.1399,
      "step": 1161
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.520826816558838,
      "learning_rate": 5.532953620829943e-06,
      "loss": 1.0793,
      "step": 1162
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7284930944442749,
      "learning_rate": 5.451586655817738e-06,
      "loss": 0.9403,
      "step": 1163
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4351271688938141,
      "learning_rate": 5.370219690805533e-06,
      "loss": 0.7546,
      "step": 1164
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1883918046951294,
      "learning_rate": 5.288852725793328e-06,
      "loss": 1.5398,
      "step": 1165
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8528764843940735,
      "learning_rate": 5.207485760781123e-06,
      "loss": 1.076,
      "step": 1166
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8923212885856628,
      "learning_rate": 5.126118795768918e-06,
      "loss": 0.7594,
      "step": 1167
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5547860264778137,
      "learning_rate": 5.044751830756713e-06,
      "loss": 1.1158,
      "step": 1168
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7575052380561829,
      "learning_rate": 4.963384865744508e-06,
      "loss": 0.7818,
      "step": 1169
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7601244449615479,
      "learning_rate": 4.882017900732303e-06,
      "loss": 0.7343,
      "step": 1170
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6488808393478394,
      "learning_rate": 4.8006509357200975e-06,
      "loss": 0.6405,
      "step": 1171
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6592381596565247,
      "learning_rate": 4.7192839707078925e-06,
      "loss": 0.6919,
      "step": 1172
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8788785934448242,
      "learning_rate": 4.6379170056956875e-06,
      "loss": 0.9218,
      "step": 1173
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6225599646568298,
      "learning_rate": 4.5565500406834825e-06,
      "loss": 0.5221,
      "step": 1174
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1045559644699097,
      "learning_rate": 4.4751830756712775e-06,
      "loss": 0.7028,
      "step": 1175
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7060686945915222,
      "learning_rate": 4.3938161106590725e-06,
      "loss": 0.9106,
      "step": 1176
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6816679835319519,
      "learning_rate": 4.3124491456468675e-06,
      "loss": 1.1961,
      "step": 1177
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5725566148757935,
      "learning_rate": 4.2310821806346625e-06,
      "loss": 0.6003,
      "step": 1178
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8197067975997925,
      "learning_rate": 4.1497152156224575e-06,
      "loss": 1.0855,
      "step": 1179
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5908666849136353,
      "learning_rate": 4.0683482506102525e-06,
      "loss": 1.0582,
      "step": 1180
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7646458745002747,
      "learning_rate": 3.9869812855980475e-06,
      "loss": 1.0855,
      "step": 1181
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6071869134902954,
      "learning_rate": 3.9056143205858425e-06,
      "loss": 0.8063,
      "step": 1182
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6198987364768982,
      "learning_rate": 3.8242473555736375e-06,
      "loss": 0.6451,
      "step": 1183
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6179772615432739,
      "learning_rate": 3.7428803905614325e-06,
      "loss": 0.9146,
      "step": 1184
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3789791762828827,
      "learning_rate": 3.6615134255492267e-06,
      "loss": 0.3754,
      "step": 1185
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3161464929580688,
      "learning_rate": 3.580146460537022e-06,
      "loss": 1.5099,
      "step": 1186
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9340975880622864,
      "learning_rate": 3.498779495524817e-06,
      "loss": 1.0765,
      "step": 1187
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0048307180404663,
      "learning_rate": 3.417412530512612e-06,
      "loss": 1.7338,
      "step": 1188
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5235004425048828,
      "learning_rate": 3.336045565500407e-06,
      "loss": 1.1199,
      "step": 1189
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5563020706176758,
      "learning_rate": 3.254678600488202e-06,
      "loss": 0.5325,
      "step": 1190
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.185368537902832,
      "learning_rate": 3.173311635475997e-06,
      "loss": 0.8568,
      "step": 1191
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9468039870262146,
      "learning_rate": 3.0919446704637917e-06,
      "loss": 0.7436,
      "step": 1192
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8714249730110168,
      "learning_rate": 3.010577705451587e-06,
      "loss": 0.9269,
      "step": 1193
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.47114142775535583,
      "learning_rate": 2.9292107404393817e-06,
      "loss": 0.5785,
      "step": 1194
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8122802376747131,
      "learning_rate": 2.8478437754271767e-06,
      "loss": 0.8026,
      "step": 1195
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1978788375854492,
      "learning_rate": 2.7664768104149717e-06,
      "loss": 0.7533,
      "step": 1196
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.186542272567749,
      "learning_rate": 2.6851098454027667e-06,
      "loss": 1.5212,
      "step": 1197
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4577111005783081,
      "learning_rate": 2.6037428803905617e-06,
      "loss": 0.6103,
      "step": 1198
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4215350151062012,
      "learning_rate": 2.5223759153783567e-06,
      "loss": 1.2305,
      "step": 1199
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8653436899185181,
      "learning_rate": 2.4410089503661517e-06,
      "loss": 0.5931,
      "step": 1200
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5649451613426208,
      "learning_rate": 2.3596419853539462e-06,
      "loss": 0.5246,
      "step": 1201
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2208375930786133,
      "learning_rate": 2.2782750203417412e-06,
      "loss": 1.335,
      "step": 1202
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5190237760543823,
      "learning_rate": 2.1969080553295362e-06,
      "loss": 0.5589,
      "step": 1203
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.350806713104248,
      "learning_rate": 2.1155410903173312e-06,
      "loss": 1.9851,
      "step": 1204
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8054018020629883,
      "learning_rate": 2.0341741253051262e-06,
      "loss": 1.2219,
      "step": 1205
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6946026086807251,
      "learning_rate": 1.9528071602929212e-06,
      "loss": 0.8858,
      "step": 1206
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.885708749294281,
      "learning_rate": 1.8714401952807162e-06,
      "loss": 0.9261,
      "step": 1207
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8863222599029541,
      "learning_rate": 1.790073230268511e-06,
      "loss": 1.4513,
      "step": 1208
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7397483587265015,
      "learning_rate": 1.708706265256306e-06,
      "loss": 0.633,
      "step": 1209
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.48948267102241516,
      "learning_rate": 1.627339300244101e-06,
      "loss": 0.5558,
      "step": 1210
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6799353957176208,
      "learning_rate": 1.5459723352318958e-06,
      "loss": 0.8699,
      "step": 1211
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.8960486650466919,
      "learning_rate": 1.4646053702196908e-06,
      "loss": 0.8076,
      "step": 1212
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.4096086025238037,
      "learning_rate": 1.3832384052074858e-06,
      "loss": 0.4596,
      "step": 1213
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2480285167694092,
      "learning_rate": 1.3018714401952808e-06,
      "loss": 1.1888,
      "step": 1214
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.3444795608520508,
      "learning_rate": 1.2205044751830758e-06,
      "loss": 0.3586,
      "step": 1215
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.45836085081100464,
      "learning_rate": 1.1391375101708706e-06,
      "loss": 0.451,
      "step": 1216
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3609623908996582,
      "learning_rate": 1.0577705451586656e-06,
      "loss": 1.4173,
      "step": 1217
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.42492225766181946,
      "learning_rate": 9.764035801464606e-07,
      "loss": 0.6017,
      "step": 1218
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6440496444702148,
      "learning_rate": 8.950366151342555e-07,
      "loss": 0.8096,
      "step": 1219
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.192885398864746,
      "learning_rate": 8.136696501220505e-07,
      "loss": 0.7671,
      "step": 1220
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.569729208946228,
      "learning_rate": 7.323026851098454e-07,
      "loss": 0.6888,
      "step": 1221
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6030610203742981,
      "learning_rate": 6.509357200976404e-07,
      "loss": 1.21,
      "step": 1222
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8765538334846497,
      "learning_rate": 5.695687550854353e-07,
      "loss": 0.9177,
      "step": 1223
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3587149977684021,
      "learning_rate": 4.882017900732303e-07,
      "loss": 0.5826,
      "step": 1224
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9344746470451355,
      "learning_rate": 4.0683482506102526e-07,
      "loss": 0.7162,
      "step": 1225
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1190996170043945,
      "learning_rate": 3.254678600488202e-07,
      "loss": 0.7617,
      "step": 1226
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.712860107421875,
      "learning_rate": 2.4410089503661516e-07,
      "loss": 0.7092,
      "step": 1227
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0469880104064941,
      "learning_rate": 1.627339300244101e-07,
      "loss": 1.1031,
      "step": 1228
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5310999751091003,
      "learning_rate": 8.136696501220505e-08,
      "loss": 0.8149,
      "step": 1229
    }
  ],
  "logging_steps": 1,
  "max_steps": 1229,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2.1546645887071027e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
