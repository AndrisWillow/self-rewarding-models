{
    "model": "mistralai/Mistral-7B-Instruct-v0.2",
    "adapter": "/home/andris/src/Self_rewarding_LLM/app/benchmarks/arc-chalange/../../../outputs/Mistral-7B-Instruct-v0.2-SFT_baseline-DPO-M1",
    "result": 0.447098976109215,
    "failed_generations": 648,
    "total_rows_evaluated": 1172,
    "total_correct_guesses": 524
}